# KNN 연습

*   iris 데이터셋 사용
*   2진 분류: Setosa와 Setosa가 아닌 것으로 분류.(0, 1로 전처리 해도 됨)
*   2개 특성 사용: sepal_length, sepal_width 변수(컬럼) 사용.
*   KNN 모델 생성, 훈련, 예측, 정확도(기본값 먼저 해보기(k = 5일때))
*   k값 변화에 따른 정확도 변화

```python
iris = sns.load_dataset('iris')
iris.head()
```
![image](https://github.com/user-attachments/assets/681d9d00-01cf-491a-90c5-135a4be54326)

```python
X = iris[['sepal_length', 'sepal_width']].values
```
```python
X[:5, :]
```
![image](https://github.com/user-attachments/assets/a58bbd26-1e0e-4dec-b60d-f70edb695f0b)

```python
# 타겟 배열(레이블)
y = iris['species'].values
```
```python
y[:5]
```
![image](https://github.com/user-attachments/assets/a8a5d7d3-8907-4954-833d-c3e819290194)

```python
y[-5:]
```
![image](https://github.com/user-attachments/assets/c33b8ca9-74cd-45c5-9501-f908048de3ad)

```python
# y = 'setosa' if y == 'setosa' else 'not_setosa'
# np.where(조건식, true_val, false_val): 
# 배열의 원소들이 조건식을 만족하면 true_val로 변경, 조건식을 만족하지 않으면 fasle_val로 변경한 배열을 리턴.
y = np.where(y == 'setosa', 'setosa', 'not_setosa')
```
```python
y[:5]
```
![image](https://github.com/user-attachments/assets/1669783a-54c8-4a8a-8bd1-ecb2a20963a5)

```python
y[-5:]
```
![image](https://github.com/user-attachments/assets/7d5db2dc-b445-40f1-bc6f-3a88d90ce58f)

```python
plt.scatter(x = X[:50, 0], y = X[:50, 1]), label = 'setosa')
plt.scatter(x = X[50:, 0], y = X[50:, 1], label = 'not-setosa')

plt.legend()
plt.xlabel('sepal length(cm)')
plt.ylabel('sepal width(cm)')

plt.show()
```
![image](https://github.com/user-attachments/assets/7c1da6ad-3d50-423c-b36b-9f5f9b94916f)

```python
# 머신 러닝 모델 선택 - 생성자 호출
knn_clf = KNeighborsClassifier()
```
```python
# 모델 훈련
knn_clf.fit(X, y)
```
![image](https://github.com/user-attachments/assets/f9c6f85f-9ec7-4556-be60-511367ae8815)

```python
# 예측값 계산(각 X에 대해 가장 가까운 이웃(K개의 이웃)을 찾아보고, 그 이웃들의 y값을 기준으로 예측)
y_pred = knn_clf.predict(X)
```

```python
y_pred
```
![image](https://github.com/user-attachments/assets/3ac5e996-dec7-402e-919a-e5dcde67e1b0)

```python
# 정확도 계산 -> 모델 평가
knn_clf.score(X, y)
```
![image](https://github.com/user-attachments/assets/127804aa-e6f6-4367-9713-37d7f30dc55b)

```python
# k값에 따른 정확도 변화
accuracies = []  # 정확도들을 저장할 빈 리스트

k_values = np.arange(1, 151)  # 가장 가까운 이웃의 개수(k)
for k in k_values:
    knn = KNeighborsClassifier(n_neighbors=k)
    knn.fit(X, y)
    acc = knn.score(X, y)
    accuracies.append(acc)
print(accuracies)
```
```python
# 결과
# [1.0, 0.9933333333333333, 0.9933333333333333, 0.9933333333333333, 0.9933333333333333, 0.9933333333333333, 0.9933333333333333, 0.9933333333333333, 0.9933333333333333, 0.9933333333333333, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9933333333333333, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9933333333333333, 0.9933333333333333, 0.9933333333333333, 0.9866666666666667, 0.9866666666666667, 0.9866666666666667, 0.9866666666666667, 0.9866666666666667, 0.9866666666666667, 0.9866666666666667, 0.98, 0.98, 0.98, 0.9866666666666667, 0.9866666666666667, 0.9866666666666667, 0.9866666666666667, 0.9866666666666667, 0.9866666666666667, 0.9866666666666667, 0.9866666666666667, 0.9866666666666667, 0.9866666666666667, 0.98, 0.9866666666666667, 0.98, 0.98, 0.9733333333333334, 0.9733333333333334, 0.9533333333333334, 0.9533333333333334, 0.9466666666666667, 0.9466666666666667, 0.9333333333333333, 0.9466666666666667, 0.92, 0.9266666666666666, 0.7866666666666666, 0.8066666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666]
# 결과 정확도가 점점 떨어짐
```
```python
plt.figure(figsize = (12, 4))
plt.plot(k_values, accuracies, 'bo-')
plt.xlabel('k value')
plt.ylabel('accuracy')
plt.grid()
plt.show()

# 가장 가까운 1개 찾는건 자기 자신이니깐 의미가 없음
```
![image](https://github.com/user-attachments/assets/ba0b2aa3-405b-4063-92b8-af19fb53dfe2)

-----

*   훈련 셋과 테스트 셋을 나누는 방법
    *   순차 추출(sequential sampling)
    *   임의 추출(random sampling)
    *   층화 추출(stratified sampling)
*   분류 모델의 평가 지표(metrics)
    *   정확도(accuracy)
    *   정밀도(precision)
    *   재현율(recall)
    *   F1 score
*   특성 스케일링(feature scaling)
    *   표준화(standardization)
    *   정규화(normalization)

```python
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.neighbors import KNeighborsClassifier   # 머신러닝 모델
from sklearn.model_selection import train_test_split    # 훈련/테스트 셋 분리 함수
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score     # 평가 지표
from sklearn.metrics import classification_report, confusion_matrix 
from sklearn.preprocessing import StandardScaler, MinMaxScaler      # 변환기(특성 스케일링) (표준화, 정규화(class는 카멜 표기법으로 함))
```

# 데이터셋 준비
<br>
fish 데이터셋 - 도미(Bream)/빙어(Smelt) 분류
<br>

```python
file_path = 'https://github.com/JakeOh/202505_BD50/raw/refs/heads/main/datasets/fish.csv'
fish = pd.read_csv(file_path)
fish.head()
```
![image](https://github.com/user-attachments/assets/28c52928-a3ab-46de-84ec-8e632a351d38)

```python
df = fish.loc[fish.Species.isin(['Bream', 'Smelt']), ['Species', 'Weight', 'Length']]
df.head()
```
![image](https://github.com/user-attachments/assets/17b0e129-841c-49f1-81c4-515125892816)

```python
pd.options.display.max_rows = 10
```
```python
df    # 10개가 넘으면 ...으로 나옴
```
![image](https://github.com/user-attachments/assets/7967763e-e741-444a-a917-55a4375ca80f)

```python
# 특성 배열
X = df[['Weight', 'Length']].values
```
```python
X[:5, :]
```
![image](https://github.com/user-attachments/assets/8a946572-920a-4ad1-8586-a5b5d896dfd4)

```python
# 타겟 배열(레이블)
y = df[['Species']].values
```
```python
y
```
![image](https://github.com/user-attachments/assets/c4a10463-166a-4f96-95df-b63954b61321)

# 훈련 셋/테스트 셋 분리

머신 러닝: 컴퓨터가 데이터를 학습해서 스스로 예측.

학습/훈련: 머신 러닝 알고리즘(모델)에게 데이터(와 레이블)을 제공.

평가: 학습된 데이터와 학습되지 않은 데이터를 얼마나 잘 예측.

훈련 셋: 모델에게 제공할 데이터(와 레이블).

테스트 셋: 모델에게 제공하지 않고, 학습되지 않은 데이터를 얼마나 잘 예측하는 지 평가하기 위해 남겨두는 데이터(와 레이블).
<br>

## 순차 추출(sequential sampling)

```python
len(y)
```
![image](https://github.com/user-attachments/assets/1139b31a-5f4d-4f5d-850d-efeef98e2d15)

```python
len(X)
```
![image](https://github.com/user-attachments/assets/2819af08-babf-4851-ac8f-e8b3efb77913)

```python
len(y) * 0.7    # 70%가 몇 개냐
```
![image](https://github.com/user-attachments/assets/6b47c284-abc4-48c6-a402-8c5ca3edc5e8)

```python
num_trains = 35    # 훈련 셋의 샘플 개수 - 전체 데이터셋의 약 70% 샘플링
```
```python
X_train = X[:num_trains, :]    # 훈련 셋(0 ~ 35까지)
X_test = X[num_trains:, :]     # 테스트 셋(35 ~ 끝까지)
```
```python
X_train.shape, X_test.shape    # 전체 데이터 갯수 -> 35 + 14 = 49
```
![image](https://github.com/user-attachments/assets/22bd2828-5b74-4d79-83d3-206ca53fb9b0)

```python
y_train = y[:num_trains, :]    # 훈련 레이블
y_test = y[num_trains:, :]     # 테스트 레이블
```
```python
y_train.shape, y_test.shape    # 1차원 배열
```
![image](https://github.com/user-attachments/assets/c80f5e16-c8e7-44de-bf18-399c40e1000c)

```python
y_train
```
![image](https://github.com/user-attachments/assets/16a1e9e9-d540-4750-86ba-fd45e0f95cdf)

```python
y_test
```
![image](https://github.com/user-attachments/assets/281a8b3f-eaa8-4e84-8143-81c889a5ee49)


정렬된 데이터셋을 사용하는 경우 훈련되지 않는 레이블들이 있을 수 있음.

```python
knn = KNeighborsClassifier()    # 모델 생성
```
```python
knn.fit(X_train, y_train)    # 훈련 셋으로 훈련(학습)
```
![image](https://github.com/user-attachments/assets/8b008b4f-42e3-4422-99d4-967776228a94)

```python
# score()는 예측값과 실제값을 비교해서 얼마나 맞았는지 알려줌
train_acc = knn.score(X_train, y_train)    # X_train, y_train 에는 도미만 있어서 100% 정확도
train_acc
```
![image](https://github.com/user-attachments/assets/95e8f715-fbc8-437b-9788-900d5cddb881)

```python
test_acc = knn.score(X_test, y_test)    # 테스트 셋에서의 정확도
test_acc
```
![image](https://github.com/user-attachments/assets/08a0ca0b-a289-4cfe-95e9-6cf3c8a3804b)

```python
knn.predict(X_test)    # 테스트 셋의 예측값들(컴퓨터가 알고 있는게 Bream 밖에 없어서)
```
![image](https://github.com/user-attachments/assets/f19173be-ec04-4bff-b9bf-77feed1f746c)

## 임의 추출(random sampling)

```python
indices = np.arange(49)
print(indices)
```
![image](https://github.com/user-attachments/assets/2aa18c20-b9db-4bbf-8132-a9b895bd7bb9)

```python
np.random.seed(1)
np.random.shuffle(indices)    # 배열의 원소들을 무작위로 섞어줌(순서 변경).
print(indices)
```
![image](https://github.com/user-attachments/assets/0bba9273-2953-4d22-94ab-9ee41d66b00c)

```python
train_indices = indices[:num_trains]    # 훈련 셋으로 사용할 샘플들의 인덱스
test_indices = indices[num_trains:]     # 테스트 셋으로 사용할 샘플들의 인덱스
print(train_indices)  # 35개
print(test_indices)   # 14개
```
![image](https://github.com/user-attachments/assets/633b6384-40b9-400f-a35d-85018c3b0c68)

```python
X_train = X[train_indices]    # 훈련 셋
X_test = X[test_indices]      # 테스트 셋
```
```python
X_train.shape, X_test.shape
```
![image](https://github.com/user-attachments/assets/6225a0f7-db89-4e32-9165-7d3927b6256a)

```python
y_train = y[train_indices]    # 훈련 레이블
y_test = y[test_indices]      # 테스트 레이블
```
```python
print(y_train)
print(y_test)
```
![image](https://github.com/user-attachments/assets/930ddc23-ea80-44ba-88f4-5ba263b271f6)

```python
values, counts = np.unique(y_train, return_counts = True)     # Bream가 24번, Smelt가 11번 등장
print(values)
print(counts)
```
![image](https://github.com/user-attachments/assets/ae90acfb-69fe-44cf-a7cc-298b7d39ff9c)

```python
counts / num_trains    # Bream(도미)과 Smelt(빙어)의 비율 (24/35, 11/35)
```
![image](https://github.com/user-attachments/assets/b86da542-65e5-438c-91d9-29257d1b17e2)

```python
values, counts = np.unique(y_test, return_counts = True)
print(values)
print(counts)
```
![image](https://github.com/user-attachments/assets/eb0898bc-8660-42c6-af3f-fb23e4ceaa9b)

```python
counts / 14
```
![image](https://github.com/user-attachments/assets/4f90a450-cfa2-40d6-9618-2ae89e5fb851)

```python
knn = KNeighborsClassifier()    # KNN 모델 생성
```
```python
knn.fit(X_train, y_train)    # 모델 훈련(학습)
```
![image](https://github.com/user-attachments/assets/4c16b53e-07dc-46c0-b56c-7f08754248cf)

```python
knn.score(X_train, y_train)    # 훈련 셋에서의 정확도
```
![image](https://github.com/user-attachments/assets/8532bd13-187b-457e-99e8-22c415842075)

```python
knn.score(X_test, y_test)      # 테스트 셋에서의 정확도
```
![image](https://github.com/user-attachments/assets/0b82c54b-a08f-455f-8d72-2545c1f36e07)

## 층화 추출(stratified sampling)

```python
X_train, X_test, y_train, y_test = train_test_split(X, y,
                                                    train_size = 35,    # 훈련 셋 샘플 개수(비율). 0.75 이렇게 비율로 주기도 가능
                                                    random_state = 1,    # 난수 생성 seed
                                                    stratify = y)        # 층화 추출에서 필요한 레이블

# train_test_split 함수의 파라미터:
#   X, y: 훈련/테스트 셋으로 나눌 배열들.
#   test_size: 정수이면 테스트 셋의 샘플 개수, 0 ~ 1 사이의 실수이면 테스트 셋의 비율.
#   train_size: 정수이면 훈련 셋의 샘플 개수, 0 ~ 1 사이의 실수이면 훈련 셋의 비율.
#   test_size 또는 train_size 둘 중 하나가 결정되면, 나머지 하나는 자동으로 계산.
#   shuffle: True=샘플들을 무작위로 섞음. False=샘플들을 섞지 않음. True가 기본값.
#   stratify: 층화 추출의 기준이 되는(각 클래스의 비율을 알 수 있는) 1차원 배열.
#   random_state: 난수 seed 설정값.
```
```python
X_train.shape, X_test.shape
```
![image](https://github.com/user-attachments/assets/113074e0-dfcb-47b6-bd24-090dfbdffd9e)

```python
y_train.shape, y_test.shape
```
![image](https://github.com/user-attachments/assets/010bd60a-b524-4085-b795-a040133a8b70)

```python
values, counts = np.unique(y_train, return_counts = True)    # return_counts = True -> 각 고유 값이 몇 번씩 나왔는지 개수(count) 반환해줌
print(values)
print(counts)
```
![image](https://github.com/user-attachments/assets/837ffb59-911d-42f5-956d-2dd2eec692b7)

```python
counts / 35
```
![image](https://github.com/user-attachments/assets/24784408-5cd1-4d5c-81dd-c9187f5349bc)

```python
values, counts = np.unique(y_test, return_counts = True)
print(values)
print(counts)
```
![image](https://github.com/user-attachments/assets/e84283b3-5831-437c-b2bf-7086d00897a9)

```python
counts / 14
```
![image](https://github.com/user-attachments/assets/ce7e14a3-a9ae-4e79-8559-de80f665ba29)

```python
knn = KNeighborsClassifier()    # 모델 생성
knn.fit(X_train, y_train)    # 모델 훈련
print('훈련 셋 정확도:', knn.score(X_train, y_train))
print('테스트 셋 정확도:', knn.score(X_test, y_test))
```
![image](https://github.com/user-attachments/assets/33dc7212-b0ac-401d-a146-217ab33a0691)

```python
# 훈련 셋과 테스트 셋 시각화
plt.scatter(X_train[:, 1], X_train[:, 0], label = 'Train', alpha = 0.4, color = 'blue')
plt.scatter(X_test[:, 1], X_test[:, 0], label = 'Test', alpha = 0.4, color = 'red')

plt.legend()    # 범례 표시
plt.xlabel('Length (cm)')
plt.ylabel('Weight (g)')
plt.show()
```
![image](https://github.com/user-attachments/assets/4486476e-10f0-4059-baee-f1fdea56d612)

# 분류 평가 지표

*   용어 정의
    *   TP(True Positive): 실제 양성인 샘플을 양성으로 맞게 예측한 것.
    *   FN(False Negative): 실제 양성인 샘플을 음성으로 틀리게 예측한 것.
    *   FP(False Positive): 실제 음성인 샘플을 양성으로 틀리게 예측한 것.
    *   TN(True Negative): 실제 음성인 샘플을 음성으로 맞게 예측한 것.
*   정확도(accuracy): 샘플들을 정확하게 분류한 비율. 전체 샘플에서 정답의 비율.

    `accuracy = (TP + TN) / (TP + FN + FP + TN)`

*   정밀도(precision): 양성 예측들 중에서 정답의 비율.

    `precision = TP / (TP + FP)`

*   재현율(recall): 실제 양성 샘플들 중에서 정답의 비율.

    `recall = TP / (TP + FN)`

*   F1 score: 정밀도 재현율(반복적으로 똑같은 결과를 줄수있는거)의 조화 평균(역수들의 평균의 역수)

    `f1-score = 2/(1/precision + 1/recall)`


![image](https://github.com/user-attachments/assets/907a50a0-6f24-4a94-a354-fe9a8f3a4b9f)

![image](https://github.com/user-attachments/assets/c348c65f-61ad-4e8a-b135-e62e5af2acc0)


- (예시 - 코로나) FN(코로나인데 코로나가 아닌걸로 분류하는거)을 줄여야함.
- 일단 정확도가 높은게 좋은거고, 똑같은 정확도일때 정밀도가 좋은 모델을 선택할건지, 재현율이 좋은 모델을 선택할건지

```python
test_pred = knn.predict(X_test)    # 테스트 셋의 예측값
confusion_matrix(y_test, test_pred)    # 혼동행렬 (y_test -> 실제 정답, y_pred -> 예측값)
```
![image](https://github.com/user-attachments/assets/a298bf66-7f75-4be3-ad15-2761d2dcf4cb)

![image](https://github.com/user-attachments/assets/a386a014-dcc9-4dfc-b914-4255a6948fca)

```python
report = classification_report(y_test, test_pred)
print(report)
# support는 갯수
```
![image](https://github.com/user-attachments/assets/ea5b5135-76a0-42c1-a7f7-c1df78caf77f)

```python
accuracy_score(y_test, test_pred)    # 정확도(실제값, 예측값, 정확도 100)
```
![image](https://github.com/user-attachments/assets/4c7abc5b-93cb-4519-a19c-0fd32f90fbf9)

```python
# Bream을 양성(positive)로 간주할 때의 정밀도
precision_score(y_test, test_pred, pos_label = 'Bream')
```
![image](https://github.com/user-attachments/assets/148df302-a1cd-45f0-957a-4ffa938065ad)

```python
# Bream을 양성으로 간주할 때의 재현율
recall_score(y_test, test_pred, pos_label = 'Bream')
```
![image](https://github.com/user-attachments/assets/32b8d27e-c4da-480b-ac2c-8e5b8e180f96)

```python
# Bream을 양성으로 간주할 때의 f1 score
f1_score(y_test, test_pred, pos_label = 'Bream')
```
![image](https://github.com/user-attachments/assets/7326a7d6-1895-4067-9e45-8088b1922d6a)

```
정확도
- 전체 중에서 맞춘 예측의 비율
예: 총 100개 중 90개 맞췄다면 정확도는 90%

정밀도
- 사과라고 예측한 것들 중 실제 사과인 비율
예: - AI가 사과라고 한 10개 중 실제 사과가 8개라면 정밀도는 80%
- FP를 줄이는 데 유리함. 즉, 헛다리 짚은 예측이 얼마나 적은지를 보여줌

재현율
- 실제 사과 중에서 AI가 사과라고 맞힌 비율
예: - 실제 사과가 20개인데 그중 8개만 사과라고 맞혔다면 재현율은 40%
- FN를 줄이는 데 유리함. 중요한 대상을 빠뜨리면 안 되는 상황에 중요 (예: 병 진단)

F1-score
- 정밀도와 재현율의 균형을 평가
- Precision과 Recall 둘 중 하나라도 낮으면 F1도 낮아짐
```

# 특성 스케일링(feature scaling)

```python
# 훈련 셋(X_train) 시각화
plt.scatter(X_train[:, 1], X_train[:, 0], label = 'train set', color = 'blue', alpha = 0.0

# 가상의 물고기 (150g, 25cm) 데이터
unknown = np.array([[150, 25]])    # 주의: 특성 배열은 반드시 2차원 배열.
plt.scatter(unknown[:, 1], unknown[:, 0], label = 'unknown fish', color = 'red', marker = 'v')

plt.grid()
plt.xlabel('Length(cm)')
plt.ylabel('Weight(g)')
plt.legend()
plt.show()
```
![image](https://github.com/user-attachments/assets/6f99b814-4b36-4453-b9db-df5b473baaa0)

![image](https://github.com/user-attachments/assets/ac0401e2-9d70-41e4-8f3d-5668bd17b8a6)


```python
prediction = knn.predict(unknown)
print(prediction)
```
![image](https://github.com/user-attachments/assets/b164d7e1-e355-4624-aae2-1af3f5bf5a87)

```python
distances, indices = knn.kneighbors(unknown)
print(distances)
print(indices)    # unknown 데이터에 가장 가까운 k개의 이웃이 훈련 데이터에서 몇 번째 위치에 있는지
```
![image](https://github.com/user-attachments/assets/a8f1d6d9-14ae-434c-ad72-fbf18300aa26)

```python
y_train[indices[0]]
```
![image](https://github.com/user-attachments/assets/239e87b3-1e36-4a38-8db8-45e9666d81c2)


*   생선의 두 특성(길이, 무게)는 서로 단위(cm, g)가 다르기 때문에, 값의 범위도 매우 다름.
    *   길이 범위: 0 ~ 50 cm, 무게 범위: 0 ~ 1,000 g
    *   특성(변수)들의 스케일이 다름!
    *   가장 가까운 이웃을 찾기 위해서 거리를 계산할 때, 생선의 길이가 거리에 미치는 영향은 생선의 무게가 거리에 미치는 영향에 비해 작음.
    *   예측을 할 때 거리 계산에 영향이 적은 변수(특성)는 무시되기 쉬움.
    *   예측 결과가 부정확해 질 수 있음.
    *   따라서, 모든 특성(변수)들이 거리 계산에 비슷한 영향을 미칠 수 있도록 스케일을 변환할 필요가 있음.
*   KNN과 같이 거리 기반의 머신 러닝 알고리즘에서는, 모델을 훈련하기 전에 모든 특성(변수)들을 비슷한 스케일이 되도록 전처리(preprocessing)를 할 필요가 있음!
    *   **표준화(standardization)**: *훈련 셋*의 평균과 표준편차를 사용해서, 평균이 0이 되고 표준편차가 1이 되도록 특성 값들의 스케일을 변환하는 것.
    *   **정규화(normalization)**: *훈련 셋*의 최솟값과 최댓값을 사용해서, 최솟값은 0이 되고 최댓값은 1이 되도록 특성 값들의 스케일을 변환하는 것.

```
전처리 할때 필요한 평균, 표준편차, 최댓값.. 훈련 셋에서 데이터를 기준으로 처리해야 함
테스트 셋은 훈련 셋에서 찾은걸
```

## 표준화(Standardization)
<br>
훈련 셋에서 특성들의 평균을 0으로, 표준편차가 1이 되도록 특성들의 값을 변환(scaling)하는 것. 

```python
std_scaler = StandardScaler()   # 표준화 특성 스케일링 변환기 생성
```
```python
# 훈련셋에서만 fit
# 평균과 표준편차 찾기
std_scaler.fit(X_train)     # 표준화하기 위해서 필요한 훈련 셋의 평균과 표준편차를 찾음.
```
![image](https://github.com/user-attachments/assets/c80c7946-590b-49a4-a5dd-c6013a7944e4)

```python
std_scaler.mean_    # [무게의 평균, 길이의 평균]
# 훈련셋의 무게의 평균, 훈련셋의 길이의 평균
```
![image](https://github.com/user-attachments/assets/fb62481a-2227-40a5-bb40-1f0a267daa19)

```python
std_scaler.var_     # [무게의 분산, 길이의 분산]
```
![image](https://github.com/user-attachments/assets/198cfad8-f906-4cc9-92dc-76afd02da3ef)

```python
# 변환된 훈련셋
X_tr_scaled = std_scaler.transform(X_train)     # 표준화 특성 스케일링을 수행. (훈련 셋 표준화)
# 평균 0, 표준편차 1로 변환된 훈련 데이터
```
```python
X_tr_scaled[:5, :]
```
![image](https://github.com/user-attachments/assets/cf27362c-e5e9-4c97-a854-f268d4b715d2)

```python
X_te_scaled = std_scaler.transform(X_test)  # 테스트 셋 표준화
```
```python
X_te_scaled
```
![image](https://github.com/user-attachments/assets/38f1bbb3-42ce-4449-a2f8-cb800d7131ff)

- 여기까지 데이터 전처리

```python

```



