<참고><br>
https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_iris.html#sklearn.datasets.load_iris

# Imports

```python
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn import datasets    # load_iris() 함수 사용하기 위해서
from sklearn.model_selection import train_test_split    # 훈련 셋/테스트 셋 분리 함수
from sklearn.preprocessing import StandardScaler    # 특성 스케일링 클래스
from sklearn.neighbors import KNeighborsClassifier      # KNN 모델 클래스
from sklearn.metrics import confusion_matrix, classification_report, accuracy_score     # 평가 지표
```
# Iris 데이터셋 준비

```python
iris = datasets.load_iris()
```

scikit-learn Bunch 클래스: Python의 dict와 비슷한 클래스.
*   key_value 쌍으로 아이템들을 저장.
*   `bunch[key]` 또는 `bunch.key` 형식으로 key를 사용해서 value 값을 참조할 수 있음.

```python
print(type(iris))    # sklearn 패키지에서 만들어져 있는 Bunch라는 클래스 타입
```
![image](https://github.com/user-attachments/assets/a5b4e8a5-4411-4569-a9e1-312184020a23)

```python
iris.keys()
```
![image](https://github.com/user-attachments/assets/d1883647-51da-4535-ba33-cee095abec81)

```python
X = iris.data    # 특성 배열: (sample 개수, 특성 개수) shape을 갖는 2차원 배열
y = iris.target    # 타겟 배열: (sample 개수,) shape을 갖는 1차원 배열(ndarray)
```
```python
X[:5, :]    # 한개의 꽃에 대해서 4개의 정보가 있음(붓꽃의 꽃받침 길이/너비, 꽃잎 길이/너비)
```
![image](https://github.com/user-attachments/assets/05cc8beb-b64b-4bfc-b476-73f49cc3b25d)

```python
y[:5]
```
![image](https://github.com/user-attachments/assets/fb62546f-53f7-4465-be7a-57b47a19c513)

```python
np.unique(y, return_counts = True)    # y에 0, 1, 2가 50개씩 있음
# 레이블(타겟 클래스)들이 숫자로 인코딩되어 있음.
```
![image](https://github.com/user-attachments/assets/2bf1de5a-36c6-4663-8b4a-ffd8e78038f9)

```python
iris.target_names    # 타겟 이름(문자열)
```
![image](https://github.com/user-attachments/assets/14185ad3-036c-4cc0-8e95-a734cfde7802)

```python
iris.feature_names    # 특성 이름
```
![image](https://github.com/user-attachments/assets/6a12e016-7b2a-4614-936b-66cd1382340c)

```python
print(iris.DESCR)    # iris 데이터셋에 대한 설명(여기서 class는 레이블)
```
```
<결과>

.. _iris_dataset:

Iris plants dataset
--------------------

**Data Set Characteristics:**

:Number of Instances: 150 (50 in each of three classes)
:Number of Attributes: 4 numeric, predictive attributes and the class
:Attribute Information:
    - sepal length in cm
    - sepal width in cm
    - petal length in cm
    - petal width in cm
    - class:
            - Iris-Setosa
            - Iris-Versicolour
            - Iris-Virginica

:Summary Statistics:

============== ==== ==== ======= ===== ====================
                Min  Max   Mean    SD   Class Correlation
============== ==== ==== ======= ===== ====================
sepal length:   4.3  7.9   5.84   0.83    0.7826
sepal width:    2.0  4.4   3.05   0.43   -0.4194
petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)
petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)
============== ==== ==== ======= ===== ====================

:Missing Attribute Values: None
:Class Distribution: 33.3% for each of 3 classes.
:Creator: R.A. Fisher
:Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)
:Date: July, 1988

The famous Iris database, first used by Sir R.A. Fisher. The dataset is taken
from Fisher's paper. Note that it's the same as in R, but not as in the UCI
Machine Learning Repository, which has two wrong data points.

This is perhaps the best known database to be found in the
pattern recognition literature.  Fisher's paper is a classic in the field and
is referenced frequently to this day.  (See Duda & Hart, for example.)  The
data set contains 3 classes of 50 instances each, where each class refers to a
type of iris plant.  One class is linearly separable from the other 2; the
latter are NOT linearly separable from each other.

.. dropdown:: References

  - Fisher, R.A. "The use of multiple measurements in taxonomic problems"
    Annual Eugenics, 7, Part II, 179-188 (1936); also in "Contributions to
    Mathematical Statistics" (John Wiley, NY, 1950).
  - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.
    (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.
  - Dasarathy, B.V. (1980) "Nosing Around the Neighborhood: A New System
    Structure and Classification Rule for Recognition in Partially Exposed
    Environments".  IEEE Transactions on Pattern Analysis and Machine
    Intelligence, Vol. PAMI-2, No. 1, 67-71.
  - Gates, G.W. (1972) "The Reduced Nearest Neighbor Rule".  IEEE Transactions
    on Information Theory, May 1972, 431-433.
  - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al"s AUTOCLASS II
    conceptual clustering system finds 3 classes in the data.
  - Many, many more ...
```

```python
# iris = datasets.load_iris()
# X = iris.data
# y = iris.target
# 위에 코드를 한줄로 끝냄
# 원래는 복잡한 구조인 Bunch로 데이터 반환하는데 return_X_y = True 옵션을 사용하면 단순한 형태로 가져옴(머신러닝 모델에 적용할 때 유용)
X, y = datasets.load_iris(return_X_y = True)    # 2개의 배열 리턴 해줌
```
```
<결과>
(array([[5.1, 3.5, 1.4, 0.2],
        [4.9, 3. , 1.4, 0.2],
        [4.7, 3.2, 1.3, 0.2],
        [4.6, 3.1, 1.5, 0.2],
        [5. , 3.6, 1.4, 0.2],
        [5.4, 3.9, 1.7, 0.4],
        [4.6, 3.4, 1.4, 0.3],
        [5. , 3.4, 1.5, 0.2],
        [4.4, 2.9, 1.4, 0.2],
        [4.9, 3.1, 1.5, 0.1],
        [5.4, 3.7, 1.5, 0.2],
        [4.8, 3.4, 1.6, 0.2],
        [4.8, 3. , 1.4, 0.1],
        [4.3, 3. , 1.1, 0.1],
        [5.8, 4. , 1.2, 0.2],
        [5.7, 4.4, 1.5, 0.4],
        [5.4, 3.9, 1.3, 0.4],
        [5.1, 3.5, 1.4, 0.3],
        [5.7, 3.8, 1.7, 0.3],
        [5.1, 3.8, 1.5, 0.3],
        [5.4, 3.4, 1.7, 0.2],
        [5.1, 3.7, 1.5, 0.4],
        [4.6, 3.6, 1. , 0.2],
        [5.1, 3.3, 1.7, 0.5],
        [4.8, 3.4, 1.9, 0.2],
        [5. , 3. , 1.6, 0.2],
        [5. , 3.4, 1.6, 0.4],
        [5.2, 3.5, 1.5, 0.2],
        [5.2, 3.4, 1.4, 0.2],
        [4.7, 3.2, 1.6, 0.2],
        [4.8, 3.1, 1.6, 0.2],
        [5.4, 3.4, 1.5, 0.4],
        [5.2, 4.1, 1.5, 0.1],
        [5.5, 4.2, 1.4, 0.2],
        [4.9, 3.1, 1.5, 0.2],
        [5. , 3.2, 1.2, 0.2],
        [5.5, 3.5, 1.3, 0.2],
        [4.9, 3.6, 1.4, 0.1],
        [4.4, 3. , 1.3, 0.2],
        [5.1, 3.4, 1.5, 0.2],
        [5. , 3.5, 1.3, 0.3],
        [4.5, 2.3, 1.3, 0.3],
        [4.4, 3.2, 1.3, 0.2],
        [5. , 3.5, 1.6, 0.6],
        [5.1, 3.8, 1.9, 0.4],
        [4.8, 3. , 1.4, 0.3],
        [5.1, 3.8, 1.6, 0.2],
        [4.6, 3.2, 1.4, 0.2],
        [5.3, 3.7, 1.5, 0.2],
        [5. , 3.3, 1.4, 0.2],
        [7. , 3.2, 4.7, 1.4],
        [6.4, 3.2, 4.5, 1.5],
        [6.9, 3.1, 4.9, 1.5],
        [5.5, 2.3, 4. , 1.3],
        [6.5, 2.8, 4.6, 1.5],
        [5.7, 2.8, 4.5, 1.3],
        [6.3, 3.3, 4.7, 1.6],
        [4.9, 2.4, 3.3, 1. ],
        [6.6, 2.9, 4.6, 1.3],
        [5.2, 2.7, 3.9, 1.4],
        [5. , 2. , 3.5, 1. ],
        [5.9, 3. , 4.2, 1.5],
        [6. , 2.2, 4. , 1. ],
        [6.1, 2.9, 4.7, 1.4],
        [5.6, 2.9, 3.6, 1.3],
        [6.7, 3.1, 4.4, 1.4],
        [5.6, 3. , 4.5, 1.5],
        [5.8, 2.7, 4.1, 1. ],
        [6.2, 2.2, 4.5, 1.5],
        [5.6, 2.5, 3.9, 1.1],
        [5.9, 3.2, 4.8, 1.8],
        [6.1, 2.8, 4. , 1.3],
        [6.3, 2.5, 4.9, 1.5],
        [6.1, 2.8, 4.7, 1.2],
        [6.4, 2.9, 4.3, 1.3],
        [6.6, 3. , 4.4, 1.4],
        [6.8, 2.8, 4.8, 1.4],
        [6.7, 3. , 5. , 1.7],
        [6. , 2.9, 4.5, 1.5],
        [5.7, 2.6, 3.5, 1. ],
        [5.5, 2.4, 3.8, 1.1],
        [5.5, 2.4, 3.7, 1. ],
        [5.8, 2.7, 3.9, 1.2],
        [6. , 2.7, 5.1, 1.6],
        [5.4, 3. , 4.5, 1.5],
        [6. , 3.4, 4.5, 1.6],
        [6.7, 3.1, 4.7, 1.5],
        [6.3, 2.3, 4.4, 1.3],
        [5.6, 3. , 4.1, 1.3],
        [5.5, 2.5, 4. , 1.3],
        [5.5, 2.6, 4.4, 1.2],
        [6.1, 3. , 4.6, 1.4],
        [5.8, 2.6, 4. , 1.2],
        [5. , 2.3, 3.3, 1. ],
        [5.6, 2.7, 4.2, 1.3],
        [5.7, 3. , 4.2, 1.2],
        [5.7, 2.9, 4.2, 1.3],
        [6.2, 2.9, 4.3, 1.3],
        [5.1, 2.5, 3. , 1.1],
        [5.7, 2.8, 4.1, 1.3],
        [6.3, 3.3, 6. , 2.5],
        [5.8, 2.7, 5.1, 1.9],
        [7.1, 3. , 5.9, 2.1],
        [6.3, 2.9, 5.6, 1.8],
        [6.5, 3. , 5.8, 2.2],
        [7.6, 3. , 6.6, 2.1],
        [4.9, 2.5, 4.5, 1.7],
        [7.3, 2.9, 6.3, 1.8],
        [6.7, 2.5, 5.8, 1.8],
        [7.2, 3.6, 6.1, 2.5],
        [6.5, 3.2, 5.1, 2. ],
        [6.4, 2.7, 5.3, 1.9],
        [6.8, 3. , 5.5, 2.1],
        [5.7, 2.5, 5. , 2. ],
        [5.8, 2.8, 5.1, 2.4],
        [6.4, 3.2, 5.3, 2.3],
        [6.5, 3. , 5.5, 1.8],
        [7.7, 3.8, 6.7, 2.2],
        [7.7, 2.6, 6.9, 2.3],
        [6. , 2.2, 5. , 1.5],
        [6.9, 3.2, 5.7, 2.3],
        [5.6, 2.8, 4.9, 2. ],
        [7.7, 2.8, 6.7, 2. ],
        [6.3, 2.7, 4.9, 1.8],
        [6.7, 3.3, 5.7, 2.1],
        [7.2, 3.2, 6. , 1.8],
        [6.2, 2.8, 4.8, 1.8],
        [6.1, 3. , 4.9, 1.8],
        [6.4, 2.8, 5.6, 2.1],
        [7.2, 3. , 5.8, 1.6],
        [7.4, 2.8, 6.1, 1.9],
        [7.9, 3.8, 6.4, 2. ],
        [6.4, 2.8, 5.6, 2.2],
        [6.3, 2.8, 5.1, 1.5],
        [6.1, 2.6, 5.6, 1.4],
        [7.7, 3. , 6.1, 2.3],
        [6.3, 3.4, 5.6, 2.4],
        [6.4, 3.1, 5.5, 1.8],
        [6. , 3. , 4.8, 1.8],
        [6.9, 3.1, 5.4, 2.1],
        [6.7, 3.1, 5.6, 2.4],
        [6.9, 3.1, 5.1, 2.3],
        [5.8, 2.7, 5.1, 1.9],
        [6.8, 3.2, 5.9, 2.3],
        [6.7, 3.3, 5.7, 2.5],
        [6.7, 3. , 5.2, 2.3],
        [6.3, 2.5, 5. , 1.9],
        [6.5, 3. , 5.2, 2. ],
        [6.2, 3.4, 5.4, 2.3],
        [5.9, 3. , 5.1, 1.8]]),
 array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]))
```
```python
result = datasets.load_iris(as_frame = True)
result.frame    # 데이터프레임으로 보여줌
```
![image](https://github.com/user-attachments/assets/d33bc3de-5255-412e-b31b-73fc584b1b1f)

# 훈련 셋/테스트 셋 분리

```python
X_train, X_test, y_train, y_test = train_test_split(X, y,
                                                    test_size = 0.2,
                                                    random_state = 42,  # 섞을 때 난수를 고정시키는거
                                                    stratify = y)
```
```python
X_train.shape, X_test.shape
```
![image](https://github.com/user-attachments/assets/3ddaa6c3-49f1-4265-9390-adbe80e139ac)

```python
y_train.shape, y_test.shape
```
![image](https://github.com/user-attachments/assets/453652d0-e26c-4453-b606-70dcaa6ae12c)

```python
np.unique(y_train, return_counts = True)    # 1대1대1로 나눠져 있음
```
![image](https://github.com/user-attachments/assets/d29285b0-afce-449b-8e46-967e2d1b7f6d)

```python
np.unique(y_test, return_counts = True)
```

<img width="284" height="36" alt="image" src="https://github.com/user-attachments/assets/6fc30afe-fb30-4014-8e0e-c6b8c3af6502" />

# 전처리(특성 스케일링)

```python
scaler = StandardScaler()
```
```python
# fit_transform(X): X에서 각 특성들의 평균, 표준편차를 찾아서(fit) 스케일 변환을 수행(transform).
# 주의: 테스트 셋에서는 fit_transform() 메서드를 사용하면 안됨. transform() 메서드만 사용해야 됨.
X_train_scaled = scaler.fit_transform(X_train)
```
```python
X_train_scaled[:5, :]
```
<img width="437" height="96" alt="image" src="https://github.com/user-attachments/assets/5216fc59-707c-45fd-bf43-d5765cd28baa" />

```python
scaler.mean_    # 4개 특성들의 평균(1차원 배열)
```
<img width="400" height="31" alt="image" src="https://github.com/user-attachments/assets/35cc3e2f-25c2-42d6-b862-a212cec80416" />

```python
scaler.var_    # 4개 특성들의 분산
```
<img width="405" height="30" alt="image" src="https://github.com/user-attachments/assets/a181616c-58a6-43b9-baca-6394912cab9a" />

```python
X_test_scaled = scaler.transform(X_test)
```
```python
X_test_scaled[:5, :]
```
<img width="443" height="96" alt="image" src="https://github.com/user-attachments/assets/34d523c1-2a23-43c3-8517-4afa8d935a0d" />

# 모델 훈련, 평가

```python
knn = KNeighborsClassifier()
```
```python
knn.fit(X_train_scaled, y_train)
```
<img width="239" height="68" alt="image" src="https://github.com/user-attachments/assets/430cb076-f532-4dcf-b969-b8936416bb13" />

```python
# 훈련 셋의 예측값
train_pred = knn.predict(X_train_scaled)
print(train_pred)
```
<img width="538" height="80" alt="image" src="https://github.com/user-attachments/assets/a129cfdb-738f-4bbc-ba5b-e7dce912bc93" />

```python
print(y_train)    # 훈련 셋의 실제 레이블(정답지)
```
<img width="537" height="76" alt="image" src="https://github.com/user-attachments/assets/683f8f6c-de99-4722-a223-4e0b87ff2ee5" />

```python
knn.score(X_train_scaled, y_train)    # 정확도
```
<img width="63" height="35" alt="image" src="https://github.com/user-attachments/assets/583775a4-1ec4-470b-bced-eb7d6c03ae71" />

```python
sns.pairplot(data = result.frame, hue = 'target')
plt.show()
```
<img width="1054" height="986" alt="image" src="https://github.com/user-attachments/assets/b2bb406e-ec82-479f-9234-5a5df18f7ab7" />

```python
# 혼동 행렬(오차 행렬)
conf_mat = confusion_matrix(y_train, train_pred)
conf_mat
```
<img width="163" height="56" alt="image" src="https://github.com/user-attachments/assets/5b42fefd-dc4b-4975-ac3e-0dd9cdabfcf3" />


```
실제 레이블이 1인 샘플을 2로 잘못 예측한 샘플이 1개.

실제 레이블이 2인 샘플을 1로 잘못 예측한 샘플이 2개.

실제 0을 0이라고 예측한게 40개(나머지는 맞춤), 실제 1을 1이라고 예측한게 39개(1개는 2라고 해서 틀림)

대각선이 정답
```

```python
sns.heatmap(data = conf_mat, cmap = 'Blues', annot = True,    # annot -> 숫자 보여주는 거
            xticklabels = iris.target_names, yticklabels = iris.target_names)
plt.show()
# 숫자에 따라 색 진하기가 다름
```
<img width="479" height="391" alt="image" src="https://github.com/user-attachments/assets/526422e6-3f55-41f7-8603-65ac3ff8f5fd" />

```python
print(classification_report(y_train, train_pred))
```
<img width="395" height="164" alt="image" src="https://github.com/user-attachments/assets/c6612826-a3a4-473e-836e-2d20bb4d42c3" />

```python
print(39/41)
print(39/40)
```
<img width="146" height="40" alt="image" src="https://github.com/user-attachments/assets/2dea38c9-7b2a-408c-9566-bf951e4612c9" />

```python
# 테스트 셋 예측값
test_pred = knn.predict(X_test_scaled)
```
```python
print(test_pred)
```
<img width="442" height="34" alt="image" src="https://github.com/user-attachments/assets/ee933ef5-5c5b-4ef8-8bb8-a2f3cd3443d8" />

```python
# 테스트 셋의 실제 레이블
print(y_test)
```
<img width="444" height="28" alt="image" src="https://github.com/user-attachments/assets/367fb0a2-8e4d-43c2-9df6-e5cffd796eab" />

```python
accuracy_score(y_test, test_pred)
```
<img width="145" height="29" alt="image" src="https://github.com/user-attachments/assets/79f2e2c6-d1d1-401e-9a8a-562e476c8f11" />

```python
cm = confusion_matrix(y_test, test_pred)
cm
```
<img width="161" height="63" alt="image" src="https://github.com/user-attachments/assets/33c85ba8-85c8-4a68-a6cc-64f545f1e152" />

```python
sns.heatmap(data = cm, cmap = 'Blues', annot = True,
            xticklabels = iris.target_names, yticklabels = iris.target_names)
plt.show()
```
<img width="487" height="397" alt="image" src="https://github.com/user-attachments/assets/a25de662-a9ce-44cb-88c2-2899d6a76495" />

```python
print(classification_report(y_test, test_pred))
```
<img width="389" height="155" alt="image" src="https://github.com/user-attachments/assets/927a723f-ffe1-4ee8-ab2b-cf5630f1241b" />

# k 값 변화에 따른 훈련 셋과 테스트 셋의 정확도

```python
k_values = np.arange(1, 41)     # KNN에서 사용할 n_neighbors 값(총 120개 중에 40개만 조사할거임)
train_scores = []    # 훈련 셋에서의 정확도를 저장할 리스트(정확도 40개가 저장됨)
test_scores = []    # 테스트 셋에서의 정확도를 저장할 리스트

for k in k_values:
    # 모델 생성
    knn = KNeighborsClassifier(n_neighbors=k)
    # 모델 훈련
    knn.fit(X_train_scaled, y_train)
    # 훈련 셋 정확도
    train_acc = knn.score(X_train_scaled, y_train)
    train_scores.append(train_acc)
    # 테스트 셋 정확도
    test_acc = knn.score(X_test_scaled, y_test)
    test_scores.append(test_acc)
```

```python
print(train_scores)
```
```python
# <결과>
[1.0, 0.9666666666666667, 0.9583333333333334, 0.9583333333333334, 0.975, 0.9583333333333334, 0.975, 0.9583333333333334, 0.9583333333333334, 0.9583333333333334, 0.9583333333333334, 0.9583333333333334, 0.9583333333333334, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 0.9583333333333334, 0.9666666666666667, 0.9416666666666667, 0.9583333333333334, 0.95, 0.9583333333333334, 0.9583333333333334, 0.95, 0.9583333333333334, 0.9333333333333333, 0.9333333333333333, 0.925, 0.9166666666666666, 0.9166666666666666, 0.9, 0.8916666666666667, 0.8916666666666667, 0.8833333333333333, 0.875, 0.8833333333333333, 0.8833333333333333, 0.8916666666666667, 0.8916666666666667, 0.891666666666666
```
```python
print(test_scores)
```
```python
[0.9666666666666667, 0.9333333333333333, 0.9333333333333333, 0.9333333333333333, 0.9333333333333333, 0.9333333333333333, 0.9666666666666667, 0.9333333333333333, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 0.9333333333333333, 0.9333333333333333, 0.9, 0.9, 0.8666666666666667, 0.8666666666666667, 0.8666666666666667, 0.8666666666666667, 0.8666666666666667, 0.8666666666666667, 0.8666666666666667, 0.8666666666666667, 0.8666666666666667, 0.8666666666666667, 0.8666666666666667, 0.8666666666666667, 0.8666666666666667, 0.8666666666666667, 0.866666666666666
```
```python
# 훈련 셋 정확도 시각화(k값이 많을 수록 좋은건 아님)
plt.plot(k_values, train_scores, 'bo-', label = 'Train Acc.')

# 테스트 셋 정확도 시각화
plt.plot(k_values, test_scores, 'ro:', label = 'Test Acc.')

plt.xlabel('k (# of neighbors)')
plt.ylabel('accuracy')
plt.legend()
plt.grid()
plt.show()
```
<img width="539" height="402" alt="image" src="https://github.com/user-attachments/assets/dc98d179-1e6b-4588-be39-2d6b49f24891" />

```
# 정확도가 잘 나오는 k값은 데이터셋에 따라 다름
# 이 그래프에서 7이 젤 좋음. train과 test 값이 다 높음
```

*   과(대)적합(overfitting)
    *   훈련 셋에서의 평가 점수가 테스트 셋에서의 평가 점수보다 (과하게) 높은 경우.
    *   과대적합인 경우에는 학습되지 않은 데이터에서 오차가 크게 발생 -> 일반화 성능이 나쁘다.
    *   일반적으로 지도학습인 경우에는 과대적합이 발생하는 경우가 많음.
    *   과대적합의 정도가 작은 모델일 수록 좋은 모델.
    *   과대적합을 줄이기 위한 튜닝을 수행 -> 규제(regularization) 적용.
*   과소적합(underfitting)
    *   훈련 셋에서의 평가 점수가 테스트 셋에서의 평가 점수보다 낮은 경우.
    *   보통 훈련 샘플의 개수가 적을 때 과소적합이 나타나는 경우가 있음.
    *   훈련 샘플을 더 많이 수집해서 모델을 훈련시키면 과소적합을 해결할 수 있음.
    *   교차 검증(cross validation)을 사용해서 훈련 샘플의 크기를 늘린 것 같은 효과를 줄 수 있음.

-----

머신 러닝(Machine Learning) 종류 - 사람의 감독 하에 훈련하는 것인 지 아닌 지 분류
*   지도 학습(Supervised Learning): 레이블(타겟)이 있는 데이터를 학습.-> (수업시간엔 대부분 지도학습 할거임)
    *   분류(classification): 클래스들을 분류.
    *   회귀(regression): 숫자 예측.
*   비지도 학습(Unsupervised Learning): 레이블이 없는 데이터를 학습.
    *   군집(clustering)
    *   시각화(visualization)
    *   이상치(outlier) 탐지
*   준지도 학습(semi-supervised learning): 비지도 학습 + 전문가 시스템
*   강화 학습(reinforcement learning): 보상과 벌칙을 통해서 학습.


# 문제

fish 데이터셋에서 물고기의 무게를 예측.
*   Perch(농어)의 무게(Weight)를 길이(Length) 특성만으로 예측.
    *   Weight(관심 변수, 레이블, 타겟) ~ Length(독립 변수, 특성)
    *   KNN, Linear Regression
*   Perch의 무게를 다른 4개의 특성들로 예측.
    *   Weight ~ Length + Diagonal + Height + Width # 독립 변수가 4개가 있고,
    *   Linear Regression
 
# Imports

```python
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.neighbors import KNeighborsRegressor       # KNN을 이용한 숫자 예측 알고리즘.
from sklearn.linear_model import LinearRegression       # 선형 회귀를 이용한 숫자 예측 알고리즘.
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score       # 회귀 평가 지표들
```

## 데이터 준비

```python
file_path = 'https://github.com/JakeOh/202505_BD50/raw/refs/heads/main/datasets/fish.csv'
```
```python
fish = pd.read_csv(file_path)
```
```python
fish.head()
```
<img width="418" height="186" alt="image" src="https://github.com/user-attachments/assets/643ccd92-9c37-4cfb-8f89-1de37eee7978" />

```python
perch = fish[fish.Species == 'Perch']
```
```python
perch.head()
```
<img width="421" height="181" alt="image" src="https://github.com/user-attachments/assets/94c13ea4-9ebc-4a82-9bd8-7ba86138c22b" />
<br>

농어의 무게(Weight)를 길이(Length)만으로 예측할 수 있을까?
*   특성(feature): Length -> 2차원 배열(컬럼이 한개라도 2차원 배열이 되어야 함)
*   레이블(label), 타겟(target, 예측하고 싶은거): Weight -> 1차원 배열

```python
perch[['Length']].values    # 2차원 배열. perch['Length'].values -> 1차원 배열
```
```python
array([[ 8.4],
       [13.7],
       [15. ],
       [16.2],
       [17.4],
       [18. ],
       [18.7],
       [19. ],
       [19.6],
       [20. ],
       [21. ],
       [21. ],
       [21. ],
       [21.3],
       [22. ],
       [22. ],
       [22. ],
       [22. ],
       [22. ],
       [22.5],
       [22.5],
       [22.7],
       [23. ],
       [23.5],
       [24. ],
       [24. ],
       [24.6],
       [25. ],
       [25.6],
       [26.5],
       [27.3],
       [27.5],
       [27.5],
       [27.5],
       [28. ],
       [28.7],
       [30. ],
       [32.8],
       [34.5],
       [35. ],
       [36.5],
       [36. ],
       [37. ],
       [37. ],
       [39. ],
       [39. ],
       [39. ],
       [40. ],
       [40. ],
       [40. ],
       [40. ],
       [42. ],
       [43. ],
       [43. ],
       [43.5],
       [44. ]])
```
```python
# 특성 배열 - (samples, features) shape의 2차원 배열
X = perch[['Length']].values.copy()
# copy()는 원본 데이터를 복사해서 새로운 배열을 생성. 나중에 X를 수정하더라도 perch의 DataFrame에는 영향을 주지 않음
```
```python
X[:5]
```
<img width="122" height="91" alt="image" src="https://github.com/user-attachments/assets/808e678a-4a44-4045-9b8e-65f3d81b3af6" />

```python
X.shape    # 샘플 개수: 56, 특성 개수: 1
```
<img width="61" height="25" alt="image" src="https://github.com/user-attachments/assets/ae62038c-bfa5-4247-9856-4d78841f7b47" />

```python
# 타겟 배열 - (samples,) shape의 1차원 배열
y = perch['Weight'].values.copy()
```
```python
y[:5]   # 길이가 8.4인건 무게가 5.9 ...
```
<img width="273" height="26" alt="image" src="https://github.com/user-attachments/assets/0aee50f6-61ca-4cf1-bd0d-8cc729c62d3a" />

```python
y.shape
```
<img width="47" height="28" alt="image" src="https://github.com/user-attachments/assets/df33516d-28e8-4f52-b726-46c220cdf2ae" />

# train-test split

```python
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state=42)
```
```python
56 * 0.25
```
<img width="47" height="29" alt="image" src="https://github.com/user-attachments/assets/bbba17e3-efce-46b7-af2a-441d8efafd21" />

```python
X_train.shape, X_test.shape, y_train.shape, y_test.shape   # X_train.shape -> 56 * 0.75
```
<img width="237" height="28" alt="image" src="https://github.com/user-attachments/assets/65e38707-34cb-4b29-a702-640d726aa37f" />

```python
# y(Weight) ~ X(Length) 산점도 시각화. 훈련 셋/테스트 셋 구분.
plt.scatter(X_train, y_train, label = 'train', alpha = 0.4)
plt.scatter(X_test, y_test, label = 'test', alpha = 0.4)

plt.legend()
plt.grid()
plt.title('Perch')
plt.xlabel('Length (cm)')
plt.ylabel('Weight (g)')
plt.show()
```
<img width="580" height="455" alt="image" src="https://github.com/user-attachments/assets/9808dc48-2232-46be-afb2-f716f949ddd2" />

# KNN 모델 훈련, 평가

KNN(K-Nearest Neighbors) Regressor: 가장 가까운 k개의 이웃들의 레이블(타겟) 평균 값으로 숫자를 예측하는 모델.

```python
knn = KNeighborsRegressor()
```
```python
knn.fit(X_train, y_train)    # knn은 지도학습이기 때문에 레이블이 반드시 필요. X_train 길이, y_train 무게
```
<img width="225" height="69" alt="image" src="https://github.com/user-attachments/assets/9596f7fd-1cfc-4846-bc03-e4d807be9089" />

```python
train_pred = knn.predic(X_train)    # 훈련 셋의 예측값 - 예측한 무게
```
```python
train_pred
```
<img width="505" height="108" alt="image" src="https://github.com/user-attachments/assets/3f4b49d7-fdb4-446e-ab44-4bb8b229bd36" />

```python
y_train    # 실젯값 - 실제 무게
```
<img width="504" height="93" alt="image" src="https://github.com/user-attachments/assets/4558c115-8e33-4710-8f12-f7abb3bb21b8" />

```python
test_pred = knn.predict(X_test)    # 테스트 셋의 예측값
```
```python
test_pred
```
<img width="508" height="47" alt="image" src="https://github.com/user-attachments/assets/88b69bd0-44cc-46e7-a6c7-3e1281a024f7" />

```python
y_test    # 테스트 셋의 실젯값
```
<img width="505" height="47" alt="image" src="https://github.com/user-attachments/assets/34887f84-7c73-4097-b0e6-b3c2000901d1" />

# 회귀 모델의 평가 지표(metrics)

*   MSE(Mean Squared Errors): 오차들의 제곱의 평균.
*   RMSE(Root Mean Squared Errors): MSE의 제곱근.
*   MAE(Mean Absolute Errors): 오차들의 절대값의 평균.
*   MSE, RMSE, MAE는 값이 작을 수록 좋은 점수. 값이 클 수록 나쁜 점수!
    *   일반적인 평가지표들은 값이 클 수록 좋은 점수, 값이 작을 수록 나쁜 점수.
    *   회귀 문제에서도 오차들이 작을 수록 점수가 커지는 평가지표를 개발 -> R2 score.

*  $ y_i $ : $i$번째 샘플의 실젯값(label)
*  $ \hat{y_i} $ : $i$번째 샘플의 예측값
*  $ \bar{y} $ : 타겟의 평균값
*  $ n $ : 샘플 개수

* MAE(Mean Absolute Errors)
$$
MAE = \frac{1}{n} \sum_{i=1}^{n} \lvert y_i - \hat{y_i} \rvert
$$

* MSE(Mean Squared Errors)
$$
MSE = \frac{1}{n} \sum_{i=1}^{n} ( y_i - \hat{y_i} )^2
$$

* RMSE(Root Mean Squared Errors)
$$
RMSE = \sqrt{ \frac{1}{n} \sum_{i=1}^{n} ( y_i - \hat{y_i} )^2 }
$$

* $ R^2 $ score(Coefficient of determinant, 결정 계수)
$$
R^2 = 1 - \dfrac{\text{MSE}}{\text{Variance}}
    = 1 - \dfrac{ \sum_{i=1}^{n} (y_i - \hat{y_i})^2 }
                { \sum_{i=1}^{n} (y_i - \bar{y})^2 }
$$
    * 결정 계수는 최댓값이 1이 되도록 만든 평가 지표.
    * 모델이 타겟을 오차없이 정확하게 예측하면, 실제값 - 예측값 = 0 이므로, 결정 계수는 최댓값 1이 됨.
    * 모델이 타겟을 매우 비슷하게 예측하면, 오차가 매우 작으면 분자가 0에 가까운 값이 되므로, 결정 계수는 1보다는 작지만 1에 가까운 값이 됨.
    * 모델이 타겟의 평균으로만 예측하는 정도라면, (분자) = (분모) 이므로, 결정 계수는 0이 됨.
    * 모델이 타겟의 평균 정도도 예측하지 못하면(오차가 매우 크면), (분자) > (분모)일 수 있고, 그런 경우 결정 계수는 음수가 될 수 있음.
 
```python
# 훈련 셋의 MSE
mean_squared_error(y_train, train_pred)
```
<img width="148" height="28" alt="image" src="https://github.com/user-attachments/assets/d7ebf91e-323b-4c6f-a540-699e47b5b2b5" />

```python
# 훈련 셋의 RMSE
np.sqrt(mean_squared_error(y_train, train_pred))
```
<img width="215" height="24" alt="image" src="https://github.com/user-attachments/assets/5f7d168f-8898-4d0a-a0c2-86a7c03bbf1f" />

```python
# 훈련 셋의 MAE
mean_absolute_error(y_train, train_pred)
```
<img width="128" height="25" alt="image" src="https://github.com/user-attachments/assets/38d8f453-5317-4f1c-ba67-be6dcb26b207" />

```python
# 테스트 셋의 MSE
mean_squared_error(y_test, test_pred)
# 샘플 수가 너무 작아서 과소적합
```
<img width="137" height="24" alt="image" src="https://github.com/user-attachments/assets/2b836f65-d2de-452f-bec5-8cc71a721cbf" />

```python
# 테스트 셋의 MAE
mean_absolute_error(y_test, test_pred)
# MSE에서 과소적합이면 MAE에서도 과소적합으로 나옴
```
<img width="139" height="25" alt="image" src="https://github.com/user-attachments/assets/e584b068-08f8-4d80-b3ff-7c88dadf2253" />

테스트 셋에서의 평가 점수가 훈련 셋에서의 평가지표보다 더 좋음 -> 과소적합(underfitting)

```python
# 훈련 셋 결정 계수(r2 score)
r2_score(y_train, train_pred)
# 1에 가까워서 좋은거
```
<img width="145" height="29" alt="image" src="https://github.com/user-attachments/assets/80ac1cbd-f537-4b50-9320-73d2d310c3ed" />

```python
# 테스트 셋 결정 계수
r2_score(y_test, test_pred)
```
<img width="137" height="24" alt="image" src="https://github.com/user-attachments/assets/41e52ad4-80c3-4b2e-91b3-9b5167abbd56" />

# KNN Regressor 문제점

outlier가 있는 경우 오차가 커질 수 있음.

```python
# 훈련 셋 시각화
plt.scatter(X_train, y_train, alpha = 0.5)

# 가상의 물고기(50cm, 1500g)
plt.scatter(50, 1500, color = 'red', marker = 'v')

plt.grid()
plt.show()
```
<img width="533" height="393" alt="image" src="https://github.com/user-attachments/assets/91275c5c-69f0-4972-8470-dc22280977d1" />

```python
# 길이 50cm인 물고기의 무게 예측값.
prediction = knn.predict([[50]])    # 2차원 배열로 줘야함
prediction  # 예측한 값이 1010g
```
<img width="114" height="27" alt="image" src="https://github.com/user-attachments/assets/b371c5ac-bf4a-40fd-9117-dca5f3b7d83a" />

```python
indices = knn.kneighbors([[50]], return_distance=False)
indices     # 가상의 물고기와 가장 가가운 훈련 셋 샘플의 인덱스 5개.
# 훈련셋에서 인덱스 34번이 젤 가깝다, 14번이 두번째 ...
```
<img width="222" height="28" alt="image" src="https://github.com/user-attachments/assets/ad704d2e-56e1-4db0-96fe-c8831d100ae8" />

```python
y_train[indices[0]]     # 가장 가까운 5개 샘플의 레이블(무게)
```
<img width="301" height="23" alt="image" src="https://github.com/user-attachments/assets/978824eb-d879-4895-b99b-2b28b7204b2e" />

머신 러닝의 종류 - 단순하게 알고 있는 데이터 포인트와 새 데이터 포인트를 비교하는 것인 지, 아니면 훈련 셋에서 패턴을 발견(공식 발견)해서 예측 모델을 만드는 지
*   사례 기반 머신러닝(instance-based ML)
    *   수학적인 모델을 만들지 않고, 훈련 셋의 특성들을 이용해서 예측.
    *   outlier들이 많은 경우에는 성능이 떨어질 수 있음.
    *   예: KNN
*   모델 기반 머신러닝(model-based ML)
    *   훈련 셋에서 수학적인 모델을 만들고, 그 수학 모델로 예측.
    *   예: 선형 회귀(Linear Regression)


