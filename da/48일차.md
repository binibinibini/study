# Grid Search Cross Validation

```python
from sklearn.model_selection import GridSearchCV
```
```python
# 파라미터 튜닝을 하려는 ML 모델(예측기) 생성
tree = DecisionTreeClassifier(random_state = 42)
```
```python
# 튜닝할 하이퍼 파라미터들의 조합을 dict로 만듦. 키는 ML 클래스 생성자의 파라미터 이름을 사용.
params = {'max_depth': np.arange(2, 21),
          'min_samples_split': np.arange(2, 100, 2)}
```
```python
# GridSearchCV 객체 생성
grid_cv = GridSearchCV(estimator = tree, param_grid = params, n_jobs = -1)
# GridSearchCV() -> 교차 검증을 통해 가장 성능이 좋은 조합을 자동으로 찾아주는 도구
# estimator -> 사용할 기본 모델, param_grid -> 하이퍼파라미터 후보 값 딕셔너리, n_jobs -> 병렬 처리 설정(-1이면 모든 CPU 사용)
```
```python
# 훈련 -> 5-fold 교차 검증 수행하면서 최적의 파라미터 조합을 찾음.
grid_cv.fit(X_tr_full, y_tr_full)
```
<img width="346" height="157" alt="image" src="https://github.com/user-attachments/assets/550df450-9ce6-41db-a8f7-919947ecc708" />

```python
grid_cv.best_params_    # 교차 검증의 test_score를 최대로 만들어 주는 파라미터 조합(가장 성능이 좋았던 조합을 알려주는 속성)
# 결정 트리의 최대 깊이를 7로 설정했을 때 가장 좋은 성능. 노드를 분할하기 위해 필요한 최소 샘플 수가 84일 때 가장 좋은 성능
```
<img width="439" height="30" alt="image" src="https://github.com/user-attachments/assets/a089c414-6b2a-4c3d-b12c-091cd07b7a4d" />

```python
grid_cv.best_score_    # 교차 검증에서 test_score 최댓값.(최적의 파라미터 조합을 사용했을 때, 교차 검증을 통해 얻은 평균 정확도)
```
<img width="219" height="25" alt="image" src="https://github.com/user-attachments/assets/28b365f8-bf12-4cdc-874b-e16998d8977b" />

```python
grid_cv.best_estimator_
# 가장 성능이 좋았던 모델 자체를 반환
# best_estimator_ : 이미 학습된 모델을 바로 사용할 수 있게 해줌.
```
<img width="567" height="87" alt="image" src="https://github.com/user-attachments/assets/f87c49fb-318f-4b7d-8d64-cc96c0144782" />

```python
best_tree = grid_cv.best_estimator_
best_tree
```
<img width="569" height="89" alt="image" src="https://github.com/user-attachments/assets/c7a56626-8bd1-4f83-9512-773f7ec20c2d" />

```python
best_tree.score(X_test, y_test)
```
<img width="148" height="31" alt="image" src="https://github.com/user-attachments/assets/cd7bc4ed-0c1b-4c68-9326-20470f783678" />


# Random Search Cross Validation

*   Grid Search 교차검증은 파라미터들의 조합을 직접 (dict 타입으로) 만들어서 교차검증을 수행.
*   Random Search 교차검증
    *   파라미터들의 조합을 난수로 샘플링할 수 있도록 확률 분포 객체를 만듦.
    *   교차검증을 수행하는 객체가 파라미터들을 특정 확률 분포를 따르는 난수로 생성해서 교차검증을 수행.
    *   scipy 패키지의 확률분포 함수들을 이용.
 
```python
import scipy
```
```python
int_gen = scipy.stats.randint(0, 10)  # [0, 10) 범위의 정수를 균등 분포로 만들어 주는 객체.
int_gen
```
<img width="520" height="28" alt="image" src="https://github.com/user-attachments/assets/2d241065-7d52-4933-9cf5-4479e17e5ec8" />

```python
numbers = int_gen.rvs(100)  # 난수 발생기로 난수를 100개 생성. rvs:random values
numbers
```
<img width="520" height="93" alt="image" src="https://github.com/user-attachments/assets/6a43133c-a074-41b8-849f-7c2446ed8590" />

```python
np.unique(numbers, return_counts = True)  # 0이 7번, 1이 8번, ...
```
<img width="361" height="45" alt="image" src="https://github.com/user-attachments/assets/c87a07ef-3fd7-4d37-af4d-e53eaa83b889" />

```python
num_gen = scipy.stats.uniform(0, 1)     # [0, 1) 범위의 실수들을 동일한 확률로 생성해 주는 객체.
num_gen
```
<img width="534" height="33" alt="image" src="https://github.com/user-attachments/assets/c604926f-629a-4940-8a75-8ce3dcfc7593" />

```python
numbers = num_gen.rvs(10)
numbers
```
<img width="480" height="45" alt="image" src="https://github.com/user-attachments/assets/29b573a1-9500-47e4-bc5f-6ee9ec58d17a" />

```python
from sklearn.model_selection import RandomizedSearchCV
```
```python
# random search cv에서 사용할 파라미터 조합 - 난수 확률 분포.(몇개가 만들어질지 모름)
params = {'max_depth': scipy.stats.randint(2, 100),
          'min_samples_split': scipy.stats.randint(2, 500),  # 최소 몇개의 샘플이 있어야 하는지(값이 크면 트리가 덜 분할되어 단순해짐)
          'min_samples_leaf': scipy.stats.randint(2, 50),  # 리프 노드에 있어야 할 최소 샘플 수(값이 크면 트리가 더 일반화되고 과적합을 방지할 수 있음)
          'min_impurity_decrease': scipy.stats.uniform(0.0001, 0.001)}   # 분할을 위한 최소 불순도 감소량(값이 작을수록 더 많은 분할이 허용됨.)
```
```python
tree = DecisionTreeClassifier(random_state = 42)
```
```python
rand_cv = RandomizedSearchCV(estimator=tree,  # 사용할 기본 모델 지정(tree = DecisionTreeClassifier())
                             param_distributions=params,    # 파라미터들의 확률 분포
                             n_iter = 100,      # 파라미터들의 조합 갯수(100개의 하이퍼파라미터 조합을 무작위로 선택해서 평가. GridSearchCV는 모든 조합을 평가, RandomizedSearchCV는 일부만 시도)
                             n_jobs=-1,     
                             random_state=42)
# RandomizedSearchCV() 얘가 알아서 조합해줌
```
```python
rand_cv.fit(X_tr_full, y_tr_full)   # 교차검증으로 최적의 파라미터 조합을 찾음.
```
<img width="348" height="164" alt="image" src="https://github.com/user-attachments/assets/a3755da5-748c-45f5-bc97-43c9b2a62a47" />

```python
rand_cv.best_params_  # 제일 좋은거 출력
```
<img width="444" height="87" alt="image" src="https://github.com/user-attachments/assets/905d410e-35f3-4902-b844-4379ab9d7091" />

```python
rand_cv.best_score_    # 위의 조합으로한 best_score_
```
<img width="226" height="30" alt="image" src="https://github.com/user-attachments/assets/774e0614-131a-4a14-9150-130112dc704e" />

# Decision Tree Regressor


결정 나무 알고리즘을 사용한 회귀 모델(숫자 예측).


```python
from sklearn.tree import DecisionTreeRegressor
from sklearn.metrics import r2_score, mean_squared_error
from sklearn.preprocessing import PolynomialFeatures, StandardScaler
from sklearn.pipeline import Pipeline
```

# 데이터셋 준비
```python
fish_csv = 'https://github.com/JakeOh/202505_BD50/raw/refs/heads/main/datasets/fish.csv'
```
```python
fish_df = fish_csv(fish_csv)
```
```python
fish_df.head()
```
<img width="435" height="199" alt="image" src="https://github.com/user-attachments/assets/be32abb1-2e72-4b3e-bcca-899807635263" />


농어(Perch)의 무게를 다른 특성들(Length, Diagonal, Height, Width)로 예측.


```python
perch = fish_df[fish_df.Species == 'Perch']
```
```python
X = perch.iloc[:, 2:].values    # 특성 배열
y = perch.Weight    # 타겟 배열
```
```python
# 훈련 셋/테스트 셋 나누기
X_tr_full, X_te, y_tr_full, y_te = train_test_split(X, y, test_size = 0.25, random_state=42)
```
```python
X_tr.shape  # 31마리로 트리 만들기
```
<img width="65" height="28" alt="image" src="https://github.com/user-attachments/assets/3f721474-ed76-4e19-afa1-84019d6b3411" />

```python
X_val.shape
```
<img width="72" height="34" alt="image" src="https://github.com/user-attachments/assets/1a467d84-aaf6-485c-be63-32e59f0b0467" />

## Decision Tree 훈련

```python
# Decision Tree 객체 생성
tree_reg = DecisionTreeRegressor(random_state = 42)    # DecisionTreeRegressor() : 숫자 예측
```
```python
tree_reg.fit(X_tr, y_tr)
```
<img width="291" height="78" alt="image" src="https://github.com/user-attachments/assets/609424e0-f156-4adb-b232-5f5dd487f395" />

```python
plot_tree(tree_reg)
plt.show()
```
<img width="553" height="388" alt="image" src="https://github.com/user-attachments/assets/d4b0b2c5-37ac-4fe6-804a-0c422924582b" />

```python
# 위에 그래프 크게 보기
plt.figure(figsize = (16, 8))
plot_tree(tree_reg, max_depth = 2, feature_names = perch.columns[2:])  # 여기서 max_depth는 깊이 2까지만 보여줌
plt.show()
# 첫번째는 Length로 나눔. 전체 31마리, value는 31마리(노드에 속한 물고기 수) 무게 평균. squared error = MSE
```
<img width="1299" height="607" alt="image" src="https://github.com/user-attachments/assets/e308ed72-6051-4add-bb17-870ae3e51ed7" />

```python
np.mean(y_tr)   # 각 노드의 value는 그 노드에 포함된 샘플의 평균.(훈련 데이터 전체의 평균 타깃 값)
```
<img width="222" height="26" alt="image" src="https://github.com/user-attachments/assets/576001b3-187c-41c0-bc43-a555048b3023" />

```python
print('train score:', tree_reg.score(X_tr, y_tr))
print('validation score:', tree_reg.score(X_val, y_val))
```
<img width="273" height="44" alt="image" src="https://github.com/user-attachments/assets/1e1601cf-a74a-4e0a-b643-2ba36c03a879" />


Decision Tree는 과대적합이 심함.


## cross_validate() 함수를 사용해서 최적의 max_depth를 찾아보세요.

```python
depths = np.arange(2, 10)   # Decision Tree에서 테스트할 max_depth들
train_scores = []   # 교차 검증에 계산된 훈련 셋 점수(들의 평균)을 저장
val_scores = []     # 교차 검증에서 계산된 테스트 셋 점수(들의 평균)을 저장
for d in depths:
    reg = DecisionTreeRegressor(max_depth = d, random_state=42)
    cv = cross_validate(estimator=reg, X = X_tr_full, y = y_tr_full, 
                        cv = 5, n_jobs=-1, return_train_score=True)          # cv -> 데이터를 5등분해서 5번 평가, return_train_score=True ->훈련 점수도 함께 반환

    train_scores.append(np.mean(cv['train_score']))   # return_train_score=True이게 있어야 cv['train_score']가 실행 가능
    val_scores.append(np.mean(cv['test_score']))

print(train_scores)
print(val_scores)
```
```
결과
[np.float64(0.9685903554980261), np.float64(0.9934290771426412), np.float64(0.998899697772964), np.float64(0.9998826458263576), np.float64(0.9999698194541387), np.float64(0.99999878447581), np.float64(1.0), np.float64(1.0)]
[np.float64(0.9177278634402615), np.float64(0.9531203941305982), np.float64(0.9434072226786077), np.float64(0.923513957039156), np.float64(0.9655899177591556), np.float64(0.9397846070006051), np.float64(0.9070082050390672), np.float64(0.9070082050390672)]
```
```python
plt.plot(depths, train_scores, 'bo-', label = 'train')
plt.plot(depths, val_scores, 'r^:', label = 'validataion')
plt.legend()
plt.grid()
plt.xlabel('Tree Depth')
plt.ylabel('$R^2 score$')
plt.show()
```
<img width="595" height="427" alt="image" src="https://github.com/user-attachments/assets/5e899703-54f3-4a44-af33-cfb11ac473f0" />

6이 제일 좋음(과대 적합이 젤 적은거)

```python
best_score_index = np.argmax(val_scores)    # val_scores에서 최대값의 인덱스
depths[best_score_index]    # val_scores가 최대인 max_depth.
```
<img width="91" height="25" alt="image" src="https://github.com/user-attachments/assets/232c73cc-45ef-43c8-943b-c668ab6b014b" />

```
DecisionTreeRegressor : 회귀 모델 생성. 출력은 예측값
cross_validate : 모델 성능 평가(교차 검증). 출력은 점수, 시간, 훈련/검증 성능
```

## GridSearchCV 클래스를 사용해서 최적의 max_depth를 찾아보세요.

```python
grid_cv = GridSearchCV(estimator = DecisionTreeRegressor(random_state = 42),
                       param_grid = {'max_depth': np.arange(2, 10)},
                       cv = 5, n_jobs = -1)
```
```python
grid_cv.fit(X_tr_full, y_tr_full)
```
<img width="338" height="159" alt="image" src="https://github.com/user-attachments/assets/03474750-6014-4a06-a319-2945d0747158" />

```python
grid_cv.best_params_
```
<img width="195" height="34" alt="image" src="https://github.com/user-attachments/assets/790adeb5-865a-42fb-bb4a-a2b6cbd3f754" />

```python
grid_cv.best_score_
```
<img width="224" height="44" alt="image" src="https://github.com/user-attachments/assets/d931dec4-b688-4b2f-a1c5-8fb6f5cac852" />

# Pipeline과 GridSearchCV

*   PolynomialFeatures, StandardScaler, LinearRegression/ElasticNet
*   GridSearchCV를 사용해서 하이퍼 파라미터들을 튜닝
    *   PolynomialFeatures: degree
    *   ElansticNet: 규제의 크기

```python
from sklearn.preprocessing import PolynomialFeatures, StandardScaler
from sklearn.pipeline import Pipeline
from sklearn.linear_model import LinearRegression, ElasticNet
```
```python
X_tr_full[:5, :]
```
<img width="326" height="93" alt="image" src="https://github.com/user-attachments/assets/3e69f5cb-2a35-4913-847a-63a3799893b3" />

```python
# 교차 검증에서 사용할 ML
model = Pipeline(steps = [('poly', PolynomialFeatures(include_bias = False)),
                          ('scaler', StandardScaler()),
                          ('reg', LinearRegression())])
```
```python
# ML 모델의 파라미터 조합
# param의 키 이름: step_name__param_name
params = {'poly__degree': np.arange(1, 50)}
```
```python
# GridSearchCV 객체 생성
grid_cv = GridSearchCV(estimator = model, param_grid = params, n_jobs = -1)
```
```python
grid_cv.fit(X_tr_full, y_tr_full)
```
<img width="260" height="203" alt="image" src="https://github.com/user-attachments/assets/9765919f-de28-4d4c-ad01-37fc03080282" />

```python
grid_cv.best_params_      # 2차함수가 제일 좋음
```
<img width="220" height="29" alt="image" src="https://github.com/user-attachments/assets/e2bdc397-6c00-4999-b4a3-6920059fb890" />

```python
grid_cv.best_score_
```
<img width="225" height="33" alt="image" src="https://github.com/user-attachments/assets/a27e34c1-5f01-4448-bdf1-b4d466e8aa87" />

## ElasticNet

```python
model = Pipeline(steps = [('poly', PolynomialFeatures(include_bias = False)),
                          ('scaler', StandardScaler()),
                          ('reg', ElasticNet(random_state = 42))])
```
```python
params = {'poly__degree': np.arange(1, 11),
          'reg__alpha': [0.0001, 0.001, 0.01, 0.1, 1],     # 규제 크기(작을수록 규제가 약함 -> 더 복잡한 모델 가능)
          'reg__l1_ratio': np.arange(0.1, 1.0, 0.1)}       # 0.1부터 0.9까지 단계별로 테스트
```
```python
grid_cv = GridSearchCV(estimator = model, param_grid = params, n_jobs = -1)
```
```python
grid_cv.fit(X_tr_full, y_tr_full)
```
<img width="252" height="204" alt="image" src="https://github.com/user-attachments/assets/57a77770-0a42-4cd0-9dd9-2948c1cde689" />

```python
grid_cv.best_params_
```
<img width="260" height="59" alt="image" src="https://github.com/user-attachments/assets/68ae6d39-2e7f-4592-b410-6c3a8cfca85b" />

```python
grid_cv.best_score_
```
<img width="218" height="27" alt="image" src="https://github.com/user-attachments/assets/4a9f168b-40a5-4020-af59-7c7a25292fa1" />


분류(acc) -> 다수결(최빈값)
회귀(r^2) -> 평균

------

# Ensemble Learning(앙상블 학습방법)

*   앙상블(ensemble): ML에서 사용되는 일련의 모델(알고리즘)들.
    *   서로 다른 모델(알고리즘) 여러 개를 학습시키는 방법.
    *   한 가지 모델을 서로 다른 훈련 셋으로 학습시키는 방법.
*   앙상블 학습방법: 앙상블을 사용한 학습방법.
    *   투표(voting) 방식: 여러 개의 모델들을 학습시킨 후, 각각의 모델들의 예측값을 투표로 결정하는 방식.(분류인 경우는 다수결, 회귀는 평균으로 계산)
    *   __Bagging(Bootstrap Aggregating)__: __중복을 허용__해서 샘플링한 훈련 셋의 부분집합들을 하나의 알고리즘에 학습시켜서 예측(최빈값, 평균)하는 방법.
    *   Pasting: 중복을 허용하지 않고 샘플링한 훈련 셋의 부분집합들을 알고리즘에 학습시켜서 예측하는 방법.
    *   __Boosting__: 약한 학습기(weak learner)를 순차적으로 연결해서 강한 학습기(strong learner)를 만드는 앙상블 학습방법.
        *   AdaBoost(Adpative Boosting): 과소적합됐던 훈련 샘플들의 가중치를 높여서 그 다음 학습에서 사용하는 boosting 방법.
        *   Gradient Boosting: 잔여 오차(residual errors)들을 다음 훈련에서 학습시키는 boosting 방법.
*   __Random Forest__: Bagging을 사용한 Decision Tree들의 앙상블 학습방법.


bagging(Random Forest)과 boosting 많이 사용



<img width="922" height="459" alt="image" src="https://github.com/user-attachments/assets/b6bcda46-c046-4b75-85d0-3cf6b0611fa2" />


Bagging : 중복을 허용해서 샘플들을 모으는거
bootstrap(즉, Bagging)을 많이 사용
무작위로 뽑아서 병렬로 훈련


Random Forest
Bagging을 사용하는 Decision Tree(의사결정 나무)를 사용하는 앙상블 학습 방법.


<img width="918" height="489" alt="image" src="https://github.com/user-attachments/assets/a6baccf1-003d-4447-b6af-a866b5a8c873" />


예측이 틀렸던 값들을 가중치로 둬서 더 많이 훈련할 수 있도록 함. 순차적으로 훈련시킴


<img width="890" height="493" alt="image" src="https://github.com/user-attachments/assets/3d5a3055-586d-48cd-b3a0-fb55f1e2307a" />


파란점과 초록색 선 사이가 오차들.
오차들에 가중치를 줘서
오차들을 학습 시킴
두개의 곡선 합쳐줌
가장 대표적인게 XGBoost


# imports

```python
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

from sklearn import datasets
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.linear_model import LogisticRegression, SGDClassifier
from sklearn.svm import SVC
from sklearn.ensemble import VotingClassifier, BaggingClassifier, RandomForestClassifier, GradientBoostingClassifier
```

# Datasets 준비


2개의 특성(x1, x2)과 2개 클래스(0, 1)를 갖는 가상의 데이터셋을 만들고 사용.


```python
# X: 특성 배열, y: 타겟 배열
X, y = datasets.make_moons(n_samples = 500, random_state = 42, noise = 0.3)
# make_moons() : 두개의 반달 모양 데이터를 만들어주는 함수(이진 분류 문제에서 사용)
# noise = 0.3 : 데이터에 노이즈 추가(모델이 더 현실적인 조건에서 학습하기 위해서)
```
```python
X.shape
```
<img width="74" height="34" alt="image" src="https://github.com/user-attachments/assets/9368c8a7-40aa-451c-b25f-2c06db6a572b" />

```python
y.shape
```
<img width="57" height="31" alt="image" src="https://github.com/user-attachments/assets/f1e715b0-a790-49e4-955a-52865b8f6b9b" />

```python
np.unique(y, return_counts = True)
```
<img width="257" height="30" alt="image" src="https://github.com/user-attachments/assets/e1c23d60-109f-44be-9a7c-aeb86ea251c9" />


특성 배열을 타겟에 따라서 다른 색깔로 시각화


```python
y == 0
```
```
array([False,  True, False,  True,  True, False, False,  True,  True,
       False,  True,  True, False,  True, False, False, False,  True,
       False, False, False, False, False, False,  True, False, False,
        True,  True, False, False, False, False,  True,  True, False,
       False,  True,  True,  True, False,  True, False,  True,  True,
        True,  True,  True, False,  True,  True,  True,  True, False,
        True,  True,  True,  True,  True,  True, False, False, False,
       False,  True,  True, False,  True,  True, False, False, False,
       False, False, False, False, False,  True, False, False,  True,
        True, False,  True, False,  True,  True, False, False, False,
       False, False, False, False, False, False,  True,  True, False,
        True,  True, False,  True, False, False,  True, False,  True,
       False,  True,  True, False, False,  True, False, False,  True,
        True,  True,  True,  True,  True, False,  True,  True,  True,
       False,  True,  True, False,  True,  True, False, False,  True,
        True,  True,  True,  True, False,  True,  True, False,  True,
       False, False,  True,  True, False, False,  True,  True,  True,
        True, False, False,  True,  True, False,  True,  True, False,
       False,  True, False, False,  True,  True, False,  True,  True,
        True, False,  True,  True,  True, False,  True,  True, False,
       False,  True, False, False, False,  True, False,  True,  True,
        True, False, False, False, False,  True,  True,  True,  True,
        True, False, False,  True,  True,  True,  True,  True,  True,
        True, False, False, False,  True, False, False, False, False,
       False,  True, False,  True, False, False,  True,  True,  True,
       False,  True, False, False,  True,  True,  True, False,  True,
       False, False, False,  True,  True,  True, False,  True, False,
        True, False,  True,  True,  True, False,  True, False, False,
       False,  True, False, False,  True, False,  True, False, False,
        True, False,  True,  True,  True, False,  True, False,  True,
        True,  True,  True, False, False, False, False, False, False,
        True, False,  True, False,  True,  True, False, False, False,
       False, False, False, False, False, False,  True,  True, False,
       False, False, False, False,  True, False,  True,  True,  True,
       False,  True,  True,  True, False,  True, False, False,  True,
       False, False,  True, False, False,  True, False,  True, False,
        True, False,  True,  True,  True, False,  True,  True,  True,
        True,  True,  True, False, False,  True,  True,  True,  True,
       False, False,  True,  True, False, False,  True, False, False,
       False,  True, False, False,  True,  True, False,  True,  True,
        True, False,  True,  True,  True,  True, False, False,  True,
       False,  True, False,  True, False, False,  True, False,  True,
        True,  True,  True, False,  True, False, False,  True, False,
        True,  True,  True, False, False, False,  True, False, False,
       False, False,  True,  True,  True, False, False, False, False,
       False, False, False, False,  True,  True,  True,  True, False,
        True, False, False,  True,  True, False,  True, False, False,
        True, False,  True,  True,  True, False, False, False,  True,
       False, False,  True, False, False,  True,  True, False,  True,
       False, False,  True, False, False,  True, False, False, False,
        True,  True, False,  True, False,  True, False,  True, False,
        True,  True,  True,  True, False,  True, False,  True, False,
       False,  True, False, False,  True, False, False, False, False,
       False, False,  True,  True,  True, False,  True, False,  True,
       False, False,  True, False,  True, False,  True,  True,  True,
        True, False, False, False,  True])
```
```python
plt.scatter(X[y == 0, 0], X[y == 0, 1], label = 'class-0', alpha = 0.5)
plt.scatter(X[y == 1, 0], X[y == 1, 1], label = 'class-1', alpha = 0.5)

plt.grid()
plt.legend()
plt.xlabel('x1')
plt.ylabel('x2')
plt.show()
```
<img width="530" height="386" alt="image" src="https://github.com/user-attachments/assets/d42dd0ba-afbb-421c-8740-ace22603111d" />

```python
# 훈련/테스트 나누기
X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size = 0.2, random_state = 42, stratify = y)
```

# 머신 러닝 모델의 성능 비교

*   5개의 ML 모델 생성
    *   KNN, Decision Tree, Logistic Regression, SGD, SVM 기본 생성자
        *   SGDclassifier의 파라미터 중에서 loss = 'log_loss' 사용.
        *   SVC의 파라미터 중에서 probability = True 사용
*   5개의 모델을 각각 훈련 셋으로 학습시킴
*   5개 모델의 점수(score -> 정확도)를 훈련/테스트 셋에서 계산, 출력.

```python
knn = KNeighborsClassifier(n_jobs = -1)
tree = DecisionTreeClassifier(random_state = 42)
logistic = LogisticRegression(random_state = 42, n_jobs = -1)
sgd = SGDClassifier(loss = 'log_loss', random_state = 42, n_jobs = -1)
# loss = 'log_loss'로 설정한 이유: 각 클래스가 될 확률을 계산하기 위해서
svm = SVC(probability=True, random_state=42)
# probability = True 설정 이유: 각 클래스가 될 확률을 계산하기 위해서
```
```python
classifiers = [knn, tree, logistic, sgd, svm]
for clf in classifiers:
    clf.fit(X_tr, y_tr)     # 모델 훈련
    train_score = clf.score(X_tr, y_tr)     # 훈련셋의 정확도
    test_score = clf.score(X_te, y_te)
    print(f'{clf.__class__.__name__}: train score = {train_score}, test score = {test_score}')
```
<img width="436" height="89" alt="image" src="https://github.com/user-attachments/assets/50614cce-9ffc-4bc9-a93b-e0a4db7d7a1e" />


DecisionTreeClassifier은 과적합이 심하다. test score에서 점수가 낮아서
knn, SVCsms test score의 점수가 좋음


# Voting Ensemble

```python
vote_clf = VotingClassifier(estimators = [('knn', knn),
                                          ('tree', tree),
                                          ('logistic', logistic),
                                          ('sgd', sgd),
                                          ('svm', svm)],
                            voting = 'soft',
                            n_jobs = -1)
# estimators: 앙상블을 만들기 위한 예측기(ML 모델)들의 리스트.
#   ('name', estimator) 튜플들의 리스트로 전달.
# voting = 'hard': 기본값. 단순한 다수결. 각 모델에서 예측 확률을 계산할 필요가 없음.
# voting = 'soft': 각 모델의 예측값에 예측 확률을 가중치로 곱한 값을 사용해서 최종 결과를 예측.
# 일반적으로 soft voting 방식이 성능이 더 좋다고 알려져 있음.
```
```python
vote_clf.fit(X_tr, y_tr)
```
<img width="976" height="122" alt="image" src="https://github.com/user-attachments/assets/dfb1486c-d826-4ddd-9032-47986ccb2d53" />

```python
print('train score =', vote_clf.score(X_tr, y_tr))
print('test score =', vote_clf.score(X_te, y_te))
```
<img width="149" height="43" alt="image" src="https://github.com/user-attachments/assets/7efbb360-52f0-4fbe-bb75-132b3c580189" />
