# Grid Search Cross Validation

```python
from sklearn.model_selection import GridSearchCV
```
```python
# 파라미터 튜닝을 하려는 ML 모델(예측기) 생성
tree = DecisionTreeClassifier(random_state = 42)
```
```python
# 튜닝할 하이퍼 파라미터들의 조합을 dict로 만듦. 키는 ML 클래스 생성자의 파라미터 이름을 사용.
params = {'max_depth': np.arange(2, 21),
          'min_samples_split': np.arange(2, 100, 2)}
```
```python
# GridSearchCV 객체 생성
grid_cv = GridSearchCV(estimator = tree, param_grid = params, n_jobs = -1)
# GridSearchCV() -> 교차 검증을 통해 가장 성능이 좋은 조합을 자동으로 찾아주는 도구
# estimator -> 사용할 기본 모델, param_grid -> 하이퍼파라미터 후보 값 딕셔너리, n_jobs -> 병렬 처리 설정(-1이면 모든 CPU 사용)
```
```python
# 훈련 -> 5-fold 교차 검증 수행하면서 최적의 파라미터 조합을 찾음.
grid_cv.fit(X_tr_full, y_tr_full)
```
<img width="346" height="157" alt="image" src="https://github.com/user-attachments/assets/550df450-9ce6-41db-a8f7-919947ecc708" />

```python
grid_cv.best_params_    # 교차 검증의 test_score를 최대로 만들어 주는 파라미터 조합(가장 성능이 좋았던 조합을 알려주는 속성)
# 결정 트리의 최대 깊이를 7로 설정했을 때 가장 좋은 성능. 노드를 분할하기 위해 필요한 최소 샘플 수가 84일 때 가장 좋은 성능
```
<img width="439" height="30" alt="image" src="https://github.com/user-attachments/assets/a089c414-6b2a-4c3d-b12c-091cd07b7a4d" />

```python
grid_cv.best_score_    # 교차 검증에서 test_score 최댓값.(최적의 파라미터 조합을 사용했을 때, 교차 검증을 통해 얻은 평균 정확도)
```
<img width="219" height="25" alt="image" src="https://github.com/user-attachments/assets/28b365f8-bf12-4cdc-874b-e16998d8977b" />

```python
grid_cv.best_estimator_
# 가장 성능이 좋았던 모델 자체를 반환
# best_estimator_ : 이미 학습된 모델을 바로 사용할 수 있게 해줌.
```
<img width="567" height="87" alt="image" src="https://github.com/user-attachments/assets/f87c49fb-318f-4b7d-8d64-cc96c0144782" />

```python
best_tree = grid_cv.best_estimator_
best_tree
```
<img width="569" height="89" alt="image" src="https://github.com/user-attachments/assets/c7a56626-8bd1-4f83-9512-773f7ec20c2d" />

```python
best_tree.score(X_test, y_test)
```
<img width="148" height="31" alt="image" src="https://github.com/user-attachments/assets/cd7bc4ed-0c1b-4c68-9326-20470f783678" />


# Random Search Cross Validation

*   Grid Search 교차검증은 파라미터들의 조합을 직접 (dict 타입으로) 만들어서 교차검증을 수행.
*   Random Search 교차검증
    *   파라미터들의 조합을 난수로 샘플링할 수 있도록 확률 분포 객체를 만듦.
    *   교차검증을 수행하는 객체가 파라미터들을 특정 확률 분포를 따르는 난수로 생성해서 교차검증을 수행.
    *   scipy 패키지의 확률분포 함수들을 이용.
 
```python
import scipy
```
```python
int_gen = scipy.stats.randint(0, 10)  # [0, 10) 범위의 정수를 균등 분포로 만들어 주는 객체.
int_gen
```
<img width="520" height="28" alt="image" src="https://github.com/user-attachments/assets/2d241065-7d52-4933-9cf5-4479e17e5ec8" />

```python
numbers = int_gen.rvs(100)  # 난수 발생기로 난수를 100개 생성. rvs:random values
numbers
```
<img width="520" height="93" alt="image" src="https://github.com/user-attachments/assets/6a43133c-a074-41b8-849f-7c2446ed8590" />

```python
np.unique(numbers, return_counts = True)  # 0이 7번, 1이 8번, ...
```
<img width="361" height="45" alt="image" src="https://github.com/user-attachments/assets/c87a07ef-3fd7-4d37-af4d-e53eaa83b889" />

```python
num_gen = scipy.stats.uniform(0, 1)     # [0, 1) 범위의 실수들을 동일한 확률로 생성해 주는 객체.
num_gen
```
<img width="534" height="33" alt="image" src="https://github.com/user-attachments/assets/c604926f-629a-4940-8a75-8ce3dcfc7593" />

```python
numbers = num_gen.rvs(10)
numbers
```
<img width="480" height="45" alt="image" src="https://github.com/user-attachments/assets/29b573a1-9500-47e4-bc5f-6ee9ec58d17a" />

```python
from sklearn.model_selection import RandomizedSearchCV
```
```python
# random search cv에서 사용할 파라미터 조합 - 난수 확률 분포.(몇개가 만들어질지 모름)
params = {'max_depth': scipy.stats.randint(2, 100),
          'min_samples_split': scipy.stats.randint(2, 500),  # 최소 몇개의 샘플이 있어야 하는지(값이 크면 트리가 덜 분할되어 단순해짐)
          'min_samples_leaf': scipy.stats.randint(2, 50),  # 리프 노드에 있어야 할 최소 샘플 수(값이 크면 트리가 더 일반화되고 과적합을 방지할 수 있음)
          'min_impurity_decrease': scipy.stats.uniform(0.0001, 0.001)}   # 분할을 위한 최소 불순도 감소량(값이 작을수록 더 많은 분할이 허용됨.)
```
```python
tree = DecisionTreeClassifier(random_state = 42)
```
```python
rand_cv = RandomizedSearchCV(estimator=tree,  # 사용할 기본 모델 지정(tree = DecisionTreeClassifier())
                             param_distributions=params,    # 파라미터들의 확률 분포
                             n_iter = 100,      # 파라미터들의 조합 갯수(100개의 하이퍼파라미터 조합을 무작위로 선택해서 평가. GridSearchCV는 모든 조합을 평가, RandomizedSearchCV는 일부만 시도)
                             n_jobs=-1,     
                             random_state=42)
# RandomizedSearchCV() 얘가 알아서 조합해줌
```
```python
rand_cv.fit(X_tr_full, y_tr_full)   # 교차검증으로 최적의 파라미터 조합을 찾음.
```
<img width="348" height="164" alt="image" src="https://github.com/user-attachments/assets/a3755da5-748c-45f5-bc97-43c9b2a62a47" />

```python
rand_cv.best_params_  # 제일 좋은거 출력
```
<img width="444" height="87" alt="image" src="https://github.com/user-attachments/assets/905d410e-35f3-4902-b844-4379ab9d7091" />

```python
rand_cv.best_score_    # 위의 조합으로한 best_score_
```
<img width="226" height="30" alt="image" src="https://github.com/user-attachments/assets/774e0614-131a-4a14-9150-130112dc704e" />

# Decision Tree Regressor


결정 나무 알고리즘을 사용한 회귀 모델(숫자 예측).


```python
from sklearn.tree import DecisionTreeRegressor
from sklearn.metrics import r2_score, mean_squared_error
from sklearn.preprocessing import PolynomialFeatures, StandardScaler
from sklearn.pipeline import Pipeline
```

# 데이터셋 준비
```python
fish_csv = 'https://github.com/JakeOh/202505_BD50/raw/refs/heads/main/datasets/fish.csv'
```
```python
fish_df = fish_csv(fish_csv)
```
```python
fish_df.head()
```
<img width="435" height="199" alt="image" src="https://github.com/user-attachments/assets/be32abb1-2e72-4b3e-bcca-899807635263" />


농어(Perch)의 무게를 다른 특성들(Length, Diagonal, Height, Width)로 예측.


```python
perch = fish_df[fish_df.Species == 'Perch']
```
```python
X = perch.iloc[:, 2:].values    # 특성 배열
y = perch.Weight    # 타겟 배열
```
```python
# 훈련 셋/테스트 셋 나누기
X_tr_full, X_te, y_tr_full, y_te = train_test_split(X, y, test_size = 0.25, random_state=42)
```
```python
X_tr.shape  # 31마리로 트리 만들기
```
<img width="65" height="28" alt="image" src="https://github.com/user-attachments/assets/3f721474-ed76-4e19-afa1-84019d6b3411" />

```python
X_val.shape
```
<img width="72" height="34" alt="image" src="https://github.com/user-attachments/assets/1a467d84-aaf6-485c-be63-32e59f0b0467" />

## Decision Tree 훈련

```python
# Decision Tree 객체 생성
tree_reg = DecisionTreeRegressor(random_state = 42)    # DecisionTreeRegressor() : 숫자 예측
```
```python
tree_reg.fit(X_tr, y_tr)
```
<img width="291" height="78" alt="image" src="https://github.com/user-attachments/assets/609424e0-f156-4adb-b232-5f5dd487f395" />

```python
plot_tree(tree_reg)
plt.show()
```
<img width="553" height="388" alt="image" src="https://github.com/user-attachments/assets/d4b0b2c5-37ac-4fe6-804a-0c422924582b" />

```python
# 위에 그래프 크게 보기
plt.figure(figsize = (16, 8))
plot_tree(tree_reg, max_depth = 2, feature_names = perch.columns[2:])  # 여기서 max_depth는 깊이 2까지만 보여줌
plt.show()
# 첫번째는 Length로 나눔. 전체 31마리, value는 31마리(노드에 속한 물고기 수) 무게 평균. squared error = MSE
```
<img width="1299" height="607" alt="image" src="https://github.com/user-attachments/assets/e308ed72-6051-4add-bb17-870ae3e51ed7" />

```python
np.mean(y_tr)   # 각 노드의 value는 그 노드에 포함된 샘플의 평균.(훈련 데이터 전체의 평균 타깃 값)
```
<img width="222" height="26" alt="image" src="https://github.com/user-attachments/assets/576001b3-187c-41c0-bc43-a555048b3023" />

```python
print('train score:', tree_reg.score(X_tr, y_tr))
print('validation score:', tree_reg.score(X_val, y_val))
```
<img width="273" height="44" alt="image" src="https://github.com/user-attachments/assets/1e1601cf-a74a-4e0a-b643-2ba36c03a879" />


Decision Tree는 과대적합이 심함.


## cross_validate() 함수를 사용해서 최적의 max_depth를 찾아보세요.

```python
depths = np.arange(2, 10)   # Decision Tree에서 테스트할 max_depth들
train_scores = []   # 교차 검증에 계산된 훈련 셋 점수(들의 평균)을 저장
val_scores = []     # 교차 검증에서 계산된 테스트 셋 점수(들의 평균)을 저장
for d in depths:
    reg = DecisionTreeRegressor(max_depth = d, random_state=42)
    cv = cross_validate(estimator=reg, X = X_tr_full, y = y_tr_full, 
                        cv = 5, n_jobs=-1, return_train_score=True)          # cv -> 데이터를 5등분해서 5번 평가

    train_scores.append(np.mean(cv['train_score']))   # return_train_score=True이게 있어야 cv['train_score']가 실행 가능
    val_scores.append(np.mean(cv['test_score']))

print(train_scores)
print(val_scores)
```
```
결과
[np.float64(0.9685903554980261), np.float64(0.9934290771426412), np.float64(0.998899697772964), np.float64(0.9998826458263576), np.float64(0.9999698194541387), np.float64(0.99999878447581), np.float64(1.0), np.float64(1.0)]
[np.float64(0.9177278634402615), np.float64(0.9531203941305982), np.float64(0.9434072226786077), np.float64(0.923513957039156), np.float64(0.9655899177591556), np.float64(0.9397846070006051), np.float64(0.9070082050390672), np.float64(0.9070082050390672)]
```
```python
plt.plot(depths, train_scores, 'bo-', label = 'train')
plt.plot(depths, val_scores, 'r^:', label = 'validataion')
plt.legend()
plt.grid()
plt.xlabel('Tree Depth')
plt.ylabel('$R^2 score$')
plt.show()
```
<img width="595" height="427" alt="image" src="https://github.com/user-attachments/assets/5e899703-54f3-4a44-af33-cfb11ac473f0" />

6이 제일 좋음(과대 적합이 젤 적은거)

```python
best_score_index = np.argmax(val_scores)    # val_scores에서 최대값의 인덱스
depths[best_score_index]    # val_scores가 최대인 max_depth.
```
<img width="91" height="25" alt="image" src="https://github.com/user-attachments/assets/232c73cc-45ef-43c8-943b-c668ab6b014b" />

```
DecisionTreeRegressor : 회귀 모델 생성. 출력은 예측값
cross_validate : 모델 성능 평가(교차 검증). 출력은 점수, 시간, 훈련/검증 성능
```
