### 각 샘플의 길이 분포

각각의 영화 리뷰의 길이(포함된 단어 개수) 분포


```python
review_lengths = pd.Series([len(x) for x in x_train_full])
```
```python
review_lengths.describe()  # 기술 통계량
```
<img width="150" height="290" alt="image" src="https://github.com/user-attachments/assets/b57144b5-6302-47c0-bba0-1bcfedaf119c" />

```python
review_lengths.hist(bins = 20)  # 히스토그램
plt.show()
```
<img width="569" height="413" alt="image" src="https://github.com/user-attachments/assets/377f8eb3-67de-4fc1-a431-619ec6bd7400" />

```python
review_lengths.plot.box()   # outlier가 많은 분포
plt.show()
```
<img width="560" height="394" alt="image" src="https://github.com/user-attachments/assets/285c49a0-afe8-4ca6-93e4-d41b0cbfba54" />


대부분의 리뷰에 사용된 단어의 개수는 300개 미만. 평균(238개)이 중앙값(178개)보다 많이 큰 이유는 사용된 단어의 개수가 매우 많은 리뷰들이 간혹 있기 때문에.

신경망을 훈련시키기 위해서는 모든 샘플들의 길이가 같아야 함.

샘플(영화 리뷰)마다 100개의 단어(토큰)만 사용. 길이가 100 이상인 샘플들은 잘라내고, 길이가 100미만인 샘플들은 0으로 패딩을 추가.


## Data wrangling


(25_000, ) shape의 훈련/테스트 셋을 (25_000, 100) shape으로 변환.


`keras.preprocessing.sequence.pad_sequencs()` 함수의 파라미터:
*   sequences: 변환할 데이터
*   maxlen: 각 샘플의 최대 길이.
*   padding: 샘플의 길이가 maxlen보다 짧을 때 패딩을 넣을 위치. 기본값은 'pre'. 기본값은 패딩(0)을 시퀀스의 앞쪽에 채움.
*   truncating: 샘플의 길이가 maxlen보다 길 때 샘플을 자르는 위치. 기본값은 'pre', 기본값은 시퀀스의 앞쪽을 자름.
*   순환신경망을 사용할 때 padding과 truncating은 모두 'pre' 방식을 선호.


```python
x_train_full_seq = keras.preprocessing.sequence.pad_sequences(sequences = x_train_full, maxlen = 100)
```
```python
x_train_full_seq.shape  # (n_samples, n_tokens)  # (n_samples, n_tokens). 25000개의 리뷰
```
<img width="96" height="30" alt="image" src="https://github.com/user-attachments/assets/f5f24b8e-65a2-44cf-b530-3020e7673bf1" />

```python
x_test_seq = keras.preprocessing.sequence.pad_sequences(sequences = x_test, maxlen = 100)
```
```python
x_test_seq.shape  
```
<img width="97" height="27" alt="image" src="https://github.com/user-attachments/assets/fb874b97-fc76-4f5c-a690-30ca404ba220" />

```python
print(x_train_full_seq[0])  # 100개의 단어
```
<img width="528" height="100" alt="image" src="https://github.com/user-attachments/assets/6d2b3e0b-8cf0-4bd2-9284-283598dbbeb3" />


<img width="445" height="242" alt="image" src="https://github.com/user-attachments/assets/2c97c6cb-bece-4ce2-8d0b-21b925df2837" />

```
원핫 인코딩
```
```python
print(x_train_full[0][-100:])   # 첫번째 샘플의 마지막 100개 토큰.
# truncating = 'pre': 원본 샘플의 앞쪽을 잘라서 버림.
```
```
[2, 33, 6, 22, 12, 2, 28, 77, 52, 5, 14, 2, 16, 82, 2, 8, 4, 107, 117, 2, 15, 2, 4, 2, 7, 2, 5, 2, 36, 71, 43, 2, 2, 26, 2, 2, 46, 7, 4, 2, 2, 13, 104, 88, 4, 2, 15, 2, 98, 32, 2, 56, 26, 141, 6, 194, 2, 18, 4, 2, 22, 21, 134, 2, 26, 2, 5, 144, 30, 2, 18, 51, 36, 28, 2, 92, 25, 104, 4, 2, 65, 16, 38, 2, 88, 12, 16, 2, 5, 16, 2, 113, 103, 32, 15, 16, 2, 19, 178, 32]
```
```python
for i in range(25_000):
    if x_train_full_seq[i, 0] == 0:  # 앞쪽에 0이 채워진(padding)걸 아는 상태
        print(f'i = {i}')
        print(x_train_full_seq[i])
        break

# 5번째 리뷰(실제로는 6번째 리뷰)
# 이 리뷰 길이를 100으로 맞추기 위해 앞부분에 0을 채운거
```
<img width="518" height="119" alt="image" src="https://github.com/user-attachments/assets/dd950227-0409-4c8b-acd0-943a9d616db3" />

```python
print(x_train_full[5])
# padding = 'pre': 시퀀스의 길이를 100으로 만들기 위해서 원본 샘플의 앞쪽에 0을 채움.
```
```
[1, 2, 128, 74, 12, 2, 163, 15, 4, 2, 2, 2, 2, 32, 85, 156, 45, 40, 148, 139, 121, 2, 2, 10, 10, 2, 173, 4, 2, 2, 16, 2, 8, 4, 2, 65, 12, 43, 127, 24, 2, 10, 10]
```

# RNN

*   FFNN(Feed-Forward Neural Network): 데이터의 흐름이 앞으로만 전달되는 신경망
    *   완전 연결 신경망
    *   합성곱 신경망(CNN, Convolutional Neural Network)
*   RNN(Recurrent Neural Network): 순환 신경망
    *   순차 데이터(sequencial data): 순환 신경망에서 사용하는 데이터. 텍스트(문장) 또는 시계열 데이터와 같이 순서가 의미가 있는 데이터.
    *   timestep: 샘플을 처리하는 한 단계. 시퀀스의 각 원소.
    *   cell(셀): 순환 신경망 층(recurrent layer)
    *   hidden state(은닉 상태): 셀의 출력(output)
    *   sequence(시퀀스): 순환 신경망에서 사용하는 하나의 샘플.
    *   자연어 처리(NLP, Natural Language Processing)와 같은 경우에 특정 단어가 다른 단어보다 더 중요할 이유는 없음. 단어가 정수로 인코딩된 값의 대소가 중요하지 않음. 인코딩된 정수가 신경망으로 주입되면 안됨.
        *   정수를 one-hot encoding으로 변환.
            *   단점: 계산량이 많아지고 메모리를 많이 사용함.
        *   정수를 word-embedding으로 변환.
            *   one-hot encoding의 단점을 보완.
            *   정수 1개를 몇 개의 실수들로 인코딩하는 방법.
         

## One-Hot Encoding을 사용한 RNN

```python
x_train_seq, x_val_seq, y_train, y_val = train_test_split(x_train_full_seq, y_train_full,
                                                            test_size = 0.2,
                                                            random_state = 42,
                                                            stratify = y_train_full)
```
```python
model = keras.Sequential(layers = [
        keras.Input(shape = (100,)),
        keras.layers.CategoryEncoding(num_tokens = 200, output_mode = 'one-hot),    # One-Hot 인코딩.
        # num_tokens = 200: 이 모델이 다룰 수 있는 단어의 총개수(어휘 사전의 크기)를 200으로 설정합니다. 이는 load_data의 num_words와 일치해야 함
        keras.layers.SimpleRNN(units = 8),    # 순환층
        keras.layers.Dense(units = 1, activation = 'sigmoid')    # 출력층
])
```
```python
model.summary()
```
<img width="553" height="217" alt="image" src="https://github.com/user-attachments/assets/c16cd2ec-ab4d-4200-abe2-595f57353826" />

```
(200 + 8 + 1) * 8 = 1672    # SimpleRNN 모델 파라미터 개수
```
```python
model.compile(optimizer = keras.optimizers.Adam(),
              loss = keras.losses.binary_crossentropy,
              metrics = [keras.metrics.binary_accuracy])
```
```python
checkpoint = keras.callbacks.ModelCheckpoint(filepath = 'rnn_1hot.keras',
                                             save_best_only=True)
early_stop = keras.callbacks.EarlyStopping(patience = 3, restore_best_weights=True)
```
```python
result = model.fit(x = x_train_seq, y = y_train, batch_size = 64, epochs = 100, 
                   callbacks = [checkpoint, early_stop],
                   validation_data = [x_val_seq, y_val])
```
<img width="1087" height="230" alt="image" src="https://github.com/user-attachments/assets/24d31d07-9c21-4c56-8b14-77aac2cd9fb7" />

```python
epoch = result.epoch
history = result.history
plt.plot(epoch, history['loss'], 'bo-', label = 'train loss')
plt.plot(epoch, history['val_loss'], 'ro:', label = 'validation loss')
plt.legend()
plt.grid()
plt.xlabel('epoch')
plt.ylabel('loss')
plt.show()
```
<img width="576" height="432" alt="image" src="https://github.com/user-attachments/assets/4672fd43-af82-458d-97fe-c60c0fd58dc9" />


```python
# to_categorical이게 용량 많이 써야해서 하는 방법만 보기
x_train_full_1h = keras.utils.to_categorical(x = x_train_full_seq)

x_train_full_1h.shape  # (n_samples, n_timesteps, n_classes)  100개의 단어로 이루어져있고, 200개의 카테고리로 나눌 수 있음
```
<img width="133" height="26" alt="image" src="https://github.com/user-attachments/assets/e6805725-4227-42a2-91fa-04a16ce6645d" />

```python
x_test_1h = keras.utils.to_categorical(x = x_test_seq)
```
```python
x_test_1h.shape
```
<img width="133" height="26" alt="image" src="https://github.com/user-attachments/assets/a18acd10-fbe3-470a-a734-9ba4a041fa17" />

```python
x_train_full_1h[0, 0]  # 첫번재 샘플(리뷰)의 첫번재 타임스텝(단어)의 1-hot 인코딩 벡터.
```
<img width="542" height="195" alt="image" src="https://github.com/user-attachments/assets/74eeb50a-0b35-40f9-8626-2fc8d6204955" />

```
# 전체 훈련 셋을 훈련/검증 셋으로 분리
# x_train, x_val, y_train, y_val = train_test_split(x_train_full_1h, y_train_full,
#                                                   test_size = 0.2,
#                                                   random_state = 42,
#                                                   stratify = y_train_full)
# RAM 많이 사용해서 오류남!!
```

## Word Embedding을 사용한 RNN


keras.layers.Embedding 객체를 사용.

```python
x_train, x_val, y_train, y_val = train_test_split(x_train_full_seq, y_train_full,
                                                  test_size = 0.2,
                                                  random_state = 42,
                                                  stratify = y_train_full)
```
```python
x_train.shape  # (n_samples, n_timesteps). 20000개의 샘플. 영화리뷰 한개는 100개의 timesteps으로 이루어짐
```
<img width="91" height="23" alt="image" src="https://github.com/user-attachments/assets/a0bffa28-b541-4bd0-bbfb-132f1253ba44" />

```python
x_val.shape  # (n_samples, n_timesteps). 검증셋은 5000개이고, 한개의 리뷰는 100개의 timesteps으로 이루어짐
```
<img width="87" height="25" alt="image" src="https://github.com/user-attachments/assets/ba72942e-873a-44d2-8365-2ae2c8f669c5" />

```python
tf.random.set_seed(42)
np.random.seed(42)

rnn_1 = keras.Sequential(layers = [
    keras.Input(shape = (100, )),   # 입력층 (각 리뷰의 길이가 100이라서 입력 모양은 100개의 정수를 가진 1차원 백)
    keras.layers.Embedding(input_dim = 200, output_dim = 16),   # 단어 임베딩 계층 (정수 형태의 리뷰를 dense vector로 변환)
    keras.layers.SimpleRNN(units = 8),  # 순환 계층 (8개의 뉴런 사용)
    keras.layers.Dense(units = 1, activation = 'sigmoid')
    # 출력층 (긍정/부정 즉 예측값이 1개니깐 출력 유닛은 1, 출력을 0과 1사이의 값으로 변환하기 위해 sigmoid. 0.5보다 크면 긍정, 작으면 부정)
])
```
```python
rnn_1.summary()
```
<img width="554" height="204" alt="image" src="https://github.com/user-attachments/assets/7f39c411-46ff-40cf-bd5d-42d3a313a609" />

```
Embbeding 계층의 모델 파라미터 개수 = 단어 사전 어휘 개수 x 임베딩 출력
200 * 16 = 3200

SimpleRNN의 모델 파라미터 개수 = (각 타임스텝의 입력값 개수 + 순환 셀 개수 + 바이어스) * 순환 셀 개수
(16 + 8 + 1) * 8 = 200

출력층의 모델 파라미터 개수
8 + 1 = 9
```
```python
keras.utils.plot_model(rnn_1, show_shapes = True, dpi = 128)
```
<img width="704" height="590" alt="image" src="https://github.com/user-attachments/assets/d5c3411c-d5be-4555-86be-e6756d755531" />

```python
# 모델 컴파일
rnn_1.compile(optimizer = keras.optimizers.Adam(),
              loss = keras.losses.binary_crossentropy,
              metrics = [keras.metrics.binary_accuracy])
```
```python
# 체크포인트, 조기종료 콜백
checkpoint = keras.callbacks.ModelCheckpoint(filepath = 'rnn_1.keras',  # 코랩에 저장
                                             save_best_only = True)
early_stop = keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True)  
```
```python
# 모델 훈련 
result = rnn_1.fit(x = x_train, y = y_train, batch_size = 64, epochs = 100,
                   callbacks=[checkpoint, early_stop],
                   validation_data = [x_val, y_val])
```
<img width="1093" height="229" alt="image" src="https://github.com/user-attachments/assets/0c97843a-c710-4c9d-a79c-bb8a929898b0" />

```python
def plot_train_val_loss(history):
    epoch = history.epoch
    history = history.history
    plt.plot(epoch, history['loss'], 'bo-', label = 'train loss')
    plt.plot(epoch, history['val_loss'], 'ro:', label = 'validation loss')
    plt.legend()
    plt.grid()
    plt.xlabel('epoch')
    plt.ylabel('loss')
    plt.show()
```
```python
plot_train_val_loss(result)
```
<img width="576" height="432" alt="image" src="https://github.com/user-attachments/assets/0a0fbaee-8200-4db8-b9c8-4968c7650930" />

```python
# 훈련 셋 예측값
train_predicts = rnn_1.predict(x = x_train)
```
<img width="444" height="30" alt="image" src="https://github.com/user-attachments/assets/c44aac9b-7040-4fd0-9039-00ee92d7d602" />

```python
train_predicts[:10]
```
<img width="265" height="168" alt="image" src="https://github.com/user-attachments/assets/9e95c5cb-b807-448f-852e-716e974dabb1" />

```python
train_pred_labels = (train_predicts > 0.5).astype('int').ravel()    # 0.5보다 크면 1, 작으면 0으로 변환
```
```python
train_pred_labels[:10]
```
<img width="269" height="30" alt="image" src="https://github.com/user-attachments/assets/9f07d677-fbe0-4305-832d-fdc78741e24b" />

```python
y_train[:10]
```
<img width="271" height="35" alt="image" src="https://github.com/user-attachments/assets/28321f50-bea3-457e-813c-3133f368c9a0" />

```python
np.mean(train_pred_labels == y_train)  # 정확도
```
<img width="149" height="21" alt="image" src="https://github.com/user-attachments/assets/27d32140-aae0-442d-a13f-fbaea43ee700" />

```python
# 검증 셋 예측값
val_predicts = rnn_1.predict(x = x_val)     # 검증 셋 예측값
val_pred_labels = (val_predicts > 0.5).astype('int').ravel()    # 예측 레이블(타겟)
np.mean(y_val == val_pred_labels)   # 검증 셋 정확도
```
<img width="450" height="38" alt="image" src="https://github.com/user-attachments/assets/0d4e0b7d-3ac5-4a41-a980-a4b63f775400" />

# 연습

*   imdb 데이터셋을 다시 로딩하세요. 자주 사용되는 단어 500개를 사용하세요.
    *   x_train_full의 shape = (25_000,)
*   훈련 셋의 모든 샘플을 100개의 timestep을 갖는 시퀀스로 변환하세요.
    *   x_train_full_seq의 shape = (25_000, 100)
*   단어 임베딩을 사용한 가장 간단한 RNN을 생성하세요.
    *   WordEmbedding -> SimpleRNN -> Dense
    *   단어 임베딩의 출력은 32로 설정.
    *   순환 망의 셀 개수는 32로 설정.
    *   순환 망의 dropout 비율을 0.3으로 설정.
*   모델을 훈련하고 평가하세요.

```python
(x_train_full, y_train_full), (x_test, y_test) = keras.datasets.imdb.load_data(num_words = 500)
```
```python
x_train_full.shape  # 사용된 단어들의 개수가 서로 다른 25,000개의 영화 리뷰.
```
<img width="68" height="27" alt="image" src="https://github.com/user-attachments/assets/68024b63-4ec4-4d5d-888b-6c28ca4128ce" />

```python
# 모든 영화 리뷰(샘플)들 같은 크기의 시퀀스로 만들기 위해서
x_train_full_seq = keras.preprocessing.sequence.pad_sequences(sequences=x_train_full,
                                                              maxlen = 100)
```
```python
x_train_full_seq.shape
# 1개 시퀀스는 100개 timestep을 가지고 있음.
```
<img width="97" height="30" alt="image" src="https://github.com/user-attachments/assets/070e586a-876f-43dd-af9a-c6e698743722" />

```python
x_train, x_val, y_train, y_val = train_test_split(x_train_full_seq, y_train_full,
                                                  test_size = 0.2,
                                                  random_state = 42,
                                                  stratify = y_train_full)
```
```python
x_train.shape
```
<img width="95" height="30" alt="image" src="https://github.com/user-attachments/assets/1ed603b0-b85e-4d4d-821c-e4555ff2c93b" />

```python
x_val.shape
```
<img width="89" height="25" alt="image" src="https://github.com/user-attachments/assets/c4830db8-af70-4191-86b0-20d5ab1d66b1" />

```python
tf.random.set_seed(42)
np.random.seed(42)

rnn_2 = keras.Sequential(layers = [
    keras.Input(shape = (100,)),    # 입력층
    keras.layers.Embedding(input_dim = 500, output_dim = 32),   # Word Embedding layer
    keras.layers.SimpleRNN(units = 32, dropout=0.3),    # recurrent layer
    keras.layers.Dense(units = 1, activation = 'sigmoid')
])
```
```python
rnn_2.summary()
```
<img width="541" height="200" alt="image" src="https://github.com/user-attachments/assets/cc11fed2-0f68-43af-a752-99268cff792f" />

```python
keras.utils.plot_model(rnn_2, show_shapes=True, dpi = 128)
```
<img width="704" height="590" alt="image" src="https://github.com/user-attachments/assets/0d3d88d7-1253-49eb-aaf5-e57425bfbe32" />

```python
rnn_2.compile(optimizer = keras.optimizers.Adam(),
              loss = keras.losses.binary_crossentropy,
              metrics = [keras.metrics.binary_accuracy])
```
```python
checkpoint = keras.callbacks.ModelCheckpoint(filepath = 'rnn_2.keras', save_best_only = True)
early_stop = keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True)
```
```python
result = rnn_2.fit(x = x_train, y = y_train, batch_size=64, epochs = 100,
                   callbacks = [checkpoint, early_stop],
                   validation_data = [x_val, y_val])
```
<img width="1093" height="198" alt="image" src="https://github.com/user-attachments/assets/a13bd4ca-2f43-400c-b50c-19b4d21ea48d" />

```python
def plot_train_val_loss(history):
    epoch = history.epoch
    history = history.history
    plt.plot(epoch, history['loss'], 'bo-', label='train loss')
    plt.plot(epoch, history['val_loss'], 'ro:', label='validation loss')
    plt.legend()
    plt.grid()
    plt.xlabel('epoch')
    plt.ylabel('loss')
    plt.show()
```
```python
plot_train_val_loss(result)
```
<img width="576" height="432" alt="image" src="https://github.com/user-attachments/assets/2c8f5a6b-bbe7-4f09-bc2d-8a788d1264df" />

```python
from sklearn.metrics import accuracy_score
```
```python
train_predicts = rnn_2.predict(x = x_train)
train_pred_labels = (train_predicts > 0.5).astype('int').ravel()
accuracy_score(y_true = y_train, y_pred = train_pred_labels)
```
<img width="440" height="42" alt="image" src="https://github.com/user-attachments/assets/89097aac-36c8-4fbd-a75f-f84beadf7efe" />

```python
val_predicts = rnn_2.predict(x = x_val)
val_pred_labels = (val_predicts > 0.5).astype('int').ravel()
accuracy_score(y_true = y_val, y_pred = val_pred_labels)
```
<img width="444" height="48" alt="image" src="https://github.com/user-attachments/assets/b728616e-7a96-47b8-b427-fbb20273b710" />
