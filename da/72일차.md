# Dropout

*   훈련 과정(epoch)에서 일부 unit의 출력을 0으로 만드는 것(그 다음 layer로 출력값을 전달하지 않음).
*   각 epoch마다 출력을 0으로 만드는 unit은 무작위로 선택.
*   모델의 과대적합을 줄일 수 있음.


<img width="712" height="296" alt="image" src="https://github.com/user-attachments/assets/ed610e30-0040-4aff-a0cf-6a3c6abd3224" />

```python
import numpy as np
import matplotlib.pyplot as plt

import tensorflow as tf
import keras

from sklearn.model_selection import train_test_split
from sklearn.linear_model import SGDClassifier
from sklearn.metrics import accuracy_score
```

```python
model = create_model(layers = [keras.layers.Dropout(rate = 0.3)])
# 은닉층 뒤에 30% 비율로 출력을 0으로 만드는 Dropout 계층을 추가
```
```python
model.sumary()
```
<img width="541" height="229" alt="image" src="https://github.com/user-attachments/assets/beec2da9-d650-4235-9216-a30e1dd4b729" />

```python
model.compile(optimizer = keras.optimizers.Adam(),    # 모델 가중치 최적화
              loss = keras.losses.sparse_categorical_crossentropy,  # 손실 함수
              metrics = [keras.metrics.sparse_categorical_accuracy])  # 정확도
```
```python
result = model.fit(x = train_data_scaled, y = train_target, epochs = 20,
                   validation_data = [val_data_scaled, val_target])  # 훈련 중에 모델의 성능을 검증하기 위한 데이터.
```
```
Epoch 1/20
1500/1500 ━━━━━━━━━━━━━━━━━━━━ 8s 4ms/step - loss: 0.7666 - sparse_categorical_accuracy: 0.7317 - val_loss: 0.4125 - val_sparse_categorical_accuracy: 0.8526
Epoch 2/20
1500/1500 ━━━━━━━━━━━━━━━━━━━━ 4s 3ms/step - loss: 0.4560 - sparse_categorical_accuracy: 0.8365 - val_loss: 0.3964 - val_sparse_categorical_accuracy: 0.8547
Epoch 3/20
1500/1500 ━━━━━━━━━━━━━━━━━━━━ 5s 3ms/step - loss: 0.4149 - sparse_categorical_accuracy: 0.8503 - val_loss: 0.3652 - val_sparse_categorical_accuracy: 0.8685
Epoch 4/20
1500/1500 ━━━━━━━━━━━━━━━━━━━━ 5s 3ms/step - loss: 0.3834 - sparse_categorical_accuracy: 0.8571 - val_loss: 0.3460 - val_sparse_categorical_accuracy: 0.8730
Epoch 5/20
1500/1500 ━━━━━━━━━━━━━━━━━━━━ 4s 3ms/step - loss: 0.3727 - sparse_categorical_accuracy: 0.8655 - val_loss: 0.3333 - val_sparse_categorical_accuracy: 0.8792
Epoch 6/20
1500/1500 ━━━━━━━━━━━━━━━━━━━━ 5s 3ms/step - loss: 0.3596 - sparse_categorical_accuracy: 0.8689 - val_loss: 0.3422 - val_sparse_categorical_accuracy: 0.8743
Epoch 7/20
1500/1500 ━━━━━━━━━━━━━━━━━━━━ 5s 3ms/step - loss: 0.3450 - sparse_categorical_accuracy: 0.8721 - val_loss: 0.3299 - val_sparse_categorical_accuracy: 0.8806
Epoch 8/20
1500/1500 ━━━━━━━━━━━━━━━━━━━━ 5s 3ms/step - loss: 0.3382 - sparse_categorical_accuracy: 0.8759 - val_loss: 0.3300 - val_sparse_categorical_accuracy: 0.8826
Epoch 9/20
1500/1500 ━━━━━━━━━━━━━━━━━━━━ 6s 4ms/step - loss: 0.3303 - sparse_categorical_accuracy: 0.8772 - val_loss: 0.3251 - val_sparse_categorical_accuracy: 0.8830
Epoch 10/20
1500/1500 ━━━━━━━━━━━━━━━━━━━━ 5s 3ms/step - loss: 0.3230 - sparse_categorical_accuracy: 0.8809 - val_loss: 0.3178 - val_sparse_categorical_accuracy: 0.8852
Epoch 11/20
1500/1500 ━━━━━━━━━━━━━━━━━━━━ 5s 3ms/step - loss: 0.3233 - sparse_categorical_accuracy: 0.8797 - val_loss: 0.3313 - val_sparse_categorical_accuracy: 0.8825
Epoch 12/20
1500/1500 ━━━━━━━━━━━━━━━━━━━━ 6s 4ms/step - loss: 0.3164 - sparse_categorical_accuracy: 0.8791 - val_loss: 0.3350 - val_sparse_categorical_accuracy: 0.8801
Epoch 13/20
1500/1500 ━━━━━━━━━━━━━━━━━━━━ 10s 4ms/step - loss: 0.3078 - sparse_categorical_accuracy: 0.8853 - val_loss: 0.3192 - val_sparse_categorical_accuracy: 0.8842
Epoch 14/20
1500/1500 ━━━━━━━━━━━━━━━━━━━━ 5s 3ms/step - loss: 0.2937 - sparse_categorical_accuracy: 0.8896 - val_loss: 0.3180 - val_sparse_categorical_accuracy: 0.8848
Epoch 15/20
1500/1500 ━━━━━━━━━━━━━━━━━━━━ 5s 3ms/step - loss: 0.2946 - sparse_categorical_accuracy: 0.8863 - val_loss: 0.3163 - val_sparse_categorical_accuracy: 0.8871
Epoch 16/20
1500/1500 ━━━━━━━━━━━━━━━━━━━━ 6s 4ms/step - loss: 0.2913 - sparse_categorical_accuracy: 0.8903 - val_loss: 0.3305 - val_sparse_categorical_accuracy: 0.8871
Epoch 17/20
1500/1500 ━━━━━━━━━━━━━━━━━━━━ 4s 3ms/step - loss: 0.2872 - sparse_categorical_accuracy: 0.8900 - val_loss: 0.3176 - val_sparse_categorical_accuracy: 0.8879
Epoch 18/20
1500/1500 ━━━━━━━━━━━━━━━━━━━━ 5s 3ms/step - loss: 0.2837 - sparse_categorical_accuracy: 0.8921 - val_loss: 0.3220 - val_sparse_categorical_accuracy: 0.8875
Epoch 19/20
1500/1500 ━━━━━━━━━━━━━━━━━━━━ 6s 4ms/step - loss: 0.2824 - sparse_categorical_accuracy: 0.8930 - val_loss: 0.3161 - val_sparse_categorical_accuracy: 0.8898
Epoch 20/20
1500/1500 ━━━━━━━━━━━━━━━━━━━━ 5s 3ms/step - loss: 0.2758 - sparse_categorical_accuracy: 0.8943 - val_loss: 0.3204 - val_sparse_categorical_accuracy: 0.8884
```
```python
plot_train_val_losses(result)
```
<img width="576" height="432" alt="image" src="https://github.com/user-attachments/assets/8181f89f-4467-4b1e-8a77-214abefc901c" />

# 모델 저장과 복원

```python
model.summary()
```
<img width="586" height="252" alt="image" src="https://github.com/user-attachments/assets/dbb23f0a-7951-44af-b1ce-5f35af98a96f" />

```python
len(model.weights)
```
<img width="24" height="28" alt="image" src="https://github.com/user-attachments/assets/85a23998-1f85-456b-aab5-df87cbc11b67" />

```python
model.weights[0]    # (784, 100) shape. 첫번째 은닉층에서 학습된 가중치들. (784, 100) shape.
```
<img width="1116" height="215" alt="image" src="https://github.com/user-attachments/assets/c63ffa1d-3e0b-49a6-b8f2-a23f7d05857e" />

```python
model.weights[1]    # (100,) shape. 번째 은닉층에서 학습된 bias들.
```
<img width="1004" height="398" alt="image" src="https://github.com/user-attachments/assets/903add15-4bfc-49e6-8e49-45411b70ce3a" />

```python
model.weights[3]    # (10,) shape. 출력층에서 학습된 bias들.
```
<img width="1083" height="39" alt="image" src="https://github.com/user-attachments/assets/eca19bf5-a292-47e8-8977-c7e4b0165f50" />

## 모델 저장

```python
path = '/content/drive/MyDrive/Colab Notebooks/lab_da'

# 모델 파라미터들만 저장하는 파일의 확장자는 '.weights.h5'
weights_file = path + '/model1.weights.h5'  # 파일 이름 + 확장자

# 훈련이 끝난 모델을 저장하는 파일의 확장자는 '.keras'
model_file = path + '/model1.keras'
```
```python
# 모델 파라미터들만 저장
model.save_weights(weights_file)
```
```python
# 모델의 구조와 모델 파라미터들을 함께 저장
model.save(model_file)
```

## 파일에 저장된 모델을 복원

### 모델 파라미터들만 저장한 파일(weight.h5)에서 복원

```python
# 모델 파라미터와 같은 구조로 모델을 먼저 생성.
model = create_model(layers = [keras.layers.Dropout(rate = 0.3)])
```
```python
# 생성된 모델에서 load_weights 메서드 호출, 아규먼트는 저장된 가중치 파일.
model.load_weights(weights_file)
```

```
모델 파라미터들만 복원한 경우에는 모델이 컴파일되어 있지 않은 상태이기 때문에 evaluate() 메서드를 호출할 수 없음. 모델 파라미터(가중치들)들은 모두 복원이 됐기 때문에 `predict()` 메서드는 호출 가능.
```

```python
predicts = model.predict(x = train_data_scaled)
```
<img width="465" height="26" alt="image" src="https://github.com/user-attachments/assets/d69ff743-ed50-400d-a325-c3e66affe2e1" />

```python
predict_labels = predicts.argmax(axis = 1)
# predicts 배열에서 가장 높은 확률을 가진 클래스의 인덱스를 찾는 역할
# argmax() 배열에서 가장 큰 값의 인덱스를 반환하는 함수
# axis = 1 행 방향으로 적용
```
```python
accuracy_score(train_target, predict_labels)
```
<img width="56" height="31" alt="image" src="https://github.com/user-attachments/assets/d4aea62b-5b63-46e6-9299-2155498dc921" />

### 모델 구조와 파라미터들을 저장한 파일(keras)에서 모델을 복원

```python
# keras.models.load_model() 함수 호출, 모델을 저장할 파일(.keras)을 아규먼트로 줌.
model = keras.models.load_model(model_file, compile = True)
```


확장자가 .keras인 파일에서 모델을 복원하는 경우는 컴파일이 끝난 모델을 복원함. `evaluate()` 메서드와 `predict()` 메서드들을 모두 사용할 수 있음.


```python
model.evaluate(x = train_data_scaled, y = train_target)
```
<img width="830" height="42" alt="image" src="https://github.com/user-attachments/assets/2fe9572c-e21e-41a7-89d5-4dd5fb9b4a4a" />

# Callback


*   callback(콜백): 훈련 과정 중간에 어떤 작업을 수행할 수 있게 만드는 객체. `keras.callbacks`모듈 아래의 클래스들을 사용할 수 있음.
*   `keras.callbacks.ModelCheckpoint` 클래스
    *   epoch마다 모델을 저장할 수 있는 기능을 가지고 있는 클래스.
    *   `save_best_only` 파라미터를 True로 설정해서 가장 검증 손실이 작은 모델만을 저장할 수 있음.
*   `keras.callbacks.EarlyStopping` 클래스
    *   과대적합이 시작되기 전에 훈련을 일찍 종료시킬 수 있는 기능을 가지고 있는 클래스.
    *   `fit()` 메서드에서 설정된 epochs 횟수보다 일찍 모델 훈련이 종료될 수 있음.

```python
# 모델 생성
model = create_model(layers = [keras.layers.Dropout(rate = 0.3)])
```
```python
# 모델 컴파일
model.compile(optimizer = keras.optimizers.Adam(), 
              loss = keras.losses.sparse_categorical_crossentropy,
              metrics = [keras.metrics.sparse_categorical_accuracy])
```
```python
# 모델 체크포인트 콜백 객체 생성
checkpoint_cb = keras.callbacks.ModelCheckpoint(filepath = path + '/best_model.keras',
                                                save_best_only = True)
# save_best_only = True -> 모니터링 지표가 최고 성능을 기록했을 때만 모델 저장
# filepath -> 모델을 저장할 경로와 파일명 지정
```
```python
# 조기종료 콜백 객체 생성
early_stop_cb = keras.callbacks.EarlyStopping(patience = 3,  # patience 숫자가 크면 조기종료가 늦게 되는 거(손실이 늘어나도 3번까지는 기다려주겠다)
                                              restore_best_weights = True)
```
```python
# 검증 셋과 콜백들을 설정해서 모델을 훈련
result = model.fit(x = train_data_scaled, y = train_target, epochs = 100,
                    callbacks = [checkpoint_cb, early_stop_cb],
                    validation_data = [val_data_scaled, val_target])
```
<img width="1283" height="295" alt="image" src="https://github.com/user-attachments/assets/212cd509-1ec4-4b8a-818e-daec1763de1d" />

```python
plot_train_val_losses(result)
```
<img width="576" height="432" alt="image" src="https://github.com/user-attachments/assets/1b51348f-f1cf-4c02-8517-54ff9fa54deb" />

```python
# 훈련이 끝난 모델 평가
model.evaluate(x = train_data_scaled, y = train_target)     # 훈련셋
```
<img width="841" height="41" alt="image" src="https://github.com/user-attachments/assets/09e71119-2f12-4986-928b-1101531838e7" />

```python
model.evaluate(x = val_data_scaled, y = val_target)         # 검증셋
```
<img width="813" height="39" alt="image" src="https://github.com/user-attachments/assets/198cfdc9-76de-4cd1-bfc4-b6df7e0a839c" />

```python
# 최적의 파라미터들과 모델 구조를 저장한 파일에서 모델을 복원
best_model = keras.models.load_model(filepath=path + '/best_model.keras')
```
```python
best_model.evaluate(x = train_data_scaled, y = train_target)
```
<img width="834" height="41" alt="image" src="https://github.com/user-attachments/assets/a6e8508a-f7ee-4f3a-97b3-b12e705882f5" />

```python
best_model.evaluate(x = val_data_scaled, y = val_target)

```
<img width="814" height="41" alt="image" src="https://github.com/user-attachments/assets/d9d4b7ab-040f-4227-9d99-2e10f20d76be" />


--------------

# CNN(Convolution Neural Network)

# Imports

```python
import numpy as np
import matplotlib.pyplot as plt

from scipy.signal import convolve, convolve2d, correlate, correlate2d
from sklearn.datasets import load_sample_image
from sklearn.model_selection import train_test_split

import keras
```

# 1차원 합성곱 연산(1-D Convolution)

```python
x = np.arange(1, 5)
print(x)
```
<img width="74" height="26" alt="image" src="https://github.com/user-attachments/assets/d44d204c-583a-431f-861b-c9fc426973da" />

```python
y = np.array([1, 2])
print(y)
```
<img width="46" height="28" alt="image" src="https://github.com/user-attachments/assets/f0cffa3d-190c-41fc-ba20-e8208e65d8d0" />

```python
y_filp = np.flip(y)
print(y_flip)
# 좌우 반전으로 만들어진 배열
```
<img width="47" height="28" alt="image" src="https://github.com/user-attachments/assets/6074b6ba-98c5-4d95-bcc4-db7b8169e2e1" />

## convolve 함수


scipy.signal.convolve 함수는 배열 y를 filp(반전)시킨 후 연산을 수행.



<img width="550" height="540" alt="image" src="https://github.com/user-attachments/assets/5f45a708-2d28-4462-ba95-8e0fa2b7553d" />


```python
result = convolve(x, y, mode = 'valid')    # valid mode 합성곱 연산 -> 배열 x의 크기가 줄어듦.
print(result)
```
<img width="79" height="26" alt="image" src="https://github.com/user-attachments/assets/9cf13a4e-6e80-4bbf-9b7f-22a29590ef3c" />

```
[1 2 3 4]
[2 1]       -> 4
  [2 1]    -> 7
    [2 1]  -> 10
```

```python
result = convolve(x, y, mode = 'same')      # same mode 합성곱 연산 -> x의 크기와 동일한 배열 리턴.
print(result)
```
<img width="111" height="32" alt="image" src="https://github.com/user-attachments/assets/1a3301d4-9cfb-49bb-9946-ee566ecd2fbb" />

```
[0 1 2 3 4]   - padding
[2 1]       -> 1
   [2 1]    -> 4
     [2 1]  -> 7
       [2 1]-> 10
```
```python
result = convolve(x, y, mode = 'full')      # full mode 합성곱 연산 -> 배열 x의 모든 원소가 합성곱 연산에 같은 비율로 참여하도록 패딩을 넣는 것.
print(result)
```
<img width="123" height="28" alt="image" src="https://github.com/user-attachments/assets/b31911f5-83f7-4f17-ada3-43dc0d3e8f7f" />

```python
[0 1 2 3 4 0]   - padding
[2 1]          -> 1
   [2 1]       -> 4
     [2 1]     -> 7
       [2 1]   -> 10
         [2 1] -> 8

# x와 y의 모양에 따라 늘어날수도 있고 줄어들수도 있음
```

# 교차 상관(cross-crrelate)


scipy.signal.correlate 함수는 배열 y를 반전시키지 않고 연산을 수행.


```python
result = correlate(x, y, mode = 'valid')
print(result)
# 원본에 패딩을 주지 않고 배열의 끝까지 하는 작업
```
<img width="82" height="24" alt="image" src="https://github.com/user-attachments/assets/963f55a7-fb34-492c-97c6-ac994126174f" />

```
[1 2 3 4]
[1 2]       -> 5(1x1 + 2x2)
  [1 2]     -> 8
    [1 2]   -> 11
```
```python
result = correlate(x, y, mode = 'same')
print(result)
# 주위에 0으로 패딩해서 원본의 크기를 유지하도록 합성곱하는거
```
<img width="107" height="24" alt="image" src="https://github.com/user-attachments/assets/6afc23d5-9c6b-41dd-897f-5f07f2573916" />

```
[0 1 2 3 4]
[1 2]       -> 2
  [1 2]     -> 5
    [1 2]   -> 8
      [1 2] -> 11
```
```python
result = correlate(x, y, mode = 'full')
print(result)
# 상하좌우 패딩을 주는 거
```
<img width="124" height="24" alt="image" src="https://github.com/user-attachments/assets/9563c759-bc74-404c-98e1-3ae5fb5a0758" />

```
[0 1 2 3 4 0]
[1 2]         -> 2
  [1 2]       -> 5
    [1 2]     -> 8
      [1 2]   -> 11
        [1 2] -> 4
```

# 2차원 합성곱(2-D Convolution)

```python
x = np.arange(1, 17).reshape((4, 4))
print(x)
```
<img width="121" height="75" alt="image" src="https://github.com/user-attachments/assets/7905e0dd-fd7c-4c21-978e-b1e662c5b0a7" />

```python
y = np.array([[0, 1], [2, 0]])
print(y)
```
<img width="57" height="40" alt="image" src="https://github.com/user-attachments/assets/2588302e-9438-45e1-9634-cb31760c6c2d" />

```python
y_flip = np.flip(y)
print(y_flip)
```
<img width="62" height="38" alt="image" src="https://github.com/user-attachments/assets/a6af00c9-9faa-4d1b-b3e3-d9e4a610d783" />

## convolve2d 함수

```python
result = convolve2d(x, y, mode = 'valid')
print(result)   # (3, 3) shape
```
<img width="93" height="58" alt="image" src="https://github.com/user-attachments/assets/cc65bd83-6556-4f55-807b-82406807a6a7" />

```
# [1   2  3  4]
# [5   6  7  8]
# [9  10 11 12]
# [13 14 15 16]

# [0 2]
# [1 0]



# 1*0 + 2*2 + 5*1 + 6+0 = 9
# 2*0 + 3*2 + 6*1 + 7*0 = 12
# 3*0 + 4*2 + 7*1 + 8*0 = 15
# 5*0 + 6*2 + 9*1 + 10*0 = 21
```
```python
result = convolve2d(x, y, mode = 'same')
print(result)

# x가 (4, 4)이니깐 결과도 (4, 4) shape
```
<img width="112" height="67" alt="image" src="https://github.com/user-attachments/assets/49a83d54-9330-413c-9d44-61030bffae54" />

```
[0   0   0   0   0]
[0   1   2   3   4]
[0   5   6   7   8]
[0   9  10  11  12]
[0   13 14  15  16]


[0 2]
[1 0]
```
```python
result = convolve2d(x, y, mode = 'full')
print(result)   # (5, 5) shape
```
<img width="137" height="90" alt="image" src="https://github.com/user-attachments/assets/03dc5cc5-a693-430e-9fac-600c92b90bc1" />

```
[0   0   0   0   0   0]
[0   1   2   3   4   0]
[0   5   6   7   8   0]
[0   9  10  11  12   0]
[0   13 14  15  16   0]
[0   0   0   0   0   0]


[0 2]
[1 0]
```

## correlate2d 함수

```python
result = correlate2d(x, y, mode = 'valid')
print(result)
```
<img width="96" height="56" alt="image" src="https://github.com/user-attachments/assets/4a6f5040-f098-447e-85a4-5f9e137acdbb" />

```
[1   2  3  4]
[5   6  7  8]
[9  10 11 12]
[13 14 15 16]


[0 1]
[2 0]


2*1 + 5*2 = 12
3*1 + 6*2 = 15
4*1 + 14 = 18
6*1 + 9*2 = 24
```
```python
result = correlate2d(x, y, mode = 'same')
print(result)
```
<img width="123" height="71" alt="image" src="https://github.com/user-attachments/assets/a0e9cd18-a4fe-4adc-8566-59b69f5b7a52" />

```python
result = correlate2d(x, y, mode = 'full')
print(result)
```
<img width="134" height="84" alt="image" src="https://github.com/user-attachments/assets/f1e953f3-6915-4dd6-8649-66158f430d14" />

## 이미지 배열과 합성

```python
china = load_sample_image('china.jpg')
```
```python
china.shape     #china는 배열임. 컬러 이미지
```
<img width="96" height="26" alt="image" src="https://github.com/user-attachments/assets/12c87d68-72b7-4adf-84ed-55d05bcd717e" />

```python
plt.imshow(china)  / 255.0 # 0 ~ 25 범위를 0 ~ 1 범위로 스케일링
plt.show()
```
<img width="552" height="379" alt="image" src="https://github.com/user-attachments/assets/3acd70fa-78ad-4fca-81af-158e29376742" />

```python
china_cp = china.copy()
china_cp[:, :, [0, 1]] = 0
plt.imshow(china_cp)
plt.show()
```
<img width="552" height="379" alt="image" src="https://github.com/user-attachments/assets/66a44940-be70-42a8-8072-aa2e0d5d552f" />

```
china_cp = china.copy() /   255.0 # 0 ~ 25 범위를 0 ~ 1 범위로 스케일링
```

```python
china_cp[:, :, [0, 2]] = 0
plt.imshow(china_cp)
plt.show()
```
<img width="552" height="379" alt="image" src="https://github.com/user-attachments/assets/d458f187-619a-4677-869f-7d17a4e2da86" />

```python
filter = np.zeros(shape = (3, 3, 3))
filter[:, :, 1] = 1
result = convolve(china, filter, mode = 'same')
result = result.astype(np.uint8)    # np.unit8: unsigined int 8bit. 8 bit 부호 없는 정수. 0 ~ 255.
print(result.shape)
```
<img width="103" height="27" alt="image" src="https://github.com/user-attachments/assets/045b0951-e375-47b0-a1cd-d862266355d0" />

```python
plt.imshow(result)
plt.show()
```
<img width="552" height="379" alt="image" src="https://github.com/user-attachments/assets/f8d7418b-3291-43df-9a88-9433d5343e52" />

```python
filter = np.zeros(shape = (3, 3, 3))
filter[:, :, 0] = 1
result = convolve(china, filter, mode = 'same')
result = result.astype(np.uint8)    # np.unit8: unsigined int 8bit. 8 bit 부호 없는 정수. 0 ~ 255.
print(result.shape)
```
<img width="98" height="24" alt="image" src="https://github.com/user-attachments/assets/636fef45-8e7a-46c2-8594-ed40d403141d" />

```python
plt.imshow(result)
plt.show()
# 빨간색에 해당하는 특징이 더 보임
```
<img width="552" height="379" alt="image" src="https://github.com/user-attachments/assets/b9d9858a-2069-466b-9418-a80eadc71ab7" />

# Pooling

```python
x = np.arange(1, 21).reshape((5, 4))
print(x)
```
<img width="116" height="89" alt="image" src="https://github.com/user-attachments/assets/4118f571-9998-4519-b621-c85ce02ea9a1" />

```python
x = x.reshape((1, 5, 4, 1))     # 4차원 배열
```

## Max Pooling


필터링된 값들 중에서 최댓값을 선택하는 풀링 방식.

```python
max_pooling = keras.layers.MaxPool2D()
x_pool = max_pooling(x)
print(x_pool.shape)
print(type(x_pool))

# 안쪽이 2 x 2로 바뀜
```
<img width="389" height="46" alt="image" src="https://github.com/user-attachments/assets/7ff24ce7-464c-4140-97b7-d5ff008b655c" />

```python
print(x_pool.numpy().reshape((2, 2)))   # Tensor -> numpy 배열 변환 -> reshape
```
<img width="75" height="38" alt="image" src="https://github.com/user-attachments/assets/5a0799ad-a176-4f55-8669-6bc787cd0a63" />

```
pooling하면 원본 배열보다 크기가 줄어든다
```

## Average Pooling


필터링된 값들의 평균을 선택하는 풀링 방식.

```python
x = x.astype('float')   # x = x.astype(np.float32)
# TensorFlow는 암묵적인 타입 변환을 수행하지 않기 때문에.

avg_pooling = keras.layers.AveragePooling2D(pool_size = (2, 2))
x_pool = avg_pooling(x)
print(type(x_pool))
print(x_pool.shape)
```
<img width="390" height="41" alt="image" src="https://github.com/user-attachments/assets/78efbb9f-e499-42aa-bc8c-e1bd2770caed" />

```python
x_pool = x_pool.numpy().reshape((2, 2))
print(x_pool)
```
<img width="107" height="43" alt="image" src="https://github.com/user-attachments/assets/8138659a-581f-4b28-8e87-d7338743795f" />

```python
(1 + 2 + 5 + 6) / 4
```
<img width="34" height="29" alt="image" src="https://github.com/user-attachments/assets/37a561d7-d74d-4cf1-afa6-584de70b40c8" />


일반적으로 합성곱 연산에서는 필터를 1칸씩 이동(보폭 stride의 크기를 1로 설정). 풀링에서는 필터를 필터의 크기만큼씩 이동.


## 이미지의 풀링(pooling)


이미지 축소


```python
flower = load_sample_image('flower.jpg').copy()
```
```python
flower.shape    # (height, width, channel)
```
<img width="101" height="20" alt="image" src="https://github.com/user-attachments/assets/282aabbd-afa2-4fd3-8f4e-6c9aa6e25dfd" />

```python
flower.max()
```
<img width="99" height="21" alt="image" src="https://github.com/user-attachments/assets/9d7496dc-2ad6-4ba8-8e36-87c4b4a30e1c" />

```python
flower.min()
```
<img width="87" height="28" alt="image" src="https://github.com/user-attachments/assets/5c92e8d7-6c69-444e-a980-488daaa320e8" />

```python
flower = flower / 255.0     # 0 ~ 1 범위로 스케일링
```
```python
plt.imshow(flower)
plt.show()
```
<img width="552" height="379" alt="image" src="https://github.com/user-attachments/assets/a3b011bf-f85e-4527-948f-34452df64fd5" />

<img width="559" height="344" alt="image" src="https://github.com/user-attachments/assets/7bd20168-04c6-4eaf-acc2-2ff0bd4c8bf0" />


```python
max_pooling = keras.layers.MaxPool2D()
```
```python
x = flower.reshape((1, 427, 640, 3))
x_pool = max_pooling(x)
print(x_pool.shape)
print(type(x_pool))
```
<img width="384" height="38" alt="image" src="https://github.com/user-attachments/assets/0848790b-26f6-4b45-bdb8-0112fb32e2d7" />


```
numpy 배열일때만 imshow()에 넣기 가능함
```

```python
img = x_pool[0].numpy()
plt.imshow(img)
plt.show()
```
<img width="552" height="378" alt="image" src="https://github.com/user-attachments/assets/712dcecc-6555-48ac-857f-12eeb9f02fdb" />

```python
avg_pooling = keras.layers.AvgPool2D(pool_size = (2, 2))
```
```python
x_pool = avg_pooling(x)
img = x_pool[0].numpy()
plt.imshow(img)
plt.show()
```
<img width="552" height="378" alt="image" src="https://github.com/user-attachments/assets/ee93a923-1ce6-45ab-b2d6-2718e2780d18" />
