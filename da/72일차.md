# Dropout

*   훈련 과정(epoch)에서 일부 unit의 출력을 0으로 만드는 것(그 다음 layer로 출력값을 전달하지 않음).
*   각 epoch마다 출력을 0으로 만드는 unit은 무작위로 선택.
*   모델의 과대적합을 줄일 수 있음.


<img width="712" height="296" alt="image" src="https://github.com/user-attachments/assets/ed610e30-0040-4aff-a0cf-6a3c6abd3224" />

```python
import numpy as np
import matplotlib.pyplot as plt

import tensorflow as tf
import keras

from sklearn.model_selection import train_test_split
from sklearn.linear_model import SGDClassifier
from sklearn.metrics import accuracy_score
```

```python
model = create_model(layers = [keras.layers.Dropout(rate = 0.3)])
# 은닉층 뒤에 30% 비율로 출력을 0으로 만드는 Dropout 계층을 추가
```
```python
model.sumary()
```
<img width="541" height="229" alt="image" src="https://github.com/user-attachments/assets/beec2da9-d650-4235-9216-a30e1dd4b729" />

```python
model.compile(optimizer = keras.optimizers.Adam(),    # 모델 가중치 최적화
              loss = keras.losses.sparse_categorical_crossentropy,  # 손실 함수
              metrics = [keras.metrics.sparse_categorical_accuracy])  # 정확도
```
```python
result = model.fit(x = train_data_scaled, y = train_target, epochs = 20,
                   validation_data = [val_data_scaled, val_target])  # 훈련 중에 모델의 성능을 검증하기 위한 데이터.
```
```
Epoch 1/20
1500/1500 ━━━━━━━━━━━━━━━━━━━━ 8s 4ms/step - loss: 0.7666 - sparse_categorical_accuracy: 0.7317 - val_loss: 0.4125 - val_sparse_categorical_accuracy: 0.8526
Epoch 2/20
1500/1500 ━━━━━━━━━━━━━━━━━━━━ 4s 3ms/step - loss: 0.4560 - sparse_categorical_accuracy: 0.8365 - val_loss: 0.3964 - val_sparse_categorical_accuracy: 0.8547
Epoch 3/20
1500/1500 ━━━━━━━━━━━━━━━━━━━━ 5s 3ms/step - loss: 0.4149 - sparse_categorical_accuracy: 0.8503 - val_loss: 0.3652 - val_sparse_categorical_accuracy: 0.8685
Epoch 4/20
1500/1500 ━━━━━━━━━━━━━━━━━━━━ 5s 3ms/step - loss: 0.3834 - sparse_categorical_accuracy: 0.8571 - val_loss: 0.3460 - val_sparse_categorical_accuracy: 0.8730
Epoch 5/20
1500/1500 ━━━━━━━━━━━━━━━━━━━━ 4s 3ms/step - loss: 0.3727 - sparse_categorical_accuracy: 0.8655 - val_loss: 0.3333 - val_sparse_categorical_accuracy: 0.8792
Epoch 6/20
1500/1500 ━━━━━━━━━━━━━━━━━━━━ 5s 3ms/step - loss: 0.3596 - sparse_categorical_accuracy: 0.8689 - val_loss: 0.3422 - val_sparse_categorical_accuracy: 0.8743
Epoch 7/20
1500/1500 ━━━━━━━━━━━━━━━━━━━━ 5s 3ms/step - loss: 0.3450 - sparse_categorical_accuracy: 0.8721 - val_loss: 0.3299 - val_sparse_categorical_accuracy: 0.8806
Epoch 8/20
1500/1500 ━━━━━━━━━━━━━━━━━━━━ 5s 3ms/step - loss: 0.3382 - sparse_categorical_accuracy: 0.8759 - val_loss: 0.3300 - val_sparse_categorical_accuracy: 0.8826
Epoch 9/20
1500/1500 ━━━━━━━━━━━━━━━━━━━━ 6s 4ms/step - loss: 0.3303 - sparse_categorical_accuracy: 0.8772 - val_loss: 0.3251 - val_sparse_categorical_accuracy: 0.8830
Epoch 10/20
1500/1500 ━━━━━━━━━━━━━━━━━━━━ 5s 3ms/step - loss: 0.3230 - sparse_categorical_accuracy: 0.8809 - val_loss: 0.3178 - val_sparse_categorical_accuracy: 0.8852
Epoch 11/20
1500/1500 ━━━━━━━━━━━━━━━━━━━━ 5s 3ms/step - loss: 0.3233 - sparse_categorical_accuracy: 0.8797 - val_loss: 0.3313 - val_sparse_categorical_accuracy: 0.8825
Epoch 12/20
1500/1500 ━━━━━━━━━━━━━━━━━━━━ 6s 4ms/step - loss: 0.3164 - sparse_categorical_accuracy: 0.8791 - val_loss: 0.3350 - val_sparse_categorical_accuracy: 0.8801
Epoch 13/20
1500/1500 ━━━━━━━━━━━━━━━━━━━━ 10s 4ms/step - loss: 0.3078 - sparse_categorical_accuracy: 0.8853 - val_loss: 0.3192 - val_sparse_categorical_accuracy: 0.8842
Epoch 14/20
1500/1500 ━━━━━━━━━━━━━━━━━━━━ 5s 3ms/step - loss: 0.2937 - sparse_categorical_accuracy: 0.8896 - val_loss: 0.3180 - val_sparse_categorical_accuracy: 0.8848
Epoch 15/20
1500/1500 ━━━━━━━━━━━━━━━━━━━━ 5s 3ms/step - loss: 0.2946 - sparse_categorical_accuracy: 0.8863 - val_loss: 0.3163 - val_sparse_categorical_accuracy: 0.8871
Epoch 16/20
1500/1500 ━━━━━━━━━━━━━━━━━━━━ 6s 4ms/step - loss: 0.2913 - sparse_categorical_accuracy: 0.8903 - val_loss: 0.3305 - val_sparse_categorical_accuracy: 0.8871
Epoch 17/20
1500/1500 ━━━━━━━━━━━━━━━━━━━━ 4s 3ms/step - loss: 0.2872 - sparse_categorical_accuracy: 0.8900 - val_loss: 0.3176 - val_sparse_categorical_accuracy: 0.8879
Epoch 18/20
1500/1500 ━━━━━━━━━━━━━━━━━━━━ 5s 3ms/step - loss: 0.2837 - sparse_categorical_accuracy: 0.8921 - val_loss: 0.3220 - val_sparse_categorical_accuracy: 0.8875
Epoch 19/20
1500/1500 ━━━━━━━━━━━━━━━━━━━━ 6s 4ms/step - loss: 0.2824 - sparse_categorical_accuracy: 0.8930 - val_loss: 0.3161 - val_sparse_categorical_accuracy: 0.8898
Epoch 20/20
1500/1500 ━━━━━━━━━━━━━━━━━━━━ 5s 3ms/step - loss: 0.2758 - sparse_categorical_accuracy: 0.8943 - val_loss: 0.3204 - val_sparse_categorical_accuracy: 0.8884
```
```python
plot_train_val_losses(result)
```
<img width="576" height="432" alt="image" src="https://github.com/user-attachments/assets/8181f89f-4467-4b1e-8a77-214abefc901c" />

# 모델 저장과 복원

```python
model.summary()
```
<img width="586" height="252" alt="image" src="https://github.com/user-attachments/assets/dbb23f0a-7951-44af-b1ce-5f35af98a96f" />

```python
len(model.weights)
```
<img width="24" height="28" alt="image" src="https://github.com/user-attachments/assets/85a23998-1f85-456b-aab5-df87cbc11b67" />

```python
model.weights[0]    # (784, 100) shape. 첫번째 은닉층에서 학습된 가중치들. (784, 100) shape.
```
<img width="1116" height="215" alt="image" src="https://github.com/user-attachments/assets/c63ffa1d-3e0b-49a6-b8f2-a23f7d05857e" />

```python
model.weights[1]    # (100,) shape. 번째 은닉층에서 학습된 bias들.
```
<img width="1004" height="398" alt="image" src="https://github.com/user-attachments/assets/903add15-4bfc-49e6-8e49-45411b70ce3a" />

```python
model.weights[3]    # (10,) shape. 출력층에서 학습된 bias들.
```
<img width="1083" height="39" alt="image" src="https://github.com/user-attachments/assets/eca19bf5-a292-47e8-8977-c7e4b0165f50" />

## 모델 저장

```python
path = '/content/drive/MyDrive/Colab Notebooks/lab_da'

# 모델 파라미터들만 저장하는 파일의 확장자는 '.weights.h5'
weights_file = path + '/model1.weights.h5'  # 파일 이름 + 확장자

# 훈련이 끝난 모델을 저장하는 파일의 확장자는 '.keras'
model_file = path + '/model1.keras'
```
```python
# 모델 파라미터들만 저장
model.save_weights(weights_file)
```
```python
# 모델의 구조와 모델 파라미터들을 함께 저장
model.save(model_file)
```

## 파일에 저장된 모델을 복원

### 모델 파라미터들만 저장한 파일(weight.h5)에서 복원

```python
# 모델 파라미터와 같은 구조로 모델을 먼저 생성.
model = create_model(layers = [keras.layers.Dropout(rate = 0.3)])
```
```python
# 생성된 모델에서 load_weights 메서드 호출, 아규먼트는 저장된 가중치 파일.
model.load_weights(weights_file)
```

```
모델 파라미터들만 복원한 경우에는 모델이 컴파일되어 있지 않은 상태이기 때문에 evaluate() 메서드를 호출할 수 없음. 모델 파라미터(가중치들)들은 모두 복원이 됐기 때문에 `predict()` 메서드는 호출 가능.
```

```python
predicts = model.predict(x = train_data_scaled)
```
<img width="465" height="26" alt="image" src="https://github.com/user-attachments/assets/d69ff743-ed50-400d-a325-c3e66affe2e1" />

```python
predict_labels = predicts.argmax(axis = 1)
# predicts 배열에서 가장 높은 확률을 가진 클래스의 인덱스를 찾는 역할
# argmax() 배열에서 가장 큰 값의 인덱스를 반환하는 함수
# axis = 1 행 방향으로 적용
```
```python
accuracy_score(train_target, predict_labels)
```
<img width="56" height="31" alt="image" src="https://github.com/user-attachments/assets/d4aea62b-5b63-46e6-9299-2155498dc921" />

### 모델 구조와 파라미터들을 저장한 파일(keras)에서 모델을 복원

```python
# keras.models.load_model() 함수 호출, 모델을 저장할 파일(.keras)을 아규먼트로 줌.
model = keras.models.load_model(model_file, compile = True)
```


확장자가 .keras인 파일에서 모델을 복원하는 경우는 컴파일이 끝난 모델을 복원함. `evaluate()` 메서드와 `predict()` 메서드들을 모두 사용할 수 있음.


```python
model.evaluate(x = train_data_scaled, y = train_target)
```
<img width="830" height="42" alt="image" src="https://github.com/user-attachments/assets/2fe9572c-e21e-41a7-89d5-4dd5fb9b4a4a" />

# Callback


*   callback(콜백): 훈련 과정 중간에 어떤 작업을 수행할 수 있게 만드는 객체. `keras.callbacks`모듈 아래의 클래스들을 사용할 수 있음.
*   `keras.callbacks.ModelCheckpoint` 클래스
    *   epoch마다 모델을 저장할 수 있는 기능을 가지고 있는 클래스.
    *   `save_best_only` 파라미터를 True로 설정해서 가장 검증 손실이 작은 모델만을 저장할 수 있음.
*   `keras.callbacks.EarlyStopping` 클래스
    *   과대적합이 시작되기 전에 훈련을 일찍 종료시킬 수 있는 기능을 가지고 있는 클래스.
    *   `fit()` 메서드에서 설정된 epochs 횟수보다 일찍 모델 훈련이 종료될 수 있음.

```python
# 모델 생성
model = create_model(layers = [keras.layers.Dropout(rate = 0.3)])
```
```python
# 모델 컴파일
model.compile(optimizer = keras.optimizers.Adam(), 
              loss = keras.losses.sparse_categorical_crossentropy,
              metrics = [keras.metrics.sparse_categorical_accuracy])
```
```python
# 모델 체크포인트 콜백 객체 생성
checkpoint_cb = keras.callbacks.ModelCheckpoint(filepath = path + '/best_model.keras',
                                                save_best_only = True)
# save_best_only = True -> 모니터링 지표가 최고 성능을 기록했을 때만 모델 저장
# filepath -> 모델을 저장할 경로와 파일명 지정
```
```python
# 조기종료 콜백 객체 생성
early_stop_cb = keras.callbacks.EarlyStopping(patience = 3,  # patience 숫자가 크면 조기종료가 늦게 되는 거(손실이 늘어나도 3번까지는 기다려주겠다)
                                              restore_best_weights = True)
```
```python
# 검증 셋과 콜백들을 설정해서 모델을 훈련
result = model.fit(x = train_data_scaled, y = train_target, epochs = 100,
                    callbacks = [checkpoint_cb, early_stop_cb],
                    validation_data = [val_data_scaled, val_target])
```
<img width="1283" height="295" alt="image" src="https://github.com/user-attachments/assets/212cd509-1ec4-4b8a-818e-daec1763de1d" />

```python
plot_train_val_losses(result)
```
<img width="576" height="432" alt="image" src="https://github.com/user-attachments/assets/1b51348f-f1cf-4c02-8517-54ff9fa54deb" />

```python
# 훈련이 끝난 모델 평가
model.evaluate(x = train_data_scaled, y = train_target)     # 훈련셋
```
<img width="841" height="41" alt="image" src="https://github.com/user-attachments/assets/09e71119-2f12-4986-928b-1101531838e7" />

```python
model.evaluate(x = val_data_scaled, y = val_target)         # 검증셋
```
<img width="813" height="39" alt="image" src="https://github.com/user-attachments/assets/198cfdc9-76de-4cd1-bfc4-b6df7e0a839c" />

```python
# 최적의 파라미터들과 모델 구조를 저장한 파일에서 모델을 복원
best_model = keras.models.load_model(filepath=path + '/best_model.keras')
```
```python
best_model.evaluate(x = train_data_scaled, y = train_target)
```
<img width="834" height="41" alt="image" src="https://github.com/user-attachments/assets/a6e8508a-f7ee-4f3a-97b3-b12e705882f5" />

```python
best_model.evaluate(x = val_data_scaled, y = val_target)

```
<img width="814" height="41" alt="image" src="https://github.com/user-attachments/assets/d9d4b7ab-040f-4227-9d99-2e10f20d76be" />


--------------

# CNN(Convolution Neural Network)

# Imports

```python
import numpy as np
import matplotlib.pyplot as plt

from scipy.signal import convolve, convolve2d, correlate, correlate2d
from sklearn.datasets import load_sample_image
from sklearn.model_selection import train_test_split

import keras
```

# 1차원 합성곱 연산(1-D Convolution)

```python
x = np.arange(1, 5)
print(x)
```
<img width="74" height="26" alt="image" src="https://github.com/user-attachments/assets/d44d204c-583a-431f-861b-c9fc426973da" />

```python
y = np.array([1, 2])
print(y)
```
<img width="46" height="28" alt="image" src="https://github.com/user-attachments/assets/f0cffa3d-190c-41fc-ba20-e8208e65d8d0" />

```python
y_filp = np.flip(y)
print(y_flip)
# 좌우 반전으로 만들어진 배열
```
<img width="47" height="28" alt="image" src="https://github.com/user-attachments/assets/6074b6ba-98c5-4d95-bcc4-db7b8169e2e1" />

## convolve 함수


scipy.signal.convolve 함수는 배열 y를 filp(반전)시킨 후 연산을 수행.



<img width="550" height="540" alt="image" src="https://github.com/user-attachments/assets/5f45a708-2d28-4462-ba95-8e0fa2b7553d" />
