# Imports

```python
import numpy as np
import matplotlib.pyplot as plt

from scipy.signal import convolve, convolve2d, correlate, correlate2d
from sklearn.datasets import load_sample_image
from sklearn.model_selection import train_test_split

import keras
```

```
# Python에서의 이미지

*   숫자들의 배열.
*   숫자들의 스케일:
    *   0 ~ 255 정수 스케일(부호가 없는 1바이트(8비트) 정수, np.uint8)
    *   0.0 ~ 1.0 실수 스케일
*   배열의 모양
    *   흑백 이미지: (height, width) shape의 2차원 배열. 
    *   컬러 이미지: (height, width, channel) shape의 3차원 배열.
        *   불투명한 이미지인 경우, (height, width, 3). channel = rgb
        *   투명한 이미지인 경우, (height, width, 4). channel = rgba
    *   Keras 패키지에서는 합성곱 층에서 흑백 이미지를 사용할 때, 컬러 이미지처럼 3차원 배열을 사용.
        *   흑백 이미지를 (height, width, 1) shape의 3차원 배열로 취급(channel이 한개).
```

# CNN(Convolutional Neural Network, 합성곱 신경망)


Input --> Conv2D --> MaxPooling2D --> Conv2D --> MaxPooling2D --> Flatten --> Dense --> Dropout --> Dense(Output)


<img width="3999" height="1178" alt="image" src="https://github.com/user-attachments/assets/8948d40a-c68e-4cf1-aec3-777ab7f165ef" />


## Fashion MNIST datasets

```python
# 훈련셋, 훈련 레이블, 테스트셋, 테스트 레이블
(x_train_full, y_train_full), (x_test, y_test) = keras.datasets.fashion_mnist.load_data()
```
<img width="783" height="135" alt="image" src="https://github.com/user-attachments/assets/fe6053b8-2f37-4f18-a975-86ce3ebf1312" />

```python
print(x_train_full.shape)
print(y_train_full.shape)
# 60000개 샘플. 세로 x 가로 -> 28 x 28
```
<img width="117" height="41" alt="image" src="https://github.com/user-attachments/assets/1aa750c8-52c3-4e80-927d-b39a43ae838e" />

```python
# 훈련 셋을 (60_000, 28, 28) 모양에서 (60_000, 28, 28, 1) 모양으로 변환하고,
# 0 ~ 1 사이의 범위 숫자로 스케일링.
x_train_full_scaled = x_train_full.reshape((-1, 28, 28, 1)) / 255.0
# -1은 60000개를 그대로 유지하기 위해서. 60000으로 써도 됨.

x_test_scaled = x_test.reshape((-1, 28, 28, 1)) / 255.0    # 여기서 -1은 10_000개
```
```python
# 전체 훈련 셋과 훈련 레이블을 훈련 셋과 검증 셋으로 나눔.
x_train, x_val, y_train, y_val = train_test_split(x_train_full_scaled, y_train_full,
                                                  test_size = 0.2, stratify = y_train_full,
                                                  random_state = 42)
# 위에랑 순서가 다름. 순서 주의!
# x_train_full이 x_train, x_val로 나누어지는 거
```
```python
print(x_train.shape)
print(x_val.shape)
```
<img width="139" height="38" alt="image" src="https://github.com/user-attachments/assets/794545a3-bdbd-4092-a8e6-36357a419717" />

## 합성곱 신경망 생성


*   filter(필터): 합성곱 층에서의 unit(neuron).
*   kernel(커널): filter(필터와 같은 개념으로 생각하기도 함). 합성곱 연산에서 곱해지는 가중치(filter의 값들).
*   feature map(특성 맵): 합성곱 연산의 결과로 나오는 출력.
*   padding(패딩): 입력 배열 주위에 가상의 값(0)을 채우는 것.
    *   same padding: 입력과 특성 맵의 크기를 같게 만들어 주는 패딩 방식.
    *   valid padding: 패딩 없이 합성곱을 수행. 특성 맵의 크기는 입력 배열의 크기보다 작아짐.
*   stride(보폭): filter를 이동시키는 보폭. 합성곱 연산에서는 일반적으로 stride = 1.
    *   합성곱 층의 stride를 크게해서 이미지 사이즈를 줄이는 방법보다는, 풀링 층을 사용해서 이미지의 크기를 줄이는 방법을 선호.
*   pooling(풀링):
    *   가중치(kernel 값)가 없고, 일반적으로 풀링의 크기와 보폭의 크기를 같게 함.
    *   일반적으로 패딩을 사용하지 않음. padding = 'valid'.
    *   max pooling(최대 풀링): filter 안의 입력값들 중 최댓값을 선택.
    *   average pooling(평균 풀링): filter 안의 입력 값들의 평균을 계산.
    *   평균 풀링은 특성 맵의 중요한 정보들을 희석시킬 수 있기 때문에, 최대 풀링을 더 선호.
 

```
# 입력 (28, 28) filter (3, 3)

# 28 - 3 + 1 = 26
```
```python
# Sequential 객체 생성
# 순차적 모델은 여러 개의 층을 쌓아 올린 신경망 모델
model = keras.Sequential()
```
```python
# 입력 층(input layer) - (height, width, n_channels)
inputs = keras.Input(shape = (28, 28, 1))
model.add(inputs)
# 입력층 연결

# 입력 데이터 크기 (28, 28, 1)
# 생성한 입력 층을 Sequential 모델에 추가
```
<img width="222" height="166" alt="image" src="https://github.com/user-attachments/assets/e1fc47d0-b742-49d6-9ec4-059d2156818d" />

```python
# 합성곱 층(convolutional layer). 특징 추출하기 위해
conv_1 = keras.layers.Conv2D(filters = 32, kernel_size = 3,
                             padding = 'same', activation = 'relu')
model.add(conv_1)

# 2D 이미지 데이터에 적용되는 합성곱 연산을 수행하는 레이어.
# 입력 데이터에 여러 개의 filter를 적용하여 새로운 feature map을 만든다
# filter의 갯수(unit의 갯수) 32, 크기 3 x 3
# activation = 'relu' 합성곱 연산의 결과에 적용되는 활성화 함수. 음수 값을 모두 0, 양수 값은 그대로 유지.
```
<img width="628" height="222" alt="image" src="https://github.com/user-attachments/assets/a45f4a89-4ac8-401d-88a3-654aa563dbda" />

```
kernel 다 똑같은 모양이만 값들은 다름 
input은 48000개
same 패딩이라서 원본 이미지에서 픽셀의 값은 변경되지만 크기는 같음
```
```python
# 최대 풀링 층(max pooling layer). 특징 맵 크기 줄이기 위해
max_pool_1 = keras.layers.MaxPool2D()
model.add(max_pool_1)
```
<img width="755" height="498" alt="image" src="https://github.com/user-attachments/assets/d839bd65-029e-4324-8a73-055c07f26f40" />

```
channel의 갯수는 안바뀜
32개의 이미지 모두 14 x 14로 바뀜
```
```python
conv_2 = keras.layers.Conv2D(filters = 64, kernel_size = 3,
                             padding = 'same', activation = 'relu')
model.add(conv_2)
```
```python
max_pool_2 = keras.layers.MaxPool2D()
model.add(max_pool_2)
```
```python
# flatten layer: 입력 배열(특성 맵)을 2차원 배열로 변환.
model.add(kears.layers.Flatten())
```
```python
# 밀집 층(dense hidden layer)
dense_1 = keras.layers.Dense(units = 100, activation = 'relu')  # 100개의 뉴런을 만들어 줌
model.add(dense_1)
```
```python
# drop-out layer(과대적합을 줄이기 위해서)
model.add(keras.layers.Dropout(rate = 0.3))  # 훈련 단계에서 각 에포크마다 입력 뉴런의 30%를 무작위로 뉴런 연결을 끊음
```
```python
# 출력 층(output layer)
dense_2 = keras.layers.Dense(units = 10, activation = 'softmax')
model.add(dense_2)
# 소프트맥스 활성화 함수는 각 뉴런의 출력을 모든 뉴런 출력의 합이 1이 되도록 정규화된 확률로 변환
```
```
filter의 수
점진적으로 증가 시킴
증가시키는 이유 : 낮은 수준의 특징(선, 모서리 등)을 감지하고, 이 특징들을 조합하여 모델이 더 복잡한 고수준의 특징(눈, 코, 귀)를 학습할 수 있도록 필터 수를 늘림
보통 32 -> 64 -> 128 -> 256 이렇게 늘림

kernel의 크기
3x3과 같은 작은 커널을 여러 층 쌓는 것이 5x5와 같은 큰 커널 하나를 사용하는 것보다 효과적이라서 작은 크기를 선호함
```
```python
model.summary()
```
<img width="552" height="353" alt="image" src="https://github.com/user-attachments/assets/a0836648-7157-467f-9de1-a43c985aa289" />

```
model.summary에서는 입력층은 나타나지 않음. 

conv2d (Conv2D) : 입력 이미지에서 특징을 추출하는 합성곱 층
Output Shape : 28x28 크기의 이미지가 32개의 특징 맵(feature maps)으로 변환
Param # -> (9 + 1) * 32 = 320. 이 층의 필터(커널)와 편향(bias)을 포함한 학습 가능한 매개변수

max_pooling2d_2 (MaxPooling2D) : 특징 맵의 크기를 줄이는 최대 풀링 층
Output Shape: 이미지 크기가 28x28에서 14x14로 절반으로 줄어들고, 특징 맵의 수는 그대로 유지
Param # -> 0. 풀링 층은 학습 가능한 매개변수가 없음

conv2d_1 (Conv2D) : 더 복잡한 특징을 추출하는 두 번째 합성곱 층
Output Shape: 특징 맵의 수가 32개에서 64개로 늘어남
Param # -> (3 * 3 * 32 + 1) * 64 = 18,496. 첫 번째 합성곱 층보다 더 많은 특징을 학습하므로 매개변수도 늘어남

max_pooling2d_3 (MaxPooling2D): 두 번째 풀링 층으로, 데이터 크기를 다시 줄임
Output Shape: 크기가 14x14에서 7x7로 줄어든다
Param #: 0.

flatten (Flatten): 2차원 또는 3차원 형태의 특징 맵을 다음 완전 연결 층을 위해 1차원 배열로 펼칩니다.
Output Shape: 7x7x64 = 3136개의 뉴런을 가진 1차원 벡터가 됨
Param #: 0.

dense (Dense): 분류를 위한 첫 번째 완전 연결 층
Output Shape: 100개의 뉴런을 가짐
Param #: (3136 + 1) * 100 = 313,700. 3136개의 입력 뉴런과 100개의 뉴런 간의 연결 가중치 및 편향입니다.

dropout (Dropout): 과적합을 방지하는 정규화 층
Output Shape: 100개의 뉴런을 가짐
Param #: 0.

dense_1 (Dense): 최종 출력 층
Output Shape: 10개의 클래스로 분류하는 작업임을 나타냅니다.
Param #: 100개의 입력 뉴런과 10개의 출력 뉴런 간의 연결 -> 1,010

333,526. 모델이 가진 모든 매개변수의 총합
```
```python
keras.utils.plot_model(model, dpi = 64)       # 만들어진걸 그림으로 표현. dpi의 숫자가 크면 그림 크기가 작아짐
```
<img width="129" height="551" alt="image" src="https://github.com/user-attachments/assets/6838264e-5adb-4fc6-9848-cd7a3b872a09" />

```python
keras.utils.plot_model(model, dpi = 64, show_shapes = True)    # input, output 모양이 나오는거
```
<img width="399" height="828" alt="image" src="https://github.com/user-attachments/assets/2875db58-bfd8-4f45-91db-b9e049fd34d4" />

```python
# 모델 컴파일
# 모델을 훈련하기 전에 컴파일하는 과정. 컴파일은 모델이 학습을 시작할 수 있도록 학습 방법, 성능 평가 기준 등을 설정하는 단계
model.compile(optimizer = keras.optimizers.Adam(), 
              loss = keras.losses.sparse_categorical_crossentropy,
              metrics = [keras.metrics.sparse_categorical_accuracy])
```
```python
# 모델 파일 저장 위치
dir_path = '/content/drive/MyDrive/Colab Notebooks/lab_da/'
model_file = dir_path + 'cnn_best_model.keras'

# 콜백 생성
checkpoint = keras.callbacks.ModelCheckpoint(model_file, save_best_only=True)
early_stop = keras.callbacks.EarlyStopping(patience = 3, restore_best_weights = True)   # restore_best_weights = True 가장 좋을 때 파라미터 복원
```
```python
# 모델 훈련
result = model.fit(x = x_train, y = y_train, epochs = 100, 
                   callbacks = [checkpoint, early_stop],
                   validation_data = [x_val, y_val])
# epochs가 100이 되기 전에 끝날 수도 있음
```
<img width="1280" height="323" alt="image" src="https://github.com/user-attachments/assets/1752ef9f-01ce-4b8b-9ba2-42385069b745" />

```python
type(result)
```
<img width="742" height="357" alt="image" src="https://github.com/user-attachments/assets/0f0ff9a3-3291-44d0-9dba-2f0304480919" />

```python
result.epoch    # type이 list. 0 ~ 9까지 진행되었다는거(10번째 epochs에서 끝나서)
```
<img width="225" height="28" alt="image" src="https://github.com/user-attachments/assets/e9c97f84-c3c2-405a-8dd0-be5de5d7abf6" />

```python
result.history  # dict
```
<img width="404" height="633" alt="image" src="https://github.com/user-attachments/assets/c28cb03a-8a55-4f9b-9d64-3490881e57b6" />


### History 객체를 사용해서 (훈련/검증)손실 그래프를 그리세요.

```python
epochs = result.epoch
history = result.history
plt.plot(epochs, history['loss'], 'bo-', label = 'train')
plt.plot(epochs, history['val_loss'], 'ro:', label = 'validation')
plt.grid()
plt.legend()
plt.xlabel('epoch')
plt.ylabel('loss')
plt.show()
```
<img width="576" height="432" alt="image" src="https://github.com/user-attachments/assets/efeede96-c68b-418e-a204-619bc84a25de" />

## 모델 평가

```python
model.evaluate(x = x_train, y = y_train)    # 훈련 셋 정확도
```
<img width="849" height="45" alt="image" src="https://github.com/user-attachments/assets/2e720595-b9c0-4ad2-bfe5-96ca1ea97cad" />

```python
model.evaluate(x = x_val, y = y_val)
```
<img width="820" height="39" alt="image" src="https://github.com/user-attachments/assets/003b04a7-9f71-4885-82ed-d738bea4cb20" />

## 예측

```python
predicts = model.predict(x = x_train[:5])
print(predicts)     # 10개 클래스가 될 확률들.
```
<img width="527" height="181" alt="image" src="https://github.com/user-attachments/assets/f669e113-a680-4324-94a8-3dc63220858f" />

```
10개씩 숫자를 가지고 있음. 첫번재 1차원 배열에서 가장 큰 숫자는 9.4682795e-01(약 94%)
```
```python
predicts.argmax(axis = 1)   # 10개의 확률들 중에서 최댓값의 인덱스. axis =1 방향으로 최댓값의 인덱스를 반환. 
# 예측 레이블
```
<img width="165" height="21" alt="image" src="https://github.com/user-attachments/assets/dae2874d-e4a6-4a68-868d-e700c55a6081" />

```python
y_train[:5]     # 실제 레이블
```
<img width="260" height="29" alt="image" src="https://github.com/user-attachments/assets/8a31d565-f4f3-4107-b1ba-8347abcb32c8" />

```
5개 중에 4개는 맞추고 1개는 틀림
```

### 훈련 셋의 confusion matrix, 검증 셋의 confusion matrix

```python
train_predicts = model.predict(x = x_train)     # 훈련 셋에서의 예측 확률들
train_pred_labels = train_predicts.argmax(axis = 1)     # 훈련 셋에서의 예측값들
```
<img width="468" height="25" alt="image" src="https://github.com/user-attachments/assets/739b2d72-4537-4396-ac29-a1b0866bc8f6" />

```python
conf_mat = confusion_matrix(y_true=y_train, y_pred=train_pred_labels)
print(conf_mat)
```
<img width="380" height="169" alt="image" src="https://github.com/user-attachments/assets/c577f100-29ee-4086-9845-013d1b7e7dd9" />

```python
sns.heatmap(data = conf_mat, cmap = 'Blues')
plt.show()
```
<img width="528" height="413" alt="image" src="https://github.com/user-attachments/assets/0b60dbf6-58cb-4d64-b4f3-664219ba57ef" />

```python
val_predicts = model.predict(x=x_val)  # 검증 셋에서의 예측 확률들
val_pred_labels = val_predicts.argmax(axis=1)  # 검증 셋에서의 예측값들
```
<img width="463" height="27" alt="image" src="https://github.com/user-attachments/assets/226e2963-4f74-46d4-a578-1b681dd44717" />

```python
val_conf_mat = confusion_matrix(y_true=y_val, y_pred=val_pred_labels)
print(val_conf_mat)
```
<img width="381" height="166" alt="image" src="https://github.com/user-attachments/assets/671dde96-3d54-4f9a-ba0f-7a4f026aba74" />

```python
sns.heatmap(data=val_conf_mat, cmap='Blues')
plt.show()
```
<img width="528" height="413" alt="image" src="https://github.com/user-attachments/assets/fed0b93e-5113-487f-9f4e-141038b3bf17" />
