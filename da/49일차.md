# Bagging Ensemble

```python
bagging_clf = BaggingClassifier(estimator = DecisionTreeClassifier(random_state = 42),
                                n_estimators = 50,  # 총 50개의 개별 모델을 학습시킴
                                oob_score = True,
                                n_jobs = -1,
                                random_state = 42)
```
```
하나의 데이터셋을 무작위로 50번 샘플링(중복 허용)
각각의 데이터셋에 대해 하나씩 Decision Tree 모델 학습
50개 모델의 결과를 투표 또는 평균으로 합산하는 구조
```


BaggingClassifier의 파라미터들:
- estimator: 기본 추정기(예측기). 머신 러닝 모델 객체.
- n_estimators: 추정기(예측기)의 개수. 기본값 10.
- max_samples: 훈련 셋의 부분 집합이 가질 수 있는 최대 샘플 개수(정수) 또는 비율(0 ~ 1.0).
  기본값은 1.0
- bootstrap: True(중복 허용 샘플링, bagging). False(중복 불허 샘플링, pasting). 기본값은 True.
- oob_score: True(OOB 샘플로 평가 점수 계산). False(OOB 샘플로 평가 점수를 계산하지 않음). 기본값은 False.
  - OOB(Out-Of-Bagging) 샘플: 중복 허용 샘플링을 하는 동안 한 번도 샘플링되지 못하고 남아 있는 훈련 셋의 샘플.
  - OOB sample은 validation set 역할을 할 수 있음.
 

```python
bagging_clf.fit(X_tr, y_tr)
```
<img width="376" height="187" alt="image" src="https://github.com/user-attachments/assets/217696e3-314f-4020-b353-0320145da59e" />

```python
bagging_clf.score(X_tr, y_tr)  # 훈련 셋 정확도
```
<img width="50" height="34" alt="image" src="https://github.com/user-attachments/assets/5be4936e-09e8-437f-94a0-e5b55272cc4a" />

```python
bagging_clf.score(X_te, y_te)  # 테스트 셋 정확도
```
<img width="67" height="33" alt="image" src="https://github.com/user-attachments/assets/1dc2bf83-3312-45e7-a05f-30ba21198533" />

```python
bagging_clf.oob_score_    # 테스트 셋 정확도랑 비슷한 결과
```
<img width="64" height="38" alt="image" src="https://github.com/user-attachments/assets/c4779b24-6bb8-4d59-b814-505f438d3652" />


- estimator = DecisionTree() 사용.
  - n_estimators = 100 설정하고 교차검증(cross_validate)
  - n_estimators = 50, max_samples = 100 설정하고 교차검증(cross_validdate)
 

```python
bagging_clf = BaggingClassifier(estimator = DecisionTreeClassifier(random_state = 42),
                                n_estimators = 100,
                                n_jobs = -1,
                                random_state = 42)
```
```python
cv = cross_validate(estimator = bagging_clf, X = X_tr, y = y_tr, n_jobs = -1, return_train_score = True)
```
```python
cv.keys()
```
<img width="610" height="40" alt="image" src="https://github.com/user-attachments/assets/c57f9504-5a2f-4f34-94ba-1db40f58d2c7" />

```python
cv
```
<img width="774" height="101" alt="image" src="https://github.com/user-attachments/assets/515ce02e-747e-45dd-92e1-43e41ebae55e" />

```python
print('train score:', np.mean(cv['train_score'])
print('validation score', np.mean(cv['test_score']))
```
<img width="244" height="58" alt="image" src="https://github.com/user-attachments/assets/a4bc0cb7-7513-4780-91a9-8364b530e432" />

```python
bagging_clf = BaggingClassifier(estimator = DecisionTreeClassifier(random_state = 42),
                                n_estimators = 50,
                                max_samples = 100,  # 100개 까지만 샘플링 해라
                                n_jobs = -1,
                                random_state = 42)
```
```python
cv = cross_validate(estimator = bagging_clf, X = X_tr, y = y_tr, n_jobs = -1, return_train_score = True)
```
```python
cv
```
<img width="775" height="107" alt="image" src="https://github.com/user-attachments/assets/aa5f09c6-1ed3-4928-9892-f9c00813f4aa" />

```python
print('train score:', np.mean(cv['train_score'])
print('test score:', np.mean(cv['test_score']))
```
<img width="308" height="55" alt="image" src="https://github.com/user-attachments/assets/795b9543-0d5e-493d-a292-b05be17115a4" />

# Random Forest

bagging을 사용한 Decision Tree들의 앙상블 학습.

```python
forest_clf = RandomForestClassifier(n_estimators = 50, max_samples = 100, random_state = 42, n_jobs = -1)
```

Random Forest: bagging을 사용한 Decision Tree들의 앙상블 학습.
- DecisionTreeClassifier와 BaggingClassifier의 파라미터들을 가짐.
- GridSearchCV 또는 RandomizedSearchCV을 사용해서 tree와 bagging의 하이퍼 파라미터들을 튜닝할 수 있음.


```python
cv = cross_validate(estimator = forest_clf, X = X_tr, y = y_tr, return_train_score = True, n_jobs = -1)
```
```python
cv
```
<img width="759" height="103" alt="image" src="https://github.com/user-attachments/assets/7c343513-62b6-471d-8cf1-d7d6ffe01a06" />

```python
print('train score:', np.mean(cv['train_score']))
print('validation score:', np.mean(cv['test_score']))
```
<img width="354" height="50" alt="image" src="https://github.com/user-attachments/assets/23766896-4bd0-438a-b090-d1c2785126d6" />


# Random Forest를 사용한 wine 데이터셋 분류

## 데이터셋 준비
```python
wine = pd.read_csv('https://bit.ly/wine_csv_data')
wine.head()
```
<img width="314" height="226" alt="image" src="https://github.com/user-attachments/assets/cc627a05-1d35-4208-b6d7-3e3da6deaa0e" />

```python
X = wine[wine.columns[:3]].values  # wine.drop(columns = ['class']).values
y = wine['class'].values  # 타겟 배열
```
```python
X[:5, :]
```
<img width="270" height="117" alt="image" src="https://github.com/user-attachments/assets/ede7bb1c-a211-40de-b1b3-fa92f28ce41a" />

```python
y[:5]
```
<img width="265" height="39" alt="image" src="https://github.com/user-attachments/assets/0f669d4d-7b7c-4b6a-ade5-32f2db8df11d" />

```python
X.shape
```
<img width="102" height="37" alt="image" src="https://github.com/user-attachments/assets/c197203c-d2d3-427b-8f39-929689699982" />

```python
y.shape
```
<img width="88" height="42" alt="image" src="https://github.com/user-attachments/assets/7ebaf3ee-993f-42fd-ac57-51555802a696" />

```python
X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size = 0.2, random_state = 42)
```

## 모델 훈련

```python
forest_clf = RandomForestClassifier(random_state = 42, n_jobs = -1)
```
```python
cv = cross_validate(estimator = forest_clf, X = X_tr, y = y_tr, return_train_score = True, n_jobs = -1)  # return_train_score = True은 과대적합 확인하기 위해서
```
```python
print('train score:', np.mean(cv['train_score']))
print('validation score:', np.mean(cv['test_score']))
# Random Forest는 과대적합이 크다.
```
<img width="349" height="60" alt="image" src="https://github.com/user-attachments/assets/99bf3133-3bbb-475c-bc4a-a4cc8a024460" />

## 하이퍼 파라미터 튜닝
```python
# estimator 생성
forest_clf = RandomForestClassifier(n_jobs = -1, random_state = 42)
```
```python
# 파라미터 그리드(parameter grid)
params = {
    'n_estimators': [10, 20, 50, 100, 120],
    'max_depth': np.arange(2, 11),
    'min_samples_split': [2, 10, 20],
    'min_impurity_decrease': [0, 0.001, 0.01, 0.1]
}
```
```python
grid_search = GridSearchCV(estimator = forest_clf, param_grid = params, n_jobs = -1)
```
```python
grid_search.fit(X_tr, y_tr)
```
<img width="444" height="197" alt="image" src="https://github.com/user-attachments/assets/ce75ce26-4080-4fc5-86d5-203ac2d636ac" />

```python
grid_search.best_score_
```
<img width="287" height="34" alt="image" src="https://github.com/user-attachments/assets/779f41c9-3baf-4b99-bf29-f257b5263082" />

```python
grid_search.best_params_
```
<img width="270" height="100" alt="image" src="https://github.com/user-attachments/assets/fb837f98-2e01-4864-8b2e-9d6caa6ff07c" />

```python
best_model = grid_search.best_estimator_
```
```python
best_model.score(X_tr, y_tr)  # Random Forest 기본 파라미터들 보다 과대적합이 작아짐.
```
<img width="188" height="37" alt="image" src="https://github.com/user-attachments/assets/1a6463b4-13e6-416a-8457-e37b16a6317f" />


# Extra Tree

*   Random Forest와 비슷한 점:
    *   여러 개(기본값은 100)의 decision tree들을 훈련.
    *   decision tree의 파라미터들을 튜닝할 수 있음.
*   Random Forest와 다른 점:
    *   Bagging(Bootstrap Aggregating)을 사용하지 않음.
        *   여러 개의 tree들을 전체 훈련 셋을 사용해서 학습시킴.
    *   노드를 분할할 때 가장 좋은 분할 방법을 찾는 게 아니라, 무작위로 분할함.
        *   Random Forest는 최적의 분할 방법을 찾기 위해서 많은 훈련 시간이 필요함.
        *   Extra Tree는 무작위 분할을 하기 때문에 훈련 시간이 빠름.
     

```python
# Extra Tree 객체 생성
extra_tree = ExtraTreesClassifier(n_jobs = -1, random_state = 42)
```
```python
cv = cross_validate(estimator = extra_tree, X = X_tr, y = y_tr, n_jobs = -1, return_train_score = True)
```
```python
cv
```
<img width="780" height="109" alt="image" src="https://github.com/user-attachments/assets/dcd86b8b-2691-4687-aaaf-3e704b501140" />

```python
print('train score:', np.mean(cv['train_score']))
print('validation score:', np.mean(cv['test_score']))
```
<img width="339" height="59" alt="image" src="https://github.com/user-attachments/assets/7552e1da-63c0-499b-be65-6bd1fffc5131" />


# Gradient Boosting

*   깊이(depth)가 얕은 decision tree들을 순차적으로(직렬로) 연결해서 훈련시킴.
*   훈련시킬 때는, 이전 훈련 단계에서 발생한 오차들을 그 다음 훈련에서 가중치를 주고 훈련시킴.
*   장점: 깊이가 얕은 tree들을 사용하기 때문에, 과대적합이 작아지고 높은 일반화 성능을 기대할 수 있음.
*   단점: Random Forest처럼 병렬로 훈련시킬 수 없음. 훈련 시간이 느림.
*   Gradient Descent(경사하강법) + Decision Tree + Ensemble 파라미터들을 튜닝할 수 있음.


```python
grad_boost = GradientBoostingClassifier(random_state = 42)
```
```python
cv = cross_validate(estimator = grad_boost, X = X_tr, y = y_tr, n_jobs = -1,
                    return_train_score=True)
cv
```
<img width="775" height="100" alt="image" src="https://github.com/user-attachments/assets/3713900e-c092-4773-9bf2-dd2e477c9574" />

```python
print('train score:', np.mean(cv['train_score']))
print('validation score:', np.mean(cv['test_score']))
# 과대적합이 거의 없음.
```
<img width="352" height="56" alt="image" src="https://github.com/user-attachments/assets/dd23a2a4-2fd4-4985-b7bb-d86ea3e971a2" />


훈련셋과 검증셋에서 과대적합 보고 하이퍼파라미터 튜닝. (기본값부터 비교)

-------

# Preprocessing(전처리)

# Imports
```python
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split
from sklearn.compose import ColumnTransformer   # 특정 컬럼(들)만 변환할 때 사용
from sklearn.preprocessing import LabelEncoder, OrdinalEncoder, OneHotEncoder   # 문자열 -> 숫자로 변환할 때 사용
from sklearn.preprocessing import StandardScaler    # 전처리
from sklearn.pipeline import Pipeline
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import confusion_matrix, classification_report
```

# Penguins 데이터셋
```python
penguins = sns.load_dataset('penguins')
```
```python
penguins.head()
```
<img width="950" height="249" alt="image" src="https://github.com/user-attachments/assets/00fc17f9-92f4-4931-a859-b175004c4fa0" />

```python
penguins.info()
```
<img width="458" height="312" alt="image" src="https://github.com/user-attachments/assets/4f8b05ec-8897-4555-8410-5a61783bfcd2" />


DataFrame에서 NA가 포함된 행들은 모두 삭제

```python
df = penguins.dropna()
```
```python
df.info()
```
<img width="464" height="321" alt="image" src="https://github.com/user-attachments/assets/5f449ffa-49fb-469a-9159-31297a7026d9" />

# 데이터 탐색

## 카테고리 타입 변수 시각화
```python
fig, axes = plt.subplots(ncols = 3, figsize = (16, 4))

variables = ['species', 'island', 'sex']
for i, v in enumerate(variables):
    sns.countplot(data = df, x = v, ax = axes[i])

plt.show()
```
<img width="1653" height="485" alt="image" src="https://github.com/user-attachments/assets/1b93ebe7-b8b9-422e-9b02-2e8a117830bb" />

## 숫자 타입 변수 시각화

히스토그램

```python
fig, axes = plt.subplots(ncols = 4, figsize = (16, 4))

variables = df.columns[2:6]
for i, v in enumerate(variables):
    sns.histplot(data = df, x = v, ax = axes[i])
plt.show()
```
<img width="1693" height="468" alt="image" src="https://github.com/user-attachments/assets/1bc1967d-e719-4967-98b7-063186a7edbe" />


pairplot

```python
sns.pairplot(data = df, hue = 'species')
plt.show()
```
<img width="1111" height="986" alt="image" src="https://github.com/user-attachments/assets/87b5c81b-6738-4430-9477-7ad93ca8b8fb" />

```python
target = df['species']
features = df[df.columns[1:]]
```
```python
target
```
<img width="210" height="561" alt="image" src="https://github.com/user-attachments/assets/16122a88-2723-4402-a1c7-8e472535dc76" />

```python
features
```
<img width="852" height="516" alt="image" src="https://github.com/user-attachments/assets/364416b7-053f-4992-89ce-734cf2201ac9" />

# LabelEncoder
```
*   타겟 배열(1차원 배열)의 클래스들을 숫자(레이블)로 변환.
*   (예) Adelie -> 0, Chinstrap -> 1, Gentoo -> 2
*   1차원 배열 --> 1차원 배열
```
```python
label_enc = LabelEncoder()  # LabelEncoder 객체 생성
```
```python
result = label_enc.fit_transform(target)  # 훈련시키고 변화시키는 것
```
```python
result
```
<img width="661" height="367" alt="image" src="https://github.com/user-attachments/assets/164f2215-4d1a-4dd2-a129-3c087b54b65e" />

```python
label_enc.classes_    # 레이블로 변환된 클래스 이름들.
```
<img width="504" height="36" alt="image" src="https://github.com/user-attachments/assets/624d3f50-0e77-4a0c-86e5-1f747835bceb" />

# OrdinalEncoder
```
*   카테고리 타입 특성들을 정수들의 배열로 변환.
*   2차원 배열 --> 2차원 배열
    *   (n_samples, n_features) --(변환)--> (n_samples, n_features)
```
```python
ordinal_enc = OrdinalEncoder()
```
```python
result = ordinal_enc.fit_trainform(features[['island']])    # features[['island']] --> 2차원 배열로 줘야 함
```
```python
result[:5, :]
```
<img width="148" height="125" alt="image" src="https://github.com/user-attachments/assets/350360de-fb42-4e82-ace7-bdfa91166255" />

```python
ordinal_enc.categories_
```
<img width="517" height="40" alt="image" src="https://github.com/user-attachments/assets/fb465541-c572-4a11-8b4f-737fffd3473d" />

```python
result[-5:, :]
```
<img width="131" height="121" alt="image" src="https://github.com/user-attachments/assets/fd3bea16-b54a-4ff9-b064-e3f2e38073e4" />

```python
result = ordinal_enc.fit_trainsform(features[['island', 'sex']])
```
```python
result[:5, :]
```
<img width="173" height="131" alt="image" src="https://github.com/user-attachments/assets/3d75d06f-cf54-43d8-9a17-df9d12bcd7eb" />

# One-Hot Encoder
```
*   2차원 배열 --> 2차원 배열
*   (n_samples, features) --> (n_samples, n_encoded_features)
```
```python
onehot_enc = OneHotEncoder()
```
```python
result = onehot_enc.fit_transform(features[['island']])  # 리스트로 컬럼 이름 넘겨주기
```
```python
result
```
<img width="514" height="54" alt="image" src="https://github.com/user-attachments/assets/7f24db4e-509d-4690-809f-b44906509791" />

```python
result.toarray()[:5, :]    # 'Torgensen' -> [0 0 1] 변환
```
<img width="208" height="115" alt="image" src="https://github.com/user-attachments/assets/7db3aa21-0222-4253-85f6-af39bbbed79d" />

```python
result.toarray()[-5:, :]    # 'Biscoe' -> [1 0 0] 변환
```
```python
# island와 sex을 함께 one-hot encoding
result = onehot_enc.fit_transform(features[['island', 'sex']])
```
```python
result
```
<img width="513" height="43" alt="image" src="https://github.com/user-attachments/assets/cf903e4a-c6a7-4ac4-b568-611d90dc083a" />

```python
result.toarray()[:5, :]     # ['Torgensen', 'Male'] -> [0 0 1 0 1]
```
<img width="273" height="119" alt="image" src="https://github.com/user-attachments/assets/6d8b002a-5a87-4fbc-9948-6a3fff4646eb" />

# Column Transformer
```
*   컬럼별로 다른 변환기를 적용할 때 사용.
*   카테고리 컬럼들 - Encoder 적용(Ordinal, OneHot)
*   숫자 타입 컬럼들 - Scaler 적용(Standard, MinMax)
```
```python
features.columns
```
<img width="671" height="81" alt="image" src="https://github.com/user-attachments/assets/8beb378b-6253-428a-a394-c5e5c0a328fd" />

```python
# 카테고리 컬럼 이름들 선택 -> Encoder 적용
cat_cols = ['island', 'sex']

# 숫자 타입 컬럼 이름들 선택 -> Scaler 적용
num_cols = ['bill_length_mm', 'bill_depth_mm', 'flipper_length_mm', 'body_mass_g']
```
```python
# ColumnTransformer 객체 생성
col_transformer = ColumnTransformer(transformers = [('enc', OrdinalEncoder(), cat_cols),
                                                    ('scaler', StandardScaler(), num_cols)])
```
```python
result = col_transformer.fit_transform(features)
```
```python
result.shape
```
<img width="85" height="36" alt="image" src="https://github.com/user-attachments/assets/451284d9-4f73-48b5-8f63-758204de5958" />

```python
result[:5, :]   # 'island', 'sex',
```
<img width="673" height="230" alt="image" src="https://github.com/user-attachments/assets/c6a0e532-46c6-494d-8655-4a4a55128e4d" />

```python
col_transformer.named_transformers_     # dict
```
<img width="497" height="37" alt="image" src="https://github.com/user-attachments/assets/30e082b6-8dd6-46d3-a9cf-f04bc3bce6b2" />

```python
col_transformer.named_transformers_['enc'].categories_
```
<img width="511" height="62" alt="image" src="https://github.com/user-attachments/assets/d4d8cb39-4e11-4e67-bb68-cac0f4f9f50e" />

```python
col_transformer.named_transformers_['scaler'].mean_
```
<img width="624" height="38" alt="image" src="https://github.com/user-attachments/assets/aa4ecffd-292c-4153-9185-9d7fa4fce1fe" />

```python
col_transformer.named_transformers_['scaler'].var_
```
<img width="666" height="35" alt="image" src="https://github.com/user-attachments/assets/0b5e98a2-cd43-4106-a738-a0c8b36ed5d1" />

```python
# OneHotEncoder를 사용한 변환기
col_transformer = ColumnTransformer([('enc', OneHotEncoder(), cat_cols),
                                     ('scaler', StandardScaler(), num_cols)])
```
```python
result = col_transformer.fit_transform(features)
```
```python
result.shape
```
<img width="97" height="33" alt="image" src="https://github.com/user-attachments/assets/51d354f4-6286-49d7-b8ec-a6fd68853921" />

```python
result[:5, :]
```
<img width="686" height="235" alt="image" src="https://github.com/user-attachments/assets/f4b8b050-eb6c-47b0-842a-c1835cb08cfa" />

