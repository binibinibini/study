<img width="698" height="388" alt="image" src="https://github.com/user-attachments/assets/d4042f41-b7ad-43ac-862d-703a9efa48bc" />


# Linear Regression

선형 회귀는 훈련 셋의 MSE를 최소화할 수 있는 직선의 방정식을 찾는 것

```python
lin_reg = LinearRegression()   # 선형 회귀 모델 생성
```
```python
lin_reg.fit(X_train, y_train)   # 선형 회귀 모델 훈련 - MSE를 최소화하는 직선의 방정식을 찾음.
# 길이와 무게
```
<img width="200" height="67" alt="image" src="https://github.com/user-attachments/assets/1bad0fa9-8f87-461a-aebc-0b1d9461ddb4" />

```python
lin_reg.coef_   # 1차원 배열로 나옴. 선형 회귀식 y = ax + b 에서 독립변수 x의 계수(직선의 기울기) a
```
<img width="147" height="23" alt="image" src="https://github.com/user-attachments/assets/e9675f17-4573-4a0e-ba86-aa09d1449c0a" />

```python
lin_reg.intercept_   # 선형 회귀식 y = ax + b 에서 y 절편 b
```
<img width="224" height="33" alt="image" src="https://github.com/user-attachments/assets/8186ef34-d3b7-4d45-b1fe-d684dc44656d" />

```
y = 39x - 709
```
```python
train_pred = lin_reg.predict(X_train)
```
```python
train_pred  # 물고기 무게가 음수인게 몇개 있음
```
<img width="474" height="179" alt="image" src="https://github.com/user-attachments/assets/fa0f22cd-1cbd-4312-a177-75abecb7e84a" />

```python
X_train @ lin_reg.coef_ + lin_reg.intercept_    # 예측값 찾는거. y = X @ a + b
```
<img width="475" height="181" alt="image" src="https://github.com/user-attachments/assets/84816f53-53f0-4fe1-9c15-f9e352b74ed3" />

```python
# 훈련 셋의 MSE
mean_squared_error(y_train, train_pred)     #> MSE는 KNN의 MSE보다 큼.
```
<img width="130" height="27" alt="image" src="https://github.com/user-attachments/assets/4a4e1a5d-bf3d-4140-9d7e-f83e93360882" />

```python
# 훈련 셋의 결정계수
r2_score(y_train, train_pred)   # 결정계수는 KNN의 결정계수보다 작음.
```
<img width="131" height="31" alt="image" src="https://github.com/user-attachments/assets/2ff38533-4d94-4ec3-a89f-8e8abc115957" />

```
결정계수(R^2)
- 모델의 설명력을 수치로 나타낸 것
- 0부터 1까지의 값을 가지며,
   - 0에 가까울수록 모델이 거의 설명하지 못함
   - 1에 가까울수록 모델이 완벽에 가깝게 설명함
즉, 예측값이 실제값과 얼마나 비슷한지를 나타내는 비율

높다고 항상 좋은 모델은 아님! 과적합 가능성도 고려해야 함
```
```python
# 테스트 셋의 예측값
test_pred = lin_reg.predict(X_test)

# 테스트 셋의 MSE
mean_squared_error(y_test, test_pred)   # KNN의 MSE보다 큼

# 과대적합
```
<img width="140" height="27" alt="image" src="https://github.com/user-attachments/assets/29861f20-1980-477a-a98f-467304c4501c" />

```python
# 테스트 셋의 결정계수
r2_score(y_test, test_pred)     #> KNN 결정계수보다 작음.
```
<img width="145" height="28" alt="image" src="https://github.com/user-attachments/assets/8f1ad52c-d069-4cd2-8476-28b0339f0da6" />

```
Linear Regression 모델의 결과를 보면, 훈련 셋의 평가 점수(MSE, R2)가 테스트 셋의 평가 점수보다 좋음 -> 과적합(overfitting)
```

```python
# 훈련 셋 무게~길이 산점도
plt.scatter(X_train, y_train, alpha = 0.5, label = 'Train')   # alpha는 점의 투명도. 1은 불투명 -> 겹치는 점이 많을 때 더 잘 보이도록 함.

# 테스트 셋 무게~길이 산점도
plt.scatter(X_test, y_test, alpha = 0.5, label = 'Test')

# 가상의 물고기(50cm, 1500g)
plt.scatter(50, 1500, marker = 'v', color = 'red', label = 'Unknown')

# 선형 회귀 직선 선그래프
x = np.arange(5, 51, 0.1).reshape((-1, 1))   # np.arange(5, 51, 0.1)여기까지는 1차원 배열. 2차원 배열로 만들어야 그래프 그려짐
# 5부터 50까지 0.1간격의 숫자 -> 간격이 크면 그래프가 계단처럼 뚝뚝 끊어져 보일 수 있음.
# reshape((-1, 1)) -> 열 수를 1로 만들어라는 의미. 즉, 배열을 1열짜리 2차원 배열로 바꾸는 것
y_hat = x @ lin_reg.coef_ + lin_reg.intercept_  # (n, 1) @ (1,) -> (n,)
plt.plot(x, y_hat, 'r-')

plt.legend()
plt.grid()
plt.xlabel('Length (cm)')
plt.ylabel('Weight (g)')
plt.show()
```
<img width="549" height="412" alt="image" src="https://github.com/user-attachments/assets/bd2ceab4-59ca-41da-b0e5-31c8207e1d2c" />

# 다항 회쉬
<br>
2차항을 포함하는 선형 회귀
<br>
```python
X_train[:5, :]   # 물고기의 무게들
```
<img width="120" height="99" alt="image" src="https://github.com/user-attachments/assets/b920d86e-0a33-4194-97f2-1bba5c37b36d" />

```python
X_train[:5, :] ** 2
```
<img width="140" height="99" alt="image" src="https://github.com/user-attachments/assets/2fc6e7b8-4b9f-4c51-94b9-136018e3ba00" />

```python
X_train.shape, X_test.shape
```
<img width="135" height="34" alt="image" src="https://github.com/user-attachments/assets/c51e0ce5-2158-43fc-8f5c-fa40615fc295" />

```python
X_train_poly = np.c_[X_train ** 2, X_train]   # 컬럼 합차기(2차항을 추가한 2차원 배열)
X_train_poly.shape
```
<img width="59" height="31" alt="image" src="https://github.com/user-attachments/assets/de9b002a-1f20-4ad1-ba41-86450f054c8e" />

```python
X_trian_poly[:5, :]   # 얘를 훈련 시키면 된
```
<img width="208" height="95" alt="image" src="https://github.com/user-attachments/assets/38e44493-67e9-4a10-92fa-e31b97bdccdf" />

```python
lin_reg = LinearRegression()   # 모델 생성
```
```python
lin_reg.fit(X_train_poly, y_train)   # 모델 훈련 -> y = ax^2 + bx + c 함수의 계수 a, b와 절편 y를 찾음.
```
<img width="217" height="74" alt="image" src="https://github.com/user-attachments/assets/b9c03671-7107-488a-8aac-59929cefd839" />

```python
lin_reg.coef_   # (2,) shape의 1차원 배열(원소가 2개인 1차원 배열) <- 특성이 2개(x^2, x)이기 때문에
```
<img width="260" height="30" alt="image" src="https://github.com/user-attachments/assets/1f516b22-0d56-4567-8207-33535631498f" />

```python
lin_reg.intercept_   # 상수
```
<img width="217" height="26" alt="image" src="https://github.com/user-attachments/assets/907c55c5-2cb7-4360-9dd2-2296de536322" />

```python
X_train_poly @ lin_reg.coef_ + lin_reg.intercept_
# (42, 2) @ (2,) -> (42,)
# (42,) + scalar -> (42,)
```
<img width="478" height="190" alt="image" src="https://github.com/user-attachments/assets/f2280a4c-5688-4cf0-adb1-b491e29abfa6" />

```python
train_pred = lin_reg.predict(X_train_poly)   # 훈련 셋의 예측값
# X_train_poly이걸로 훈련했으면 예측도 X_train_poly로

train_pred
```
<img width="480" height="190" alt="image" src="https://github.com/user-attachments/assets/b6d4307a-8475-489f-bacf-2039c9b632a1" />

```python
# 훈련 셋의 결정계수
r2_score(y_train, train_pred)
```
<img width="150" height="31" alt="image" src="https://github.com/user-attachments/assets/3c2d2c42-ea01-4ad6-b3a9-2d27ed9fdab0" />

```python
# 2차항을 포함하는 테스트 셋
X_test_poly = np.c_[X_test ** 2, X_test]
```
```python
X_test_poly[:5, :]
```
<img width="189" height="88" alt="image" src="https://github.com/user-attachments/assets/5a963910-2b27-4730-bc56-8ceca11a8459" />

```python
test_pred = lin_reg.predict(X_test_poly)    # 테스트 셋의 예측값
test_pred
```
<img width="474" height="73" alt="image" src="https://github.com/user-attachments/assets/881abdcd-afe6-43c5-a61f-226be6ce2f92" />

```python
# 테스트 셋의 결정계수
r2_score(y_test, test_pred)
```
<img width="151" height="27" alt="image" src="https://github.com/user-attachments/assets/5eca6a3b-1a18-401c-a8ba-dd545764f0b6" />

```python
# 훈련 셋 산점도
plt.scatter(X_train, y_train, alpha = 0.5, label = 'Train')

# 테스트 셋 산점도
plt.scatter(X_test, y_test, alpha = 0.5, label = 'Test')

# 50cm, 1500g 가상의 물고기
plt.scatter(50, 1500, marker = 'v', color = 'red', label = 'Unknown')

# 선형회귀 2차 함수 선그래프
x = np.arange(5, 51, 0.001)
x_poly = np.c_[x ** 2, x]
# print(x_poly.shape)
# print(x_poly[:5, :])
y_hat = x_poly @ lin_reg.coef_ + lin_reg.intercept_     # x^2 * a + x * b + c
plt.plot(x, y_hat, 'g-', label = 'Regression')

plt.grid()
plt.xlabel('Length (cm)')
plt.ylabel('Weight (g)')
plt.legend()
plt.show()
```
<img width="549" height="403" alt="image" src="https://github.com/user-attachments/assets/0349d118-7cfe-48eb-b97f-1eabc81e8f4c" />

# Pipeline
<br>
Pipeline: PolynomialFeatures + LinearRegression
<br>

scikit-learn 클래스 설계 철학
*   변환기(Transformer)
    *   `fit`, `fit_transform`, `transform` 메서드들을 가지고 있음.
    *   데이터 전처리(preprocessing) 과정에서 주로 사용.
    *   예: StandardScaler, MinMaxScaler, PolynomialFeatures, ...
*   추정기(예측기)(Estimator)
    *   `fit`, `predict`, `score` 메서드들을 가지고 있음.
    *   ML(머신러닝)(분류/회귀) 알고리즘들을 구현한 클래스.
    *   KNeighborsClassifier, KNeighborsRegressor, LinearRegression, ...
<br>

```python
X_train.shape, X_test.shape
```
<img width="142" height="33" alt="image" src="https://github.com/user-attachments/assets/90652aa3-0a0d-49d3-a4ff-c7ca7129f221" />

```python
poly = PolynomialFeatures(degree = 3, include_bias=False)   # 변환기 객체 생성.
# degree -> 기본값은 2차항을 만들어줌.
result = poly.fit_transform(X_train)    # 변환기를 사용해서 훈련 셋을 변환
print(poly.get_feature_names_out())
print(result.shape)
print(result[:5, :])
```
<img width="310" height="126" alt="image" src="https://github.com/user-attachments/assets/5b819139-7468-4c4f-8d3c-adcd7a2a5d83" />

```python
# Pipeline으로 연결할 변환기 생성
poly = PolynomialFeatures(degree = 2, include_bias = False)

# Pipeline으로 연결할 추정기 생성
reg = LinearRegression()

# Pipeline 생성
model = Pipeline(steps = [('poly_features', poly), ('lin_reg', reg)])
```
```python
model
```
<img width="236" height="144" alt="image" src="https://github.com/user-attachments/assets/e509eaf7-c75c-494e-94f3-43fe9445dd6a" />

```python
# 모델 훈련(Pipeline.fit 메서드 호출): (1) 변환기 fit_transform, (2) 추정기 fit
model.fit(X_train, y_train)
```
<img width="236" height="143" alt="image" src="https://github.com/user-attachments/assets/c4f94109-3743-4a5e-9dcd-fbab0e07e613" />

```python
model['lin_reg']    # LinearRegression를 찾고 싶을 때, 'lin_reg'이름을 주면 됨.
```
<img width="205" height="71" alt="image" src="https://github.com/user-attachments/assets/93128270-3084-4ae7-b1f7-bd1555f3e1a6" />

```python
model['lin_reg'].coef_  # x, x^2의 계수
```
<img width="256" height="31" alt="image" src="https://github.com/user-attachments/assets/41213693-0b5a-422b-b373-a07e722f1f10" />

```python
model['lin_reg'].intercept_
```
<img width="223" height="24" alt="image" src="https://github.com/user-attachments/assets/b90551f5-f4e2-4e6e-96e4-1c90a5087e93" />

```python
model.predict(X_train)      # 훈련 셋 예측값
# (변환되지 않은거 넣기)
```
<img width="475" height="184" alt="image" src="https://github.com/user-attachments/assets/6c70a861-41f3-4e03-b071-97800cd68fa3" />

```python
model.predict(X_test)   # 테스트 셋 예측값
```
<img width="470" height="70" alt="image" src="https://github.com/user-attachments/assets/f4918d14-1acb-47a2-b533-a7d0402ef479" />

